{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92838936",
   "metadata": {},
   "source": [
    "# **Tutorial 3: Stop detection in trajectories**\n",
    "\n",
    "In this notebook we will explore some stop detection algorithms implemented in `nomad`. We will learn the differences between stop detection and traditional clustering algorithms, and the types of errors we need to watch out for. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f26154",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "Download the file [IC2S2-2025.zip](https://drive.google.com/file/d/1wk3nrNsmAiBoTtWznHjjjPkmWAZfxk0P/view?usp=drive_link) and extract it to this folder to obtain the sample trajectory data used in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d265f4",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baab3bd",
   "metadata": {},
   "source": [
    "Let's use the same 3 week sample of data as in the previous notebook. Initially we will focus on data from a user in just one day, which we can filter at read time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19184dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.base as loader\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, box, Point\n",
    "\n",
    "\n",
    "city = gpd.read_file(\"garden_city.geojson\").to_crs('EPSG:3857')\n",
    "outer_box = box(*city.total_bounds).buffer(15, join_style='mitre')\n",
    "\n",
    "filepath_root = 'gc_data_long/'\n",
    "tc = {\n",
    "    \"user_id\": \"gc_identifier\",\n",
    "    \"timestamp\": \"unix_ts\",\n",
    "    \"x\": \"dev_x\",\n",
    "    \"y\": \"dev_y\",\n",
    "    \"ha\":\"ha\",\n",
    "    \"date\":\"date\"}\n",
    "\n",
    "users = ['admiring_brattain']\n",
    "traj = loader.sample_from_file(filepath_root, format='parquet', users=users, filters = ('date','==', '2024-01-01'), traj_cols=tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036947ae",
   "metadata": {},
   "source": [
    "Understanding the time component of the trajectory is important since the notion of a \"stop\" or a \"visit\" requires finding pings that indicate **stationary behavior**. Naturally this depends on the **pings being spatially close to one another, but also in the same period of time**. Let's try to visualize this temporal component on the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae98d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import shapely.plotting as shp_plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "# small utility\n",
    "from nomad.stop_detection.viz import adjust_zoom, plot_stops_barcode, plot_pings, plot_stops, plot_time_barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_map, ax_barcode) = plt.subplots(2, 1, figsize=(6,6.5), gridspec_kw={'height_ratios':[10,1]})\n",
    "\n",
    "# Map\n",
    "shp_plt.plot_polygon(outer_box, ax=ax_map, add_points=False, color='#0e0e0e')\n",
    "city.plot(ax=ax_map, column='type', edgecolor='black', linewidth=0.75, cmap='viridis')\n",
    "ax_map.scatter(traj['dev_x'], traj['dev_y'], s=10, color='darkblue', alpha=0.75)\n",
    "adjust_zoom(traj['dev_x'], traj['dev_y'], buffer=0.8, ax=ax_map)\n",
    "ax_map.set_axis_off()\n",
    "\n",
    "plot_time_barcode(traj['unix_ts'], ax_barcode)\n",
    "\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7380ba",
   "metadata": {},
   "source": [
    "We can see that the pings are very dense for this user and correspond (apparently) to **4 visits to close by locations**. We would like to have a clustering algorithm that can recover:\n",
    "1. **Where** those stops took place (with a centroid for example)\n",
    "2. **When** the stop started, and how long it lasted\n",
    "\n",
    "<small>*Expand the cell bellow to see a small animation for the image above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_map, ax_barcode) = plt.subplots(2, 1, figsize=(6,6.5), gridspec_kw={'height_ratios':[10,1]})\n",
    "\n",
    "# Map base\n",
    "shp_plt.plot_polygon(outer_box, ax=ax_map, add_points=False, color='#0e0e0e')\n",
    "city.plot(ax=ax_map, column='type', edgecolor='black', linewidth=0.75, cmap='Accent')\n",
    "adjust_zoom(traj['dev_x'], traj['dev_y'], buffer=0.8, ax=ax_map)\n",
    "ax_map.set_axis_off()\n",
    "points = ax_map.scatter(traj['dev_x'], traj['dev_y'], s=10, color='darkblue', alpha=0.0)\n",
    "current = ax_map.scatter([traj['dev_x'].iloc[0]], [traj['dev_y'].iloc[0]], s=50, color='red', alpha=1.0)\n",
    "\n",
    "def animate(i):\n",
    "    points.set_alpha([1.0 if j < i else 0.0 for j in range(len(traj))])\n",
    "    current.set_offsets([[traj['dev_x'].iloc[i], traj['dev_y'].iloc[i]]])\n",
    "    ax_barcode.cla()  # Clear barcode axis\n",
    "    plot_time_barcode(traj['unix_ts'], ax_barcode, current_idx=i)  # Your function, highlights current in red\n",
    "    return points, current\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(traj), interval=120, blit=False)\n",
    "plt.tight_layout(pad=0.1)\n",
    "\n",
    "html = ani.to_html5_video() # capture the animation\n",
    "plt.close(fig)\n",
    "# finally display the video\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d760b0",
   "metadata": {},
   "source": [
    "## Stop detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc66678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.stop_detection.dbscan as DBSCAN\n",
    "import nomad.stop_detection.lachesis as LACHESIS\n",
    "import nomad.stop_detection.grid_based as GRID_BASED\n",
    "import nomad.filters as filters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f276f4e",
   "metadata": {},
   "source": [
    "### Sequential stop detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b269cf8",
   "metadata": {},
   "source": [
    "The first stop detection algorithm implemented in ```nomad``` is a sequential algorithm insipired by the one in _Project Lachesis: Parsing and Modeling Location Histories_ (Hariharan & Toyama). This algorithm for extracting stays is dependent on two parameters: the roaming distance and the stay duration. \n",
    "\n",
    "dur_min\n",
    "* `delta_roam` is the Roaming distance ($\\Delta_{\\texttt{max}}$) represents the maximum distance an object can move away from a point location and still be considered to be staying at that location.\n",
    "* `dur_min` is a minimum stop duration below which we consider the stop to be (potentially) spurious\n",
    "* ```dt_max```: Maximum time gap permitted between consecutive pings in a stay in minutes (dt_max should be greater than dur_min).\n",
    "\n",
    "The algorithm identifies stops as contiguous sequences of pings that have a diameter less than `delta_roam` for at least the duration of the stop duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80327e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LACHESIS.lachesis(traj, delta_roam=20, dt_max = 60, dur_min=5, traj_cols=tc) # Try passing keep_col_names = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1dc896",
   "metadata": {},
   "source": [
    "Optionally, we can get some useful statistics about each stop with the argument `complete_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = LACHESIS.lachesis(traj, delta_roam=20, dt_max = 60, dur_min=5, complete_output=True, keep_col_names=True, traj_cols=tc)\n",
    "stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab83326",
   "metadata": {},
   "source": [
    "The diameter column can give us a notion of the extent of the stop. Larger stops reveal less precise information and could be evidence of **merging** two true stops. We can visualize them as circles with radius `stops['diameter']/2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_map, ax_barcode) = plt.subplots(2, 1, figsize=(6,6.5),\n",
    "                                         gridspec_kw={'height_ratios':[10,1]})\n",
    "\n",
    "shp_plt.plot_polygon(outer_box, ax=ax_map, add_points=False, color='#0e0e0e')\n",
    "city.plot(ax=ax_map, edgecolor='white', linewidth=1, color='#2c353c')\n",
    "\n",
    "plot_stops(stops, ax=ax_map, cmap='Reds', x='dev_x', y='dev_y')\n",
    "plot_pings(traj, ax=ax_map, s=6, point_color='black', cmap='twilight', traj_cols=tc)\n",
    "\n",
    "adjust_zoom(stops['dev_x'], stops['dev_y'], buffer=1.4, ax=ax_map)\n",
    "ax_map.set_axis_off()\n",
    "\n",
    "plot_time_barcode(traj[tc['timestamp']], ax=ax_barcode, set_xlim=True)\n",
    "plot_stops_barcode(stops, ax=ax_barcode, cmap='Reds', set_xlim=False, x='x', y='y', timestamp='unix_ts')\n",
    "\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bcc565",
   "metadata": {},
   "source": [
    "### Flexibility in input formats \n",
    "\n",
    "The stop detection algorithms implemented in `nomad` support different combinations of input formats that are common in commercial datasets, detecting default names when possible\n",
    "- timestamps in `datetime64[ns, tz]` or as unix seconds in integers\n",
    "- geographic coordinates (`lon`, `lat`) which use the Haversine distance or projected coordinates (`x`, `y`) using meters and euclidean distance.\n",
    "- Alternatively, if locations are only given through a spatial index like H3 or geohash, there is a **grid_based** clustering algorithm requiring no coordinates. \n",
    "\n",
    "The algorithms work with the same call, provided there is at least a pair of coordinates (or a location/spatial index) as well as at least a temporal column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01482356-bda1-472c-8875-bd1260679da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj['h3_cell'] = filters.to_tessellation(traj, index=\"h3\", res=10, x='dev_x', y='dev_y', data_crs='EPSG:3857')\n",
    "traj['h3_cell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "import h3\n",
    "\n",
    "traj[['longitude','latitude']] = np.column_stack(\n",
    "    filters.to_projection(traj, x='dev_x', y='dev_y', data_crs='EPSG:3857', crs_to='EPSG:4326')\n",
    ")\n",
    "\n",
    "traj['zoned_datetime'] = pd.to_datetime(traj['unix_ts'], unit='s', utc=True).dt.tz_convert('Etc/GMT-1')\n",
    "traj['h3_cell'] = filters.to_tessellation(traj, index=\"h3\", res=10, latitude='latitude', longitude='longitude')\n",
    "\n",
    "# Alternate datasets \n",
    "traj_geog = traj[['latitude', 'longitude', 'zoned_datetime']]\n",
    "traj_h3 = traj[['gc_identifier', 'unix_ts', 'h3_cell']]\n",
    "\n",
    "# Very similar call\n",
    "stops_lac =  LACHESIS.lachesis(traj_geog, delta_roam=25, dt_max = 45, dur_min=3, complete_output=True, latitude='latitude', longitude='longitude', datetime='zoned_datetime')\n",
    "traj_geog['cluster'] = LACHESIS.lachesis_labels(traj_geog, delta_roam=25, dt_max = 45, dur_min=3, latitude='latitude', longitude='longitude', datetime='zoned_datetime')\n",
    "\n",
    "stops_h3 = GRID_BASED.grid_based(traj_h3, time_thresh=180, dur_min=3, complete_output=True, timestamp='unix_ts', location_id='h3_cell')\n",
    "traj_h3['cluster'] = GRID_BASED.grid_based_labels(traj_h3, time_thresh=180, dur_min=3, timestamp='unix_ts', location_id='h3_cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_h3[['dev_x','dev_y']] = traj[['dev_x','dev_y']]\n",
    "\n",
    "fig, (ax_map, ax_barcode) = plt.subplots(2, 1, figsize=(6.5,7),\n",
    "                                         gridspec_kw={'height_ratios':[10,1]})\n",
    "\n",
    "shp_plt.plot_polygon(outer_box, ax=ax_map, add_points=False, color='#0e0e0e')\n",
    "city.plot(ax=ax_map, edgecolor='white', linewidth=1, color='#2c353c')\n",
    "\n",
    "plot_stops(stops_h3, ax=ax_map, cmap='rainbow', location_id='h3_cell', crs='EPSG:3857', edge_only=True)\n",
    "#plot_pings(traj_h3, ax=ax_map, point_color='black', cmap=\"rainbow\", radius=2, s=5, circle_alpha=0.5, traj_cols=tc)\n",
    "\n",
    "adjust_zoom(stops['dev_x'], stops['dev_y'], buffer=3, ax=ax_map)\n",
    "ax_map.set_axis_off()\n",
    "\n",
    "#plot_time_barcode(traj_h3[tc['timestamp']], ax=ax_barcode, set_xlim=True)\n",
    "plot_stops_barcode(stops_h3, ax=ax_barcode, cmap='viridis', set_xlim=False, timestamp='unix_ts')\n",
    "\n",
    "fig.suptitle(\"Stops detected from just H3_cells and unix timestamps\")\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d1d9f",
   "metadata": {},
   "source": [
    "**Fig 2. Possible problems when applying stop detection to be aware of. How to parameterize optimally?**\n",
    "    \n",
    "![title](figures/stop-detection-problems.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf66c42",
   "metadata": {},
   "source": [
    "### Density based stop detection (Temporal DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641e8bc",
   "metadata": {},
   "source": [
    "The second stop detection algorithm implemented in ```nomad``` is an adaptation of DBSCAN. Unlike in plain DBSCAN, we also incorporate the time dimension to determine if two pings are \"neighbors\". This implementation relies on 3 parameters\n",
    "\n",
    "* `time_thresh` defines the maximum time difference (in minutes) between two consecutive pings for them to be considered neighbors within the same cluster.\n",
    "* `dist_thresh` specifies the maximum spatial distance (in meters) between two pings for them to be considered neighbors.\n",
    "* `min_pts` sets the minimum number of neighbors required for a ping to form a cluster.\n",
    "\n",
    "Notice that this method also works with **geographic coordinates** (lon, lat), using Haversine distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ['confident_aryabhata']\n",
    "traj = loader.sample_from_file(filepath_root, format='parquet', users=users, filters = ('date','<=', '2024-01-03'), traj_cols=tc)\n",
    "traj[['longitude','latitude']] = np.column_stack(\n",
    "    filters.to_projection(traj, x='dev_x', y='dev_y', data_crs='EPSG:3857', crs_to='EPSG:4326')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4c618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stops_dbscan = DBSCAN.ta_dbscan(traj,\n",
    "                    time_thresh=720,\n",
    "                    dist_thresh=15,\n",
    "                    min_pts=3,\n",
    "                    complete_output=True,\n",
    "                    traj_cols=tc)\n",
    "\n",
    "fig, ax_barcode = plt.subplots(figsize=(10,1.5))\n",
    "\n",
    "plot_time_barcode(traj['unix_ts'], ax=ax_barcode, set_xlim=True)\n",
    "plot_stops_barcode(stops_dbscan, ax=ax_barcode, stop_color='red', set_xlim=False, timestamp='unix_ts')\n",
    "fig.suptitle(\"Overlapping stops\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.stop_detection.postprocessing as post\n",
    "\n",
    "post.invalid_stops(stops_dbscan, print_stops=True, **tc)\n",
    "stops_dbscan.loc[stops_dbscan.unix_ts.isin([1704197861, 1704242618])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c79720",
   "metadata": {},
   "source": [
    "## Spatial-only algorithms can produce (temporally) invalid stop tables\n",
    "\n",
    "While the parameter `time_thresh` helps mitigate this issue (this would be *pre-processing*). It seems like some post-processing is necessary to \"break up\" temporally overlapping stops. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1063cf",
   "metadata": {},
   "source": [
    "One way is to use a **sequential location-based algorithm**, using DBSCAN's cluster labels **as \"locations\"**. For this we need the **disaggregated output** of the stop-detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj[\"cluster\"] = DBSCAN.ta_dbscan_labels(traj,\n",
    "                    time_thresh=720,\n",
    "                    dist_thresh=15,\n",
    "                    min_pts=3,\n",
    "                    traj_cols=tc)\n",
    "\n",
    "## Uncomment to see label counts\n",
    "# traj.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62b203-21ca-422c-aa64-0b2cbe7d69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d633ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomad.stop_detection.utils import summarize_stop\n",
    "\n",
    "new_cluster = GRID_BASED.grid_based_labels(\n",
    "                        data=traj.loc[traj.cluster!=-1], # except noise pings\n",
    "                        time_thresh=720,\n",
    "                        min_cluster_size=3,\n",
    "                        location_id=\"cluster\", # grid_based requires a location column\n",
    "                        traj_cols=tc)\n",
    "\n",
    "traj.loc[traj.cluster!=-1, 'cluster'] = new_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_processed_stops = [\n",
    "        summarize_stop(\n",
    "            grouped_data=group,\n",
    "            keep_col_names=True,\n",
    "            complete_output=True,\n",
    "            traj_cols=tc,\n",
    "            passthrough_cols = ['cluster', 'gc_identifier']\n",
    "        )\n",
    "        for _, group in traj.loc[traj.cluster!=-1].groupby('cluster', as_index=False, sort=False)\n",
    "    ]\n",
    "post_processed_stops = pd.DataFrame(post_processed_stops)\n",
    "\n",
    "print(\"Invalid stops?\")\n",
    "post.invalid_stops(post_processed_stops, print_stops=True, **tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_barcode = plt.subplots(figsize=(10,1.5))\n",
    "\n",
    "plot_time_barcode(traj['unix_ts'], ax=ax_barcode, set_xlim=True)\n",
    "plot_stops_barcode(post_processed_stops, ax=ax_barcode, stop_color='blue', set_xlim=False, timestamp='unix_ts')\n",
    "fig.suptitle(\"DBSCAN stops with post-processing\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac75ac-6372-4268-8d2e-5bb9d8c6251b",
   "metadata": {},
   "source": [
    "This post-processing is also wrapped in the method `nomad.stop_detection.postprocessing.remove_overlaps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6eb8cd-f8e5-483a-9a92-f805eaf634c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_processed_stops = post.remove_overlaps(traj, time_thresh=720, method='cluster', traj_cols=tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de448bd",
   "metadata": {},
   "source": [
    "## Which algorithm to choose? which parameters\n",
    "\n",
    "This is not a trivial problem and researchers often rely on \"trial and error\" or, worse, default parameters. A semi-informed choice could depend on:\n",
    "\n",
    "\n",
    "| Factor | Implication |\n",
    "| --- | --- |\n",
    "| Signal sparsity | Denser data → increase DBSCAN `min_pts` to prevent over‑clustering |\n",
    "| Noise level | Higher noise (low accuracy) → use larger distance thresholds |\n",
    "| Building proximity | Dense areas → use smaller distance thresholds |\n",
    "| Scalability | More robust methods → longer execution time |\n",
    "\n",
    "We could do **a parameter search** by keeping track of some statistics of the output of several stop detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = loader.sample_from_file(filepath_root, frac_users=0.1, format='parquet', traj_cols=tc, seed=10) # try frac_users = 0.1\n",
    "\n",
    "# H3 cells for grid_based stop detection method\n",
    "traj['h3_cell'] = filters.to_tessellation(traj, index=\"h3\", res=10, x='dev_x', y='dev_y', data_crs='EPSG:3857')\n",
    "pings_per_user = traj['gc_identifier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import nomad.stop_detection.hdbscan as HDBSCAN\n",
    "\n",
    "# Approximately 5 minutes for 40 users\n",
    "results = []\n",
    "for user, n_pings in tqdm(pings_per_user.items(), total=len(pings_per_user)):\n",
    "    user_data = traj.query(\"gc_identifier == @user\")\n",
    "\n",
    "    # For location based\n",
    "    start_time = time.time()\n",
    "    stops_gb = GRID_BASED.grid_based(user_data, time_thresh=240, complete_output=True, timestamp='unix_ts', location_id='h3_cell')\n",
    "    execution_time = time.time() - start_time\n",
    "    results += [pd.Series({'user':user, 'algo':'grid_based', 'execution_time':execution_time, 'total_dwell':stops_gb.duration.sum(), 'avg_diameter':52, 'n_pings':n_pings})]\n",
    "    \n",
    "    # For Lachesis\n",
    "    start_time = time.time()\n",
    "    stops_lac = LACHESIS.lachesis(user_data, delta_roam=30, dt_max=240, complete_output=True, traj_cols=tc)\n",
    "    execution_time = time.time() - start_time\n",
    "    results += [pd.Series({'user':user, 'algo':'lachesis', 'execution_time':execution_time, 'total_dwell':stops_lac.duration.sum(), 'avg_diameter':stops_lac.diameter.mean(), 'n_pings':n_pings})]\n",
    "\n",
    "    # For TADbscan\n",
    "    start_time = time.time()\n",
    "    user_data_tadb = user_data.assign(cluster=DBSCAN.ta_dbscan_labels(user_data, time_thresh=240, dist_thresh=15, min_pts=3, traj_cols=tc))\n",
    "    # - post-processing\n",
    "    stops_tadb = post.remove_overlaps(user_data_tadb, time_thresh=240, method='cluster', traj_cols=tc, min_cluster_size=2)\n",
    "    execution_time = time.time() - start_time\n",
    "    results += [pd.Series({'user':user, 'algo':'tadbscan', 'execution_time':execution_time, 'total_dwell':stops_tadb.duration.sum(), 'avg_diameter':stops_tadb.diameter.mean(), 'n_pings':n_pings})]\n",
    "\n",
    "    # For HDBSCAN\n",
    "    start_time = time.time()\n",
    "    user_data_hdb = user_data.assign(cluster=HDBSCAN.st_hdbscan_labels(user_data, time_thresh=240, min_pts=3, min_cluster_size=2, traj_cols=tc))\n",
    "    # - post-processing\n",
    "    stops_hdb = post.remove_overlaps(user_data_hdb, time_thresh=240, method='cluster', traj_cols=tc)    \n",
    "    execution_time = time.time() - start_time\n",
    "    results += [pd.Series({'user':user, 'algo':'hdbscan', 'execution_time':execution_time, 'total_dwell':stops_hdb.duration.sum(), 'avg_diameter':stops_hdb.diameter.mean(), 'n_pings':n_pings})]\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b329c036-1a08-44ef-8a18-688240087a29",
   "metadata": {},
   "source": [
    "### Use **completeness to normalize** ('hrs with data' / 'total hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_per_user = filters.completeness(traj, timestamp='unix_ts', user_id='gc_identifier')\n",
    "dwell_scaling = 1/completeness_per_user\n",
    "dwell_scaling.name = 'dwell_scaling'\n",
    "\n",
    "metrics = pd.merge(results, dwell_scaling, left_on='user', right_index=True)\n",
    "metrics['rescaled_total_dwell'] = (metrics['total_dwell']/60)*metrics['dwell_scaling'] # in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "algos = ['grid_based', 'lachesis', 'tadbscan', 'hdbscan']\n",
    "palette = dict(zip(algos, sns.color_palette(n_colors=len(algos))))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# scatter: n_pings vs execution_time\n",
    "sns.scatterplot(data=metrics, x='n_pings', y='execution_time', hue='algo', ax=axes[0])\n",
    "axes[0].set_title('n_pings vs execution_time')\n",
    "\n",
    "# density: avg_diameter\n",
    "sns.kdeplot(data=metrics, x='avg_diameter', hue='algo', ax=axes[1], common_norm=False, bw_adjust=2)\n",
    "for algo, color in palette.items():\n",
    "    med = metrics.loc[metrics.algo == algo, 'avg_diameter'].median()\n",
    "    axes[1].axvline(med, color=color, linestyle='--')\n",
    "    \n",
    "axes[1].set_title('average stop diameter (m)')\n",
    "\n",
    "# density: rescaled_total_dwell\n",
    "sns.kdeplot(data=metrics, x='rescaled_total_dwell', hue='algo', ax=axes[2], common_norm=False)\n",
    "axes[2].set_title('total dwell time (h) rescaled')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f9bb45-f5d5-4eea-8455-288d5e12583c",
   "metadata": {},
   "source": [
    "## Export stops for next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea48f6-42ac-4db7-9cf1-ed6ed3392ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# takes approximately 6 min\n",
    "traj = loader.from_file(filepath_root, format='parquet', traj_cols=tc)\n",
    "\n",
    "all_stops = LACHESIS.lachesis_per_user(traj, delta_roam=30, dt_max=240, complete_output=True, keep_col_names=False, passthrough_cols=['tz_offset'], traj_cols=tc)\n",
    "\n",
    "loader.to_file(all_stops, \"gc_data_stops/\", format=\"parquet\", partition_by=[\"gc_identifier\"], existing_data_behavior='overwrite_or_ignore', user_id='gc_identifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 313 (nomad-venv)",
   "language": "python",
   "name": "nomad-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

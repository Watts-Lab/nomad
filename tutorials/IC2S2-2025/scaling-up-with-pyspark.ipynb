{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6428c910",
   "metadata": {},
   "source": [
    "# **Tutorial 5: Scaling up with Pyspark** \n",
    "\n",
    "In this section of the tutorial, we demonstrate how to process a much larger mobility dataset using nomad's software in a Spark cluster. Our target application will be to produce mobility metrics, aggregated at the neighborhood level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205c5b2",
   "metadata": {},
   "source": [
    "## Configure your Spark cluster with SparkMagic\n",
    "\n",
    "The EMR cluster for this demonstration has 1 master node (`m5.xlarge`, 4 vCPU, 16 GiB RAM) and 3 core nodes (`c5.4xlarge`, each with 16 vCPU and 32 GiB RAM). That gives us a total of 48 vCPUs across the workers.\n",
    "\n",
    "These resources are divided between a **driver** and multiple **executors**:\n",
    "- The **driver** runs inside the notebook. It coordinates the job, tracks task progress, and collects results.\n",
    "- The **executors** are distributed processes that perform actual computations on the worker nodes.\n",
    "\n",
    "We configure the cluster so that:\n",
    "- Each executor uses 4 vCPUs and ~5 GB of memory,\n",
    "- This fits 4 executors per core node (3 nodes × 4 = 12 total executors),\n",
    "- Giving us 48 total executor cores — fully using the cluster's compute capacity.\n",
    "\n",
    "We also allocate 8 GB of memory to the driver, which often needs to receive and process shuffled or aggregated data from the executors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cafad27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:12:20.915869Z",
     "iopub.status.busy": "2025-07-16T16:12:20.915627Z",
     "iopub.status.idle": "2025-07-16T16:12:20.931630Z",
     "shell.execute_reply": "2025-07-16T16:12:20.931040Z",
     "shell.execute_reply.started": "2025-07-16T16:12:20.915844Z"
    }
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\"conf\":\n",
    "     {\"spark.pyspark.python\":\"/home/hadoop/nomad-venv/bin/python3\",\n",
    "      \"spark.pyspark.virtualenv.bin.path\":\"/home/hadoop/nomad-venv/bin\",\n",
    "      \"spark.driver.memory\": \"6g\",\n",
    "      \"spark.driver.maxResultSize\": \"4g\",\n",
    "      \"spark.executor.memory\": \"4900m\",\n",
    "      \"spark.executor.cores\": \"4\", \n",
    "      \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "      \"spark.dynamicAllocation.minExecutors\": \"4\",\n",
    "      \"maximizeResourceAllocation\": \"true\",\n",
    "      \"spark.sql.execution.arrow.pyspark.enabled\": \"true\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f908a",
   "metadata": {},
   "source": [
    "## A not-that-off-topic example: count intersecting time intervals\n",
    "\n",
    "A large number of events := `(event_id, start_datetime, end_datetime)` need to be compared to find the pairs that intersect. \n",
    "- Events are all under 15 min long\n",
    "- Simple sorting can be a bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb4aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b89ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25_000_000\n",
    "parts = 250\n",
    "sec_in_3_weeks = 3 * 7 * 24 * 3600\n",
    "a_totally_normal_day = int(dt.datetime(2021, 1, 6).timestamp())\n",
    "\n",
    "events = (spark.range(N, numPartitions=parts)\n",
    "          # seconds offset into a 7‑day window\n",
    "          .withColumn(\"offset\", (F.rand() * sec_in_3_weeks).cast(\"int\"))\n",
    "          # duration drawn from [60s, 7200s] 1min to 2 hours\n",
    "          .withColumn(\"duration\", (F.rand() * 7140 + 60).cast(\"int\"))\n",
    "          .withColumn(\"start\", F.from_unixtime(a_totally_normal_day + F.col(\"offset\")).cast(\"timestamp\"))\n",
    "          .withColumn(\"end\",   F.from_unixtime(a_totally_normal_day + F.col(\"offset\") + F.col(\"duration\")).cast(\"timestamp\"))\n",
    "          .select(\"id\", \"start\", \"end\")\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a705fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.show(5, truncate=False)\n",
    "print(f\"Initial partitions: {events.rdd.getNumPartitions()}\")\n",
    "\n",
    "print(\"Rows in first ten partitions:\",\n",
    "      events.rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c9380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N        = 1_500_000  # records\n",
    "parts    = 200  # initial partition of the data\n",
    "DUR_MAX  = 900  # <= 15 min\n",
    "totally_normal_day  = int(dt.datetime(2021, 1, 6).timestamp())\n",
    "sec_in_5_weeks   = 5 * 7 * 24 * 3600  # 5 weeks\n",
    "\n",
    "events = (spark.range(N, numPartitions=parts)\n",
    "          .withColumn(\"offset\", (F.rand() * sec_in_5_weeks).cast(\"int\"))\n",
    "          .withColumn(\"duration\", (F.rand() * DUR_MAX + 1).cast(\"int\"))\n",
    "          .withColumn(\"start\", F.from_unixtime(totally_normal_day + F.col(\"offset\")).cast(\"timestamp\"))\n",
    "          .withColumn(\"end\",   F.from_unixtime(totally_normal_day + F.col(\"offset\") + F.col(\"duration\")).cast(\"timestamp\"))\n",
    "          .select(\"id\", \"start\", \"end\")\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399e56c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.show(5, truncate=False)\n",
    "print(f\"Initial partitions: {events.rdd.getNumPartitions()}\")\n",
    "\n",
    "print(\"Rows in first ten partitions:\",\n",
    "      events.rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a27dc5",
   "metadata": {},
   "source": [
    "### How to parallelize counting overlaps? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe716294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### [click to reveal]\n",
    "bucketed = (events\n",
    "            .withColumn(\"start_bucket\", # 30 minute interval of the start time\n",
    "                        F.floor(F.col(\"start\").cast(\"int\")/1800)) # 30 minute buckets\n",
    "            .withColumn(\"bucket\",\n",
    "                        F.explode(\n",
    "                            F.sequence(\n",
    "                                F.col(\"start_bucket\"),\n",
    "                                F.floor(F.col(\"end\").cast(\"int\")/1800)\n",
    "                            ))))\n",
    "\n",
    "\n",
    "# No execution yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505d124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### [click to reveal]\n",
    "bucketed.groupby(\"bucket\").count().show(10) # triggers execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdbb8e5",
   "metadata": {},
   "source": [
    "### *Pandas user defined functions (pandas_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50544659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "def count_overlaps(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    pdf = pdf.sort_values(\"start\")\n",
    "    starts      = pdf[\"start\"].values\n",
    "    ends        = pdf[\"end\"].values\n",
    "    start_bs    = pdf[\"start_bucket\"].values\n",
    "    cur_bucket  = pdf[\"bucket\"].iat[0]\n",
    "    \n",
    "    cnt = 0\n",
    "    n   = len(starts)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if starts[j] > ends[i]:\n",
    "                break\n",
    "            # only count if this bucket is the \"canonical\" one\n",
    "            if cur_bucket == max(start_bs[i], start_bs[j]):\n",
    "                cnt += 1\n",
    "    \n",
    "    return pd.DataFrame({\"cnt\": [cnt]})\n",
    "\n",
    "# applyInPandas and sum across buckets\n",
    "overlap_counts = (\n",
    "    bucketed\n",
    "      .groupby(\"bucket\")\n",
    "      .applyInPandas(count_overlaps, schema=\"cnt long\")\n",
    ")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13666362",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_counts.toPandas() # Will trigger all the execution again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overlaps.explain())  \n",
    "df = overlaps.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a0ee2",
   "metadata": {},
   "source": [
    "# Large scale mobility dataset (Philadelphia, PA, USA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f9991a",
   "metadata": {},
   "source": [
    "## Load Geometry Data\n",
    "\n",
    "Let's first explore a sample of data corresponding to the county of Los Angeles, in California. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00d850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nomad.io.spark import table_columns\n",
    "\n",
    "data_path = \"s3://catalog-csslab/tutorial-large-data/\"\n",
    "table_columns(data_path, include_schema=False) # try True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b26ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = spark.read.parquet(data_path)\n",
    "data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528332e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.select(F.min(data[\"date\"]), F.max(data[\"date\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce59b4c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:43:23.905876Z",
     "iopub.status.busy": "2025-07-16T16:43:23.905624Z",
     "iopub.status.idle": "2025-07-16T16:43:23.947185Z",
     "shell.execute_reply": "2025-07-16T16:43:23.946557Z",
     "shell.execute_reply.started": "2025-07-16T16:43:23.905848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nomad.io.base as loader\n",
    "from pyspark.sql.functions import col, count, approx_count_distinct, xxhash64, abs\n",
    "import geopandas as gpd\n",
    "\n",
    "la_fips = '06037' #LA COUNTY\n",
    "la_poly = \"POLYGON ((-117.704725 34.093957, -117.730125 34.021371, -117.76769 34.023506, -117.767483 34.004611, -117.785062 34.004809, -117.802539 33.975551, -117.783287 33.946411, -117.976498 33.94605, -117.976593 33.90281, -118.058918 33.846121, -118.063162 33.81961, -118.084377 33.803433, -118.096705 33.779085, -118.09197 33.758472, -118.11951 33.737064, -118.1259 33.697151, -118.237008 33.690595, -118.274239 33.663429, -118.319135 33.659547, -118.345415 33.663427, -118.466962 33.725524, -118.485577 33.753664, -118.484483 33.803154, -118.443968 33.839057, -118.447254 33.84876, -118.557356 33.987673, -118.727459 33.980307, -118.809827 33.946905, -118.841116 33.955371, -118.873998 33.983314, -118.951721 33.992858, -118.940965 34.07483, -118.788889 34.168214, -118.668152 34.168195, -118.667713 34.240404, -118.632495 34.240426, -118.636789 34.291804, -118.894634 34.817972, -118.881729 34.817802, -118.883381 34.808637, -118.870926 34.803109, -118.854114 34.803279, -118.854253 34.817772, -117.667292 34.822526, -117.667034 34.558008, -117.659994 34.55804, -117.646374 34.28917, -117.704725 34.093957))\"\n",
    "\n",
    "poly = gpd.GeoSeries.from_wkt([la_poly])[0]\n",
    "# rectangular bounding box for initial filter\n",
    "min_lon, min_lat, max_lon, max_lat = poly.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47933d",
   "metadata": {},
   "source": [
    "## How many users and records are there in this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e141b",
   "metadata": {},
   "source": [
    "## How many users and records are there in this dataset?\n",
    "\n",
    "Let's start by inspecting the schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289969e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "approx_total_records = data.rdd.countApprox(timeout=100,\n",
    "                                                confidence=0.80) \n",
    "# better than data.count( ).collect()[0]\n",
    "print(f\"Approximate total records: {approx_total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a88c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "approx_num_users = (\n",
    "    data\n",
    "    .agg(F.approx_count_distinct(\"user_id\", rsd=0.15).alias(\"approx_num_users\"))\n",
    "    .collect()[0][\"approx_num_users\"]\n",
    ")\n",
    "# better than count_distinct()\n",
    "print(f\"Approximate unique devices (user_id): {approx_num_users}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3a451",
   "metadata": {},
   "source": [
    "### We will focus on a smaller box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d5a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely as shp\n",
    "from shapely.geometry import box, LineString, Point\n",
    "import contextily as cx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# center city Philadelphia\n",
    "bbox = box(-75.1680, 39.9400, -75.1440, 39.9557)\n",
    "old_city = gpd.GeoSeries([bbox], crs=\"EPSG:4326\").to_crs(\"EPSG:3857\").iloc[0]\n",
    "\n",
    "cbgs = gpd.read_file(\"s3://ic2s2-emr-setup/tutorial-notebooks/Census_Block_Groups_2010.geojson\").to_crs(\"EPSG:3857\")\n",
    "ax = cbgs.clip(old_city).plot(figsize=(4, 4), alpha=0.4, facecolor=\"none\", linewidth=2)\n",
    "ax.set_axis_off()\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.title(\"Centery City, Philadelphia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1742829a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209ce6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nomad.filters import completeness\n",
    "\n",
    "@F.pandas_udf(\"double\")\n",
    "def completeness_udf(local_dt: pd.Series) -> float:\n",
    "    # local_dt is all the local_datetime values for one user\n",
    "    return float(completeness(\n",
    "        data=pd.to_datetime(local_dt, utc=False),\n",
    "        periods=1,\n",
    "        freq='d',\n",
    "        start=\"2020-02-01\",\n",
    "        end=\"2020-05-01\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed31344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:28:46.649275Z",
     "iopub.status.busy": "2025-07-16T16:28:46.649094Z",
     "iopub.status.idle": "2025-07-16T16:28:47.904795Z",
     "shell.execute_reply": "2025-07-16T16:28:47.904114Z",
     "shell.execute_reply.started": "2025-07-16T16:28:46.649252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 's3://catalog-pickwell/pw-full-locations25/device-visits/'\n",
    "loader.table_columns(data_path, format='csv', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ca43a",
   "metadata": {},
   "source": [
    "Spark uses **\"lazy evaluation\"**, meaning that a command like the one below doesn't actually load the data. The little execution time is to \"map\" the chunks of data to different workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995b420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_x, min_y, max_x, max_y = old_city.bounds\n",
    "date_from, date_to = [F.to_date(F.lit(s)) for s in dates]\n",
    "filtered = (\n",
    "    data\n",
    "    .filter((F.col(\"x\") >= min_x) & (F.col(\"x\") <= max_x))\n",
    "    .filter((F.col(\"y\") >= min_y) & (F.col(\"y\") <= max_y))\n",
    "    .filter(F.col(\"date\").between(\"2020-02-01\", \"2020-05-01\"))\n",
    "    .groupBy(\"user_id\")\n",
    "      .agg(completeness_udf(\"local_datetime\").alias(\"completeness\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9caf06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:28:47.906257Z",
     "iopub.status.busy": "2025-07-16T16:28:47.906009Z",
     "iopub.status.idle": "2025-07-16T16:28:51.173467Z",
     "shell.execute_reply": "2025-07-16T16:28:51.172717Z",
     "shell.execute_reply.started": "2025-07-16T16:28:47.906222Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traj = spark.read.csv(data_path, header=True, sep=\"\\t\")\n",
    "\n",
    "# We can estimate the number of records in the dataset, as well as the number of unique devices in the area of interest\n",
    "filtered = (\n",
    "    traj\n",
    "    .filter(col(\"location_method\").isin(\"gps\", \"fused\")) # remove signals with location based on WIFI\n",
    "    .filter(f\"longitude BETWEEN {min_lon} AND {max_lon}\")\n",
    "    .filter(f\"latitude  BETWEEN {min_lat} AND {max_lat}\")\n",
    ")\n",
    "\n",
    "summary = filtered.agg(\n",
    "    count(\"*\").alias(\"total_records\"),\n",
    "    approx_count_distinct(\"device_aid\", rsd=0.1)\n",
    "      .alias(\"approx_num_users\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9524c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_q = filtered.select(filtered.completeness).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc4665d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax1.hist(daily_q, bins=40)\n",
    "ax1.set_title('Completeness (d) restricted to Center City')\n",
    "ax1.set_ylabel('Number of users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73419ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5ea59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:28:51.174605Z",
     "iopub.status.busy": "2025-07-16T16:28:51.174434Z",
     "iopub.status.idle": "2025-07-16T16:41:18.705513Z",
     "shell.execute_reply": "2025-07-16T16:41:18.704610Z",
     "shell.execute_reply.started": "2025-07-16T16:28:51.174584Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# about 12 minutes with 3 core nodes!\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4c3b9",
   "metadata": {},
   "source": [
    "## Let's persist the final sample of data we will work with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e90357",
   "metadata": {},
   "source": [
    "## Phase 1: prototype on a small sample of users (can use pure python)\n",
    "\n",
    "For this we leverage `nomad.io.spark`'s `sample_users` to select 300 users at random from the polygon `poly`. We will also require that:\n",
    "- \\> 10 records for users in the sample\n",
    "- \\> 2 days in the area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e85d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This isn't working yet. Will do by hand below. \n",
    "# import nomad.io.spark as spark_loader\n",
    "# spark_loader.sample_users(\n",
    "#     data_path,\n",
    "#     format=\"csv\",\n",
    "#     size=300,\n",
    "#     within=poly,\n",
    "#     data_crs=\"EPSG:4326\",\n",
    "#     poly_crs=\"EPSG:4326\",\n",
    "#     sep=\"\\t\",\n",
    "#     user_id='device_aid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb50bdf",
   "metadata": {},
   "source": [
    "### Sample users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5390bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_users = (\n",
    "    filtered\n",
    "      .filter(F.col(\"completeness\") > 0.1)\n",
    "      .select(\"user_id\")\n",
    ")\n",
    "\n",
    "sample_data = (\n",
    "    data\n",
    "      .filter(F.col(\"date\").between(\"2020-02-01\", \"2020-05-01\"))\n",
    "      .join(sample_users, on=\"user_id\", how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2ff1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:43:27.405764Z",
     "iopub.status.busy": "2025-07-16T16:43:27.405528Z",
     "iopub.status.idle": "2025-07-16T16:43:27.655548Z",
     "shell.execute_reply": "2025-07-16T16:43:27.654753Z",
     "shell.execute_reply.started": "2025-07-16T16:43:27.405739Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_date_pings = (\n",
    "    filtered\n",
    "    .groupBy(\"device_aid\", \"date\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "active_users = (\n",
    "    user_date_pings\n",
    "    .filter(col(\"count\") > 8)\n",
    "    .groupBy(\"device_aid\")\n",
    "    .count()\n",
    "    .filter(col(\"count\") >= 2)\n",
    "    .select(\"device_aid\")\n",
    ")\n",
    "\n",
    "# Sample 0.5% of users with hash bucket approach (no shuffling!)\n",
    "sampled_users = (\n",
    "    active_users\n",
    "    .withColumn(\"_bucket\", abs(xxhash64(\"device_aid\")) % 2000)\n",
    "    .filter(col(\"_bucket\") == 0)\n",
    "    .select(\"device_aid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f56659b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:43:30.908415Z",
     "iopub.status.busy": "2025-07-16T16:43:30.908179Z",
     "iopub.status.idle": "2025-07-16T16:56:06.342720Z",
     "shell.execute_reply": "2025-07-16T16:56:06.342001Z",
     "shell.execute_reply.started": "2025-07-16T16:43:30.908389Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 12 minutes in 3 node cluster!!\n",
    "# Persist as a list (for small samples, fits in driver memory)\n",
    "sampled_users_pd = sampled_users.toPandas()  # Now a pandas DataFrame\n",
    "user_list = sampled_users_pd[\"device_aid\"].tolist()\n",
    "sampled_users_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98580697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_path = \"/tmp/temp_data/\"\n",
    "(\n",
    "    sample_data.write\n",
    "      .option(\"hiveStylePartitioning\", \"true\")\n",
    "      .partitionBy(\"date\")\n",
    "      .mode(\"overwrite\")\n",
    "      .parquet(out_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55cf04bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:56:31.374061Z",
     "iopub.status.busy": "2025-07-16T16:56:31.373832Z",
     "iopub.status.idle": "2025-07-16T16:56:31.419898Z",
     "shell.execute_reply": "2025-07-16T16:56:31.419070Z",
     "shell.execute_reply.started": "2025-07-16T16:56:31.374036Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_users_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff1c80",
   "metadata": {},
   "source": [
    "## **Radius of gyration** based on stops for this small sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd055c",
   "metadata": {},
   "source": [
    "### Join `user_list` with full trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2b0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = spark.read.parquet(out_path)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07de6a",
   "metadata": {},
   "source": [
    "### Like previously, wrap the stop_detection function in a pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d16906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nomad.stop_detection.lachesis import lachesis\n",
    "\n",
    "def _lachesis(pdf):\n",
    "    pdf = pdf.sort_values(by=['unix_timestamp'])\n",
    "    stops = lachesis(pdf, dt_max= 240, delta_roam=35,\n",
    "        complete_output = True, keep_col_names=False, timestamp = 'unix_timestamp',\n",
    "        x=\"x\", y=\"y\", user_id=\"user_id\", passthrough_cols=['tz_offset', 'local_datetime'])    \n",
    "    \n",
    "    schema_cols = [\"user_id\",\"start_timestamp\", \"end_timestamp\",\n",
    "                   \"x\", \"y\",\"n_pings\", \"max_gap\", \"duration\",\n",
    "                   \"cluster\",\"diameter\",\"local_datetime\", \"tz_offset\"]\n",
    "    if stops.empty:\n",
    "        pd.DataFrame(columns=schema_cols, dtype=object)\n",
    "    else:\n",
    "        return stops\n",
    "\n",
    "# For grouped map udfs, the syntax uses applyInPandas on a regular pandas function\n",
    "schema = (\n",
    "    f\"user_id string, \"\n",
    "    \"start_timestamp long, end_timestamp long, \"\n",
    "    \"x double, y double, \"\n",
    "    \"n_pings long, max_gap long, \"\n",
    "    \"duration long, cluster long, \"\n",
    "    \"diameter float, \"\n",
    "    \"local_datetime string, tz_offset long\"\n",
    ")\n",
    "\n",
    "stops_data = (\n",
    "    data\n",
    "    .groupBy('user_id')\n",
    "    .applyInPandas(_lachesis, schema)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4adf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_path = \"/tmp/temp_stops/\"\n",
    "(\n",
    "    stops_data.write\n",
    "      .option(\"hiveStylePartitioning\", \"true\")\n",
    "      .mode(\"overwrite\")\n",
    "      .parquet(out_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d935cd",
   "metadata": {},
   "source": [
    "### Next we compute the radius of gyration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bf8587",
   "metadata": {},
   "source": [
    "At this point the data is much smaller, and we can uncomplicate our lives by simply parallelizing a single pandas_udf computing RoGs and aggregating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b128dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.base as loader\n",
    "traj_cols = {\"datetime\":\"local_datetime\", \"user_id\":\"user_id\", \"timestamp\":\"unix_timestamp\"}\n",
    "loader.sample_from_file(out_path, format=\"parquet\", frac_users=0.2, traj_cols=traj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e829a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbgs = gpd.read_file(\"s3://ic2s2-emr-setup/tutorial-notebooks/Census_Block_Groups_2010.geojson\").to_crs(\"EPSG:3857\")\n",
    "cbgs = cbgs.rename(columns={\"GEOID10\":\"cbg\"})\n",
    "cbgs = cbgs.set_index(\"cbg\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops[\"cbg\"] = visits.point_in_polygon(\n",
    "                         data=stops,\n",
    "                         poi_table=cbgs,\n",
    "                         max_distance=0,\n",
    "                         x='x',\n",
    "                         y='y',\n",
    "                         method='centroid',\n",
    "                         data_crs='EPSG:3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_homes = homes.compute_candidate_homes(stops,\n",
    "                                           datetime=\"local_datetime\",\n",
    "                                           location_id=\"cbgs\",\n",
    "                                           user_id=\"user_id\")\n",
    "\n",
    "last_date = date(year=2020, month=6, day=1) \n",
    "home_table = homes.select_home(cand_homes, min_days=3, min_weeks=2, last_date=last_date, user_id='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute ROG join with home_table[[\"user_id\", \"cbg\"]] on 'user_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "233f887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = traj.filter(\n",
    "    (col(\"location_method\").isin(\"gps\", \"fused\")) &\n",
    "    (col(\"device_aid\").isin(user_list))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"s3://catalog-pickwell/tutorial-sample/\"\n",
    "\n",
    "filtered.write.mode(\"overwrite\").partitionBy(\"date\").parquet(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd7b3c",
   "metadata": {},
   "source": [
    "Alternatively, we can broadcast the table. This allows Spark to use a join operator instead of a filter, which can speed things up for complex queries or very large user lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867e804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:56:06.344525Z",
     "iopub.status.busy": "2025-07-16T16:56:06.344261Z",
     "iopub.status.idle": "2025-07-16T16:56:06.395459Z",
     "shell.execute_reply": "2025-07-16T16:56:06.394675Z",
     "shell.execute_reply.started": "2025-07-16T16:56:06.344490Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampled_users_spark = spark.createDataFrame([(uid,) for uid in user_list], [\"device_aid\"])\n",
    "# filtered = (\n",
    "#     traj\n",
    "#     .filter(col(\"location_method\").isin(\"gps\", \"fused\"))\n",
    "#     .join(broadcast(sampled_users_spark), on=\"device_aid\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a00e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered.toPandas() # raw dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5077a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'longitude':'longitude',\n",
    "             'latitude':'latitude',\n",
    "             'ha':'horizontal_accuracy',\n",
    "             'user_id':'device_aid',\n",
    "             'timestamp':'timestamp',\n",
    "             'date':'date'}\n",
    "\n",
    "traj = loader.from_file(df, traj_cols=traj_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab6b94",
   "metadata": {},
   "source": [
    "### Visualize completeness and filter by completeness metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f411e",
   "metadata": {},
   "source": [
    "The following code constructs a daily $Q$ matrix, which represents the completeness of user activity for each day. $q$ represents the proportion of hours in a day during which a specific user has recorded activity. A sliding window of 3 days is then applied to compute a mean completeness metric for each date in the sliding window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a83b3",
   "metadata": {},
   "source": [
    "We now visualize the number of complete users in each day for different values of completeness ($\\bar{q} = 1-\\epsilon$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dee344",
   "metadata": {},
   "source": [
    "We can use $q$ to filter users by completeness, retaining only the users who exhibit a mean completeness of over 80% in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = filters.completeness(traj, periods=1, freq='h', agg_freq='d', traj_cols=tc)\n",
    "\n",
    "Q = Q.iloc[completeness_hourly.argsort(-1)]\n",
    "Q.columns = pd.to_datetime(Q.columns)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "pcm = ax.pcolormesh(Q.columns, range(len(Q)), Q.values,               # plot matrix\n",
    "               cmap='Blues', shading='auto')\n",
    "ax.set_yticks([])\n",
    "ax.set_ylabel('User')\n",
    "ax.set_title('hourly coverage (aggregated daily)')\n",
    "\n",
    "cbar = fig.colorbar(pcm, ax=ax, orientation='vertical', label='q')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cf374",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_hourly = filters.completeness(traj, periods=1, freq='h', traj_cols=tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6fa40",
   "metadata": {},
   "source": [
    "## Part 1: LA neighborhoods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37203380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.spark as loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b79fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip1 = 'US.91001'\n",
    "wkt_poly_1 = \"POLYGON ((-118.577505 34.070578, -118.577311 34.070943, -118.578025 34.071574, -118.578235 34.072377, -118.577323 34.073198, -118.577114 34.073982, -118.578195 34.074891, -118.578632 34.075686, -118.578355 34.076989, -118.579826 34.077487, -118.580106 34.078929, -118.579752 34.079352, -118.579637 34.080475, -118.580493 34.081069, -118.582732 34.081617, -118.583276 34.082356, -118.584507 34.082632, -118.585786 34.083384, -118.585764 34.084748, -118.586535 34.085448, -118.586536 34.086198, -118.587247 34.086571, -118.58677 34.08828, -118.587505 34.089118, -118.587532 34.089858, -118.587222 34.09091, -118.585248 34.09125, -118.582463 34.093137, -118.581594 34.096281, -118.580096 34.097382, -118.580214 34.098469, -118.578385 34.100109, -118.574824 34.101449, -118.573205 34.103519, -118.570921 34.104864, -118.572187 34.106405, -118.572925 34.10673, -118.571529 34.108001, -118.569608 34.108861, -118.569797 34.109181, -118.57146 34.109321, -118.572708 34.109861, -118.573229 34.110264, -118.573444 34.110983, -118.575713 34.110794, -118.576329 34.111415, -118.564752 34.130168, -118.565316 34.130383, -118.564799 34.131111, -118.564017 34.131147, -118.563654 34.130769, -118.559995 34.129993, -118.559837 34.129382, -118.558005 34.127742, -118.557365 34.126608, -118.55661 34.126563, -118.556072 34.127197, -118.555847 34.128179, -118.554614 34.128011, -118.553816 34.128663, -118.553622 34.128247, -118.554813 34.127015, -118.554587 34.126521, -118.55356 34.126037, -118.552411 34.125968, -118.551586 34.126314, -118.549483 34.126434, -118.548086 34.125821, -118.546207 34.126079, -118.545229 34.126585, -118.54441 34.126548, -118.542059 34.127543, -118.541651 34.128931, -118.539306 34.1298, -118.539417 34.131153, -118.537802 34.131169, -118.537358 34.130637, -118.536088 34.130294, -118.535566 34.131132, -118.534757 34.13165, -118.534475 34.130163, -118.534054 34.129902, -118.533453 34.129934, -118.533261 34.130556, -118.532661 34.130953, -118.531871 34.129644, -118.528333 34.128921, -118.527129 34.128936, -118.526273 34.128558, -118.523056 34.12842, -118.52182 34.127995, -118.520718 34.128742, -118.518977 34.129031, -118.518817 34.12719, -118.517541 34.126212, -118.516463 34.122708, -118.517012 34.121477, -118.518829 34.120731, -118.520654 34.118862, -118.521475 34.117544, -118.520756 34.113642, -118.520941 34.11258, -118.520459 34.111623, -118.52144 34.103825, -118.520682 34.099877, -118.519322 34.098107, -118.519554 34.096293, -118.519118 34.096042, -118.519449 34.094067, -118.518732 34.089604, -118.51893 34.088747, -118.517583 34.08691, -118.516132 34.08264, -118.514256 34.081985, -118.512454 34.080246, -118.51184 34.078081, -118.510553 34.076701, -118.509813 34.074894, -118.509692 34.074239, -118.512761 34.072282, -118.512287 34.072207, -118.512172 34.071862, -118.511363 34.071779, -118.511425 34.071109, -118.510444 34.070519, -118.510178 34.069941, -118.508211 34.069043, -118.507643 34.068061, -118.505358 34.066724, -118.505229 34.065926, -118.504764 34.065503, -118.505257 34.065182, -118.50531 34.064287, -118.504187 34.066151, -118.504805 34.066912, -118.504167 34.067457, -118.503338 34.066617, -118.502849 34.067435, -118.502536 34.067061, -118.501053 34.066679, -118.498753 34.064608, -118.496606 34.064071, -118.495258 34.062439, -118.495237 34.060384, -118.496146 34.056388, -118.498813 34.054499, -118.499837 34.053025, -118.49987 34.051556, -118.499288 34.051668, -118.499171 34.051086, -118.496229 34.050223, -118.497398 34.048466, -118.496873 34.04807, -118.503965 34.040724, -118.50458 34.041293, -118.50731 34.040196, -118.509355 34.041402, -118.510044 34.041046, -118.51365 34.033646, -118.51509 34.033061, -118.515773 34.034498, -118.515271 34.034902, -118.515373 34.035598, -118.513348 34.037548, -118.512309 34.039885, -118.51281 34.040538, -118.512267 34.040954, -118.513405 34.042344, -118.514166 34.040952, -118.514098 34.03994, -118.515321 34.040444, -118.515424 34.041355, -118.513951 34.043227, -118.514238 34.04341, -118.515865 34.043106, -118.515872 34.044137, -118.514433 34.044926, -118.514964 34.045563, -118.516503 34.044656, -118.517201 34.041847, -118.51751 34.041447, -118.518212 34.041304, -118.518216 34.038508, -118.519633 34.034701, -118.519062 34.031548, -118.518866 34.031382, -118.518374 34.03203, -118.51712 34.031047, -118.51805 34.030434, -118.517867 34.03004, -118.51892 34.029219, -118.52009 34.026898, -118.521865 34.024999, -118.52219 34.025361, -118.523872 34.025804, -118.527945 34.028254, -118.531388 34.029714, -118.531577 34.02957, -118.542552 34.034927, -118.546074 34.036308, -118.550209 34.036712, -118.55249 34.036126, -118.55359 34.035383, -118.554565 34.035161, -118.556773 34.035276, -118.567251 34.038401, -118.566901 34.041193, -118.570107 34.047117, -118.570395 34.069346, -118.577505 34.070578))\"\n",
    "\n",
    "zip2 = 'US.90272'\n",
    "wkt_poly_2 = \"POLYGON ((-118.10042 34.190442, -118.101043 34.189947, -118.102033 34.189938, -118.10214 34.190687, -118.102616 34.190745, -118.10418 34.193334, -118.104845 34.193386, -118.105857 34.192597, -118.104588 34.190708, -118.104922 34.190323, -118.104859 34.189209, -118.103843 34.187929, -118.103586 34.186584, -118.103049 34.186653, -118.103204 34.186478, -118.102138 34.185187, -118.102439 34.184923, -118.100395 34.183328, -118.100288 34.180371, -118.098256 34.175685, -118.094998 34.175635, -118.095553 34.174225, -118.099342 34.174642, -118.104152 34.174968, -118.10426 34.174641, -118.105069 34.174489, -118.10747 34.174937, -118.109831 34.176132, -118.10997 34.176735, -118.110546 34.177045, -118.110461 34.17761, -118.112069 34.178538, -118.113155 34.177886, -118.115871 34.178128, -118.115889 34.178516, -118.118104 34.1785, -118.118361 34.177967, -118.120271 34.177823, -118.121562 34.178098, -118.121515 34.17848, -118.129664 34.178418, -118.129661 34.177154, -118.132061 34.177026, -118.142202 34.181565, -118.146251 34.181539, -118.164115 34.181436, -118.164082 34.178405, -118.164363 34.17769, -118.169043 34.181078, -118.168984 34.181328, -118.169593 34.181432, -118.170614 34.184858, -118.170279 34.185925, -118.169714 34.18548, -118.168734 34.185445, -118.168722 34.18919, -118.17172 34.189287, -118.170609 34.190122, -118.17052 34.191134, -118.169218 34.192461, -118.168592 34.190674, -118.168582 34.188804, -118.167491 34.188809, -118.167506 34.190535, -118.166872 34.190256, -118.166503 34.191233, -118.168528 34.192094, -118.168455 34.19325, -118.166489 34.196811, -118.165452 34.199835, -118.165232 34.201869, -118.166022 34.203841, -118.165814 34.205321, -118.166499 34.206284, -118.168089 34.207092, -118.168152 34.208164, -118.16974 34.208934, -118.170035 34.209388, -118.169366 34.210486, -118.168476 34.210949, -118.170064 34.210554, -118.170438 34.211009, -118.170245 34.211236, -118.169729 34.210953, -118.169661 34.211363, -118.168951 34.211378, -118.169855 34.212445, -118.168725 34.212796, -118.168264 34.213539, -118.167281 34.214094, -118.166865 34.215406, -118.167842 34.215146, -118.168516 34.215978, -118.166874 34.216465, -118.167398 34.217157, -118.166058 34.217743, -118.16583 34.218153, -118.166317 34.217177, -118.16601 34.216686, -118.165583 34.216714, -118.164397 34.217798, -118.160475 34.216922, -118.160514 34.217649, -118.159592 34.217411, -118.158433 34.217884, -118.157665 34.219597, -118.155657 34.219321, -118.155431 34.218879, -118.154058 34.219258, -118.153232 34.219851, -118.150977 34.219911, -118.15104 34.219309, -118.150493 34.219026, -118.149774 34.219148, -118.148117 34.217424, -118.147335 34.217169, -118.145125 34.217327, -118.145936 34.215933, -118.148954 34.215853, -118.150206 34.216436, -118.150639 34.216131, -118.150392 34.215828, -118.148859 34.215148, -118.136227 34.21453, -118.117895 34.204116, -118.106823 34.195829, -118.104808 34.194856, -118.104807 34.196844, -118.10048 34.196844, -118.10042 34.190442))\"\n",
    "\n",
    "zips_poly = gpd.GeoSeries.from_wkt([wkt_poly_1, wkt_poly_2]).unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034a0ff",
   "metadata": {},
   "source": [
    "### Part 2: LA county (continental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_3 = '06037' #LA COUNTY\n",
    "wkt_poly_3 = \"POLYGON ((-117.704725 34.093957, -117.730125 34.021371, -117.76769 34.023506, -117.767483 34.004611, -117.785062 34.004809, -117.802539 33.975551, -117.783287 33.946411, -117.976498 33.94605, -117.976593 33.90281, -118.058918 33.846121, -118.063162 33.81961, -118.084377 33.803433, -118.096705 33.779085, -118.09197 33.758472, -118.11951 33.737064, -118.1259 33.697151, -118.237008 33.690595, -118.274239 33.663429, -118.319135 33.659547, -118.345415 33.663427, -118.466962 33.725524, -118.485577 33.753664, -118.484483 33.803154, -118.443968 33.839057, -118.447254 33.84876, -118.557356 33.987673, -118.727459 33.980307, -118.809827 33.946905, -118.841116 33.955371, -118.873998 33.983314, -118.951721 33.992858, -118.940965 34.07483, -118.788889 34.168214, -118.668152 34.168195, -118.667713 34.240404, -118.632495 34.240426, -118.636789 34.291804, -118.894634 34.817972, -118.881729 34.817802, -118.883381 34.808637, -118.870926 34.803109, -118.854114 34.803279, -118.854253 34.817772, -117.667292 34.822526, -117.667034 34.558008, -117.659994 34.55804, -117.646374 34.28917, -117.704725 34.093957))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0c764",
   "metadata": {},
   "source": [
    "### Part 3: Ithaca NY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_4 = '36109' #TOMKINS COUNTY\n",
    "wkt_poly_4 = 'POLYGON ((-76.492989 42.281166, -76.691406 42.284307, -76.685726 42.375108, -76.696655 42.54679, -76.585989 42.54991, -76.626761 42.573868, -76.666543 42.623457, -76.265584 42.623588, -76.253359 42.407568, -76.293168 42.406572, -76.299641 42.384546, -76.239854 42.35987, -76.250149 42.296676, -76.288174 42.296764, -76.28822 42.308227, -76.350619 42.308437, -76.350871 42.318288, -76.415305 42.318368, -76.416284 42.262977, -76.474494 42.263761, -76.473962 42.281132, -76.492989 42.281166))'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9409778",
   "metadata": {},
   "source": [
    "## Data ingestion using base Nomad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff46ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.base as loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2913af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 's3://catalog-pickwell/pw-full-locations25/device-visits/geography_id_1=US/date=2025-04-22/'\n",
    "loader.table_columns(data_path, format='csv', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0011e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'longitude':'longitude',\n",
    "             'latitude':'latitude',\n",
    "             'ha':'horizontal_accuracy',\n",
    "             'user_id':'device_aid',\n",
    "             'timestamp':'timestamp',\n",
    "             'date':'date'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f63ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = loader.sample_users(data_path, format='csv', size=0.1, within=zips_poly, data_crs=\"EPSG:4326\", poly_crs=\"EPSG:4326\", sep=\"\\t\", traj_cols=traj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9436033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5063bc7e",
   "metadata": {},
   "source": [
    "### Visualize completeness and filter by completeness metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e176e4",
   "metadata": {},
   "source": [
    "The following code constructs a daily $Q$ matrix, which represents the completeness of user activity for each day. $q$ represents the proportion of hours in a day during which a specific user has recorded activity. A sliding window of 3 days is then applied to compute a mean completeness metric for each date in the sliding window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe266c1",
   "metadata": {},
   "source": [
    "We now visualize the number of complete users in each day for different values of completeness ($\\bar{q} = 1-\\epsilon$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4cf44",
   "metadata": {},
   "source": [
    "We can use $q$ to filter users by completeness, retaining only the users who exhibit a mean completeness of over 80% in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec91079a",
   "metadata": {},
   "source": [
    "# **Tutorial 5: Scaling up with Pyspark** \n",
    "\n",
    "In this section of the tutorial, we demonstrate how to process a much larger mobility dataset using nomad's software in a Spark cluster. Our target application will be to produce mobility metrics, aggregated at the neighborhood level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477e3ec",
   "metadata": {},
   "source": [
    "## Configure your Spark cluster with SparkMagic\n",
    "\n",
    "The EMR cluster for this demonstration has 1 master node (`m5.xlarge`, 4 vCPU, 16 GiB RAM) and 3 core nodes (`c5.4xlarge`, each with 16 vCPU and 32 GiB RAM). That gives us a total of 48 vCPUs across the workers.\n",
    "\n",
    "These resources are divided between a **driver** and multiple **executors**:\n",
    "- The **driver** runs inside the notebook. It coordinates the job, tracks task progress, and collects results.\n",
    "- The **executors** are distributed processes that perform actual computations on the worker nodes.\n",
    "\n",
    "We configure the cluster so that:\n",
    "- Each executor uses 4 vCPUs and ~5 GB of memory,\n",
    "- This fits 4 executors per core node (3 nodes × 4 = 12 total executors),\n",
    "- Giving us 48 total executor cores — fully using the cluster's compute capacity.\n",
    "\n",
    "We also allocate 8 GB of memory to the driver, which often needs to receive and process shuffled or aggregated data from the executors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442dafba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\"conf\":\n",
    "     {\"spark.pyspark.python\":\"/home/hadoop/nomad-venv/bin/python3\",\n",
    "      \"spark.pyspark.virtualenv.bin.path\":\"/home/hadoop/nomad-venv/bin\",\n",
    "      \"spark.driver.memory\": \"8g\",\n",
    "      \"spark.driver.maxResultSize\": \"7g\",\n",
    "      \"spark.executor.memory\": \"4900m\",\n",
    "      \"spark.executor.cores\": \"4\", \n",
    "      \"spark.executor.instances\": \"16\", \n",
    "      \"spark.dynamicAllocation.enabled\": \"false\",\n",
    "      \"spark.yarn.heterogeneousExecutors.enabled\": \"false\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore your spark session\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6584435",
   "metadata": {},
   "source": [
    "## Load Geometry Data\n",
    "\n",
    "Let's first explore a sample of data corresponding to the county of Los Angeles, in California. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6872c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.base as loader\n",
    "from pyspark.sql.functions import col, count, approx_count_distinct\n",
    "import geopandas as gpd\n",
    "\n",
    "la_fips = '06037' #LA COUNTY\n",
    "la_poly = \"POLYGON ((-117.704725 34.093957, -117.730125 34.021371, -117.76769 34.023506, -117.767483 34.004611, -117.785062 34.004809, -117.802539 33.975551, -117.783287 33.946411, -117.976498 33.94605, -117.976593 33.90281, -118.058918 33.846121, -118.063162 33.81961, -118.084377 33.803433, -118.096705 33.779085, -118.09197 33.758472, -118.11951 33.737064, -118.1259 33.697151, -118.237008 33.690595, -118.274239 33.663429, -118.319135 33.659547, -118.345415 33.663427, -118.466962 33.725524, -118.485577 33.753664, -118.484483 33.803154, -118.443968 33.839057, -118.447254 33.84876, -118.557356 33.987673, -118.727459 33.980307, -118.809827 33.946905, -118.841116 33.955371, -118.873998 33.983314, -118.951721 33.992858, -118.940965 34.07483, -118.788889 34.168214, -118.668152 34.168195, -118.667713 34.240404, -118.632495 34.240426, -118.636789 34.291804, -118.894634 34.817972, -118.881729 34.817802, -118.883381 34.808637, -118.870926 34.803109, -118.854114 34.803279, -118.854253 34.817772, -117.667292 34.822526, -117.667034 34.558008, -117.659994 34.55804, -117.646374 34.28917, -117.704725 34.093957))\"\n",
    "\n",
    "poly = gpd.GeoSeries.from_wkt([la_poly])[0]\n",
    "# rectangular bounding box for initial filter\n",
    "min_lon, min_lat, max_lon, max_lat = poly.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4cba5",
   "metadata": {},
   "source": [
    "## Part 1: LA neighborhoods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb51c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 's3://catalog-pickwell/pw-full-locations25/device-visits/geography_id_1=US/date=2025-04-22/'\n",
    "loader.table_columns(data_path, format='csv', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63953eda",
   "metadata": {},
   "source": [
    "Spark uses \"lazy loading\", meaning that a command like this doesn't actually load the data. It just maps it for later execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e747cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(data_path)\n",
    "\n",
    "# We can estimate the number of records in the dataset, as well as the number of unique devices (all of the US)\n",
    "filtered = traj.filter(col(\"location_method\").isin(\"gps\", \"fused\")).where(f\"longitude BETWEEN {min_lon} AND {max_lon} AND latitude BETWEEN {min_lat} AND {max_lat}\")\n",
    "summary = filtered.agg(\n",
    "    count(\"*\").alias(\"total_records\"),\n",
    "    # relative standard deviation (rsd) controls accuracy; smaller → more memory\n",
    "    approx_count_distinct(\"device_aid\", rsd=0.1)\n",
    "      .alias(\"approx_num_users\")\n",
    ")\n",
    "\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd655d16",
   "metadata": {},
   "source": [
    "## For now, we prototype on only a small sample of our geography of interest\n",
    "\n",
    "For this we leverage `nomad.io.spark`'s `sample_users` to select 300 users at random from the polygon `poly`. We will also require that:\n",
    "- \\> 10 records for users in the sample\n",
    "- \\> 2 days in the area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49114ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.spark as spark_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b206b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_loader.sample_users(\n",
    "    data_path,\n",
    "    format=\"csv\",\n",
    "    size=300,\n",
    "    within=poly,\n",
    "    data_crs=\"EPSG:4326\",\n",
    "    poly_crs=\"EPSG:4326\",\n",
    "    sep=\"\\t\",\n",
    "    user_id='device_aid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = traj.filter(col(\"location_method\").isin(\"gps\", \"fused\")).where(f\"longitude BETWEEN {min_lon} AND {max_lon} AND latitude BETWEEN {min_lat} AND {max_lat}\")\n",
    "df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5810fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df.device_aid.value_counts().loc[lambda s: s>20].iloc[:200].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'longitude':'longitude',\n",
    "             'latitude':'latitude',\n",
    "             'ha':'horizontal_accuracy',\n",
    "             'user_id':'device_aid',\n",
    "             'timestamp':'timestamp',\n",
    "             'date':'date'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = loader.sample_users(data_path, format='csv', size=0.1, within=zips_poly, data_crs=\"EPSG:4326\", poly_crs=\"EPSG:4326\", sep=\"\\t\", traj_cols=traj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd029e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13fa9914",
   "metadata": {},
   "source": [
    "### Visualize completeness and filter by completeness metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84eb444",
   "metadata": {},
   "source": [
    "The following code constructs a daily $Q$ matrix, which represents the completeness of user activity for each day. $q$ represents the proportion of hours in a day during which a specific user has recorded activity. A sliding window of 3 days is then applied to compute a mean completeness metric for each date in the sliding window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a03bce",
   "metadata": {},
   "source": [
    "We now visualize the number of complete users in each day for different values of completeness ($\\bar{q} = 1-\\epsilon$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd254e7",
   "metadata": {},
   "source": [
    "We can use $q$ to filter users by completeness, retaining only the users who exhibit a mean completeness of over 80% in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37613e4c",
   "metadata": {},
   "source": [
    "## Part 1: LA neighborhoods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.spark as loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip1 = 'US.91001'\n",
    "wkt_poly_1 = \"POLYGON ((-118.577505 34.070578, -118.577311 34.070943, -118.578025 34.071574, -118.578235 34.072377, -118.577323 34.073198, -118.577114 34.073982, -118.578195 34.074891, -118.578632 34.075686, -118.578355 34.076989, -118.579826 34.077487, -118.580106 34.078929, -118.579752 34.079352, -118.579637 34.080475, -118.580493 34.081069, -118.582732 34.081617, -118.583276 34.082356, -118.584507 34.082632, -118.585786 34.083384, -118.585764 34.084748, -118.586535 34.085448, -118.586536 34.086198, -118.587247 34.086571, -118.58677 34.08828, -118.587505 34.089118, -118.587532 34.089858, -118.587222 34.09091, -118.585248 34.09125, -118.582463 34.093137, -118.581594 34.096281, -118.580096 34.097382, -118.580214 34.098469, -118.578385 34.100109, -118.574824 34.101449, -118.573205 34.103519, -118.570921 34.104864, -118.572187 34.106405, -118.572925 34.10673, -118.571529 34.108001, -118.569608 34.108861, -118.569797 34.109181, -118.57146 34.109321, -118.572708 34.109861, -118.573229 34.110264, -118.573444 34.110983, -118.575713 34.110794, -118.576329 34.111415, -118.564752 34.130168, -118.565316 34.130383, -118.564799 34.131111, -118.564017 34.131147, -118.563654 34.130769, -118.559995 34.129993, -118.559837 34.129382, -118.558005 34.127742, -118.557365 34.126608, -118.55661 34.126563, -118.556072 34.127197, -118.555847 34.128179, -118.554614 34.128011, -118.553816 34.128663, -118.553622 34.128247, -118.554813 34.127015, -118.554587 34.126521, -118.55356 34.126037, -118.552411 34.125968, -118.551586 34.126314, -118.549483 34.126434, -118.548086 34.125821, -118.546207 34.126079, -118.545229 34.126585, -118.54441 34.126548, -118.542059 34.127543, -118.541651 34.128931, -118.539306 34.1298, -118.539417 34.131153, -118.537802 34.131169, -118.537358 34.130637, -118.536088 34.130294, -118.535566 34.131132, -118.534757 34.13165, -118.534475 34.130163, -118.534054 34.129902, -118.533453 34.129934, -118.533261 34.130556, -118.532661 34.130953, -118.531871 34.129644, -118.528333 34.128921, -118.527129 34.128936, -118.526273 34.128558, -118.523056 34.12842, -118.52182 34.127995, -118.520718 34.128742, -118.518977 34.129031, -118.518817 34.12719, -118.517541 34.126212, -118.516463 34.122708, -118.517012 34.121477, -118.518829 34.120731, -118.520654 34.118862, -118.521475 34.117544, -118.520756 34.113642, -118.520941 34.11258, -118.520459 34.111623, -118.52144 34.103825, -118.520682 34.099877, -118.519322 34.098107, -118.519554 34.096293, -118.519118 34.096042, -118.519449 34.094067, -118.518732 34.089604, -118.51893 34.088747, -118.517583 34.08691, -118.516132 34.08264, -118.514256 34.081985, -118.512454 34.080246, -118.51184 34.078081, -118.510553 34.076701, -118.509813 34.074894, -118.509692 34.074239, -118.512761 34.072282, -118.512287 34.072207, -118.512172 34.071862, -118.511363 34.071779, -118.511425 34.071109, -118.510444 34.070519, -118.510178 34.069941, -118.508211 34.069043, -118.507643 34.068061, -118.505358 34.066724, -118.505229 34.065926, -118.504764 34.065503, -118.505257 34.065182, -118.50531 34.064287, -118.504187 34.066151, -118.504805 34.066912, -118.504167 34.067457, -118.503338 34.066617, -118.502849 34.067435, -118.502536 34.067061, -118.501053 34.066679, -118.498753 34.064608, -118.496606 34.064071, -118.495258 34.062439, -118.495237 34.060384, -118.496146 34.056388, -118.498813 34.054499, -118.499837 34.053025, -118.49987 34.051556, -118.499288 34.051668, -118.499171 34.051086, -118.496229 34.050223, -118.497398 34.048466, -118.496873 34.04807, -118.503965 34.040724, -118.50458 34.041293, -118.50731 34.040196, -118.509355 34.041402, -118.510044 34.041046, -118.51365 34.033646, -118.51509 34.033061, -118.515773 34.034498, -118.515271 34.034902, -118.515373 34.035598, -118.513348 34.037548, -118.512309 34.039885, -118.51281 34.040538, -118.512267 34.040954, -118.513405 34.042344, -118.514166 34.040952, -118.514098 34.03994, -118.515321 34.040444, -118.515424 34.041355, -118.513951 34.043227, -118.514238 34.04341, -118.515865 34.043106, -118.515872 34.044137, -118.514433 34.044926, -118.514964 34.045563, -118.516503 34.044656, -118.517201 34.041847, -118.51751 34.041447, -118.518212 34.041304, -118.518216 34.038508, -118.519633 34.034701, -118.519062 34.031548, -118.518866 34.031382, -118.518374 34.03203, -118.51712 34.031047, -118.51805 34.030434, -118.517867 34.03004, -118.51892 34.029219, -118.52009 34.026898, -118.521865 34.024999, -118.52219 34.025361, -118.523872 34.025804, -118.527945 34.028254, -118.531388 34.029714, -118.531577 34.02957, -118.542552 34.034927, -118.546074 34.036308, -118.550209 34.036712, -118.55249 34.036126, -118.55359 34.035383, -118.554565 34.035161, -118.556773 34.035276, -118.567251 34.038401, -118.566901 34.041193, -118.570107 34.047117, -118.570395 34.069346, -118.577505 34.070578))\"\n",
    "\n",
    "zip2 = 'US.90272'\n",
    "wkt_poly_2 = \"POLYGON ((-118.10042 34.190442, -118.101043 34.189947, -118.102033 34.189938, -118.10214 34.190687, -118.102616 34.190745, -118.10418 34.193334, -118.104845 34.193386, -118.105857 34.192597, -118.104588 34.190708, -118.104922 34.190323, -118.104859 34.189209, -118.103843 34.187929, -118.103586 34.186584, -118.103049 34.186653, -118.103204 34.186478, -118.102138 34.185187, -118.102439 34.184923, -118.100395 34.183328, -118.100288 34.180371, -118.098256 34.175685, -118.094998 34.175635, -118.095553 34.174225, -118.099342 34.174642, -118.104152 34.174968, -118.10426 34.174641, -118.105069 34.174489, -118.10747 34.174937, -118.109831 34.176132, -118.10997 34.176735, -118.110546 34.177045, -118.110461 34.17761, -118.112069 34.178538, -118.113155 34.177886, -118.115871 34.178128, -118.115889 34.178516, -118.118104 34.1785, -118.118361 34.177967, -118.120271 34.177823, -118.121562 34.178098, -118.121515 34.17848, -118.129664 34.178418, -118.129661 34.177154, -118.132061 34.177026, -118.142202 34.181565, -118.146251 34.181539, -118.164115 34.181436, -118.164082 34.178405, -118.164363 34.17769, -118.169043 34.181078, -118.168984 34.181328, -118.169593 34.181432, -118.170614 34.184858, -118.170279 34.185925, -118.169714 34.18548, -118.168734 34.185445, -118.168722 34.18919, -118.17172 34.189287, -118.170609 34.190122, -118.17052 34.191134, -118.169218 34.192461, -118.168592 34.190674, -118.168582 34.188804, -118.167491 34.188809, -118.167506 34.190535, -118.166872 34.190256, -118.166503 34.191233, -118.168528 34.192094, -118.168455 34.19325, -118.166489 34.196811, -118.165452 34.199835, -118.165232 34.201869, -118.166022 34.203841, -118.165814 34.205321, -118.166499 34.206284, -118.168089 34.207092, -118.168152 34.208164, -118.16974 34.208934, -118.170035 34.209388, -118.169366 34.210486, -118.168476 34.210949, -118.170064 34.210554, -118.170438 34.211009, -118.170245 34.211236, -118.169729 34.210953, -118.169661 34.211363, -118.168951 34.211378, -118.169855 34.212445, -118.168725 34.212796, -118.168264 34.213539, -118.167281 34.214094, -118.166865 34.215406, -118.167842 34.215146, -118.168516 34.215978, -118.166874 34.216465, -118.167398 34.217157, -118.166058 34.217743, -118.16583 34.218153, -118.166317 34.217177, -118.16601 34.216686, -118.165583 34.216714, -118.164397 34.217798, -118.160475 34.216922, -118.160514 34.217649, -118.159592 34.217411, -118.158433 34.217884, -118.157665 34.219597, -118.155657 34.219321, -118.155431 34.218879, -118.154058 34.219258, -118.153232 34.219851, -118.150977 34.219911, -118.15104 34.219309, -118.150493 34.219026, -118.149774 34.219148, -118.148117 34.217424, -118.147335 34.217169, -118.145125 34.217327, -118.145936 34.215933, -118.148954 34.215853, -118.150206 34.216436, -118.150639 34.216131, -118.150392 34.215828, -118.148859 34.215148, -118.136227 34.21453, -118.117895 34.204116, -118.106823 34.195829, -118.104808 34.194856, -118.104807 34.196844, -118.10048 34.196844, -118.10042 34.190442))\"\n",
    "\n",
    "zips_poly = gpd.GeoSeries.from_wkt([wkt_poly_1, wkt_poly_2]).unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1600f",
   "metadata": {},
   "source": [
    "### Part 2: LA county (continental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d386cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_3 = '06037' #LA COUNTY\n",
    "wkt_poly_3 = \"POLYGON ((-117.704725 34.093957, -117.730125 34.021371, -117.76769 34.023506, -117.767483 34.004611, -117.785062 34.004809, -117.802539 33.975551, -117.783287 33.946411, -117.976498 33.94605, -117.976593 33.90281, -118.058918 33.846121, -118.063162 33.81961, -118.084377 33.803433, -118.096705 33.779085, -118.09197 33.758472, -118.11951 33.737064, -118.1259 33.697151, -118.237008 33.690595, -118.274239 33.663429, -118.319135 33.659547, -118.345415 33.663427, -118.466962 33.725524, -118.485577 33.753664, -118.484483 33.803154, -118.443968 33.839057, -118.447254 33.84876, -118.557356 33.987673, -118.727459 33.980307, -118.809827 33.946905, -118.841116 33.955371, -118.873998 33.983314, -118.951721 33.992858, -118.940965 34.07483, -118.788889 34.168214, -118.668152 34.168195, -118.667713 34.240404, -118.632495 34.240426, -118.636789 34.291804, -118.894634 34.817972, -118.881729 34.817802, -118.883381 34.808637, -118.870926 34.803109, -118.854114 34.803279, -118.854253 34.817772, -117.667292 34.822526, -117.667034 34.558008, -117.659994 34.55804, -117.646374 34.28917, -117.704725 34.093957))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912266b9",
   "metadata": {},
   "source": [
    "### Part 3: Ithaca NY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_4 = '36109' #TOMKINS COUNTY\n",
    "wkt_poly_4 = 'POLYGON ((-76.492989 42.281166, -76.691406 42.284307, -76.685726 42.375108, -76.696655 42.54679, -76.585989 42.54991, -76.626761 42.573868, -76.666543 42.623457, -76.265584 42.623588, -76.253359 42.407568, -76.293168 42.406572, -76.299641 42.384546, -76.239854 42.35987, -76.250149 42.296676, -76.288174 42.296764, -76.28822 42.308227, -76.350619 42.308437, -76.350871 42.318288, -76.415305 42.318368, -76.416284 42.262977, -76.474494 42.263761, -76.473962 42.281132, -76.492989 42.281166))'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25e130",
   "metadata": {},
   "source": [
    "## Data ingestion using base Nomad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f691aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d985b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.base as loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 's3://catalog-pickwell/pw-full-locations25/device-visits/geography_id_1=US/date=2025-04-22/'\n",
    "loader.table_columns(data_path, format='csv', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'longitude':'longitude',\n",
    "             'latitude':'latitude',\n",
    "             'ha':'horizontal_accuracy',\n",
    "             'user_id':'device_aid',\n",
    "             'timestamp':'timestamp',\n",
    "             'date':'date'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb13316",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = loader.sample_users(data_path, format='csv', size=0.1, within=zips_poly, data_crs=\"EPSG:4326\", poly_crs=\"EPSG:4326\", sep=\"\\t\", traj_cols=traj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46926041",
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1e5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "691d4c5c",
   "metadata": {},
   "source": [
    "### Visualize completeness and filter by completeness metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada579fb",
   "metadata": {},
   "source": [
    "The following code constructs a daily $Q$ matrix, which represents the completeness of user activity for each day. $q$ represents the proportion of hours in a day during which a specific user has recorded activity. A sliding window of 3 days is then applied to compute a mean completeness metric for each date in the sliding window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb7700",
   "metadata": {},
   "source": [
    "We now visualize the number of complete users in each day for different values of completeness ($\\bar{q} = 1-\\epsilon$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b384e35",
   "metadata": {},
   "source": [
    "We can use $q$ to filter users by completeness, retaining only the users who exhibit a mean completeness of over 80% in the sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51384400",
   "metadata": {},
   "source": [
    "# **Tutorial 5: Scaling up with Pyspark** \n",
    "\n",
    "In this section of the tutorial, we demonstrate how to process a much larger mobility dataset using nomad's software in a Spark cluster. We begin with a fundamental demonstration of how Spark's optimized execution plan works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc4b0b-a172-4a81-a60d-5896fb8b2b19",
   "metadata": {},
   "source": [
    "## Configure the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf35bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder \n",
    "\t.master(\"local[3]\") \n",
    "\t.appName(\"My local cluster\")\n",
    "\t.config(\"spark.driver.memory\", \"3g\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"7g\")\n",
    "\t.config(\"spark.executor.memory\", \"4g\")\n",
    "    .config(\"spark.executor.cores\", \"3\")\n",
    "    .config(\"spark.jars.packages\",\n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4,\"\n",
    "            \"com.amazonaws:aws-java-sdk-bundle:1.12.633\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "              \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\")\n",
    "\t.getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78d2bd-8db5-4173-8a39-32ac0807d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Need to use a specific virtual environment with python 3.9\n",
    "# # — ensure both driver and executors use the same Python binary —\n",
    "# os.environ[\"PYSPARK_DRIVER_PYTHON\"] = r\"C:\\Users\\pacob\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\"\n",
    "# os.environ[\"PYSPARK_PYTHON\"]        = r\"C:\\Users\\pacob\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625bd35-a435-4f01-b197-82fd689514b4",
   "metadata": {},
   "source": [
    "## A not-too-irrelevant toy problem: intersecting time intervals\n",
    "\n",
    "A large number of events := `(event_id, start_datetime, end_datetime)` need to be compared to find the pairs that intersect. \n",
    "- Events are all under 2 hours long\n",
    "- Simple sorting can be a bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d9a5f1-1779-4377-87bf-2e59176100fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509afeda-0392-4010-8b9e-eea163c7943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25_000_000\n",
    "parts = 250\n",
    "sec_in_3_weeks = 3 * 7 * 24 * 3600\n",
    "a_totally_normal_day = int(dt.datetime(2021, 1, 6).timestamp())\n",
    "\n",
    "events = (spark.range(N, numPartitions=parts)\n",
    "          # seconds offset into a 7‑day window\n",
    "          .withColumn(\"offset\", (F.rand() * sec_in_3_weeks).cast(\"int\"))\n",
    "          # duration drawn from [60s, 7200s] 1min to 2 hours\n",
    "          .withColumn(\"duration\", (F.rand() * 7140 + 60).cast(\"int\"))\n",
    "          .withColumn(\"start\", F.from_unixtime(a_totally_normal_day + F.col(\"offset\")).cast(\"timestamp\"))\n",
    "          .withColumn(\"end\",   F.from_unixtime(a_totally_normal_day + F.col(\"offset\") + F.col(\"duration\")).cast(\"timestamp\"))\n",
    "          .select(\"id\", \"start\", \"end\")\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553dd7d-0dab-43c7-8532-9aa95809571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.show(5, truncate=False)\n",
    "print(f\"Initial partitions: {events.rdd.getNumPartitions()}\")\n",
    "\n",
    "print(\"Rows in first ten partitions:\",\n",
    "      events.rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bada7-216c-4c24-bbea-878c4e11137e",
   "metadata": {},
   "source": [
    "### Map the problem to buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf14af2-90c9-42e4-b92d-3cac6e7433fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketed = (events.withColumn(\"bucket\",\n",
    "                F.explode(\n",
    "                    F.array(\n",
    "                        F.floor(F.unix_timestamp(\"start\")/3600),\n",
    "                        F.floor(F.unix_timestamp(\"end\")  /3600)\n",
    "                    )))\n",
    "            .repartition(\"bucket\")) # <<< SHUFFLE\n",
    "\n",
    "# No execution yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514c5ff-b192-47ea-9c20-24632ffd2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ee200-5dc0-407f-9fbc-0b8c1730cb49",
   "metadata": {},
   "source": [
    "### Each chunk of data can be processed with a custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc36a6e-2ece-4890-9286-5c124cb1620f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "def find_overlaps(pdf):\n",
    "    ids = pdf[\"id\"].values\n",
    "    starts = pdf[\"start\"].values\n",
    "    ends = pdf[\"end\"].values\n",
    "\n",
    "    pairs = []\n",
    "    n = len(ids)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if starts[i] <= ends[j] and starts[j] <= ends[i]:\n",
    "                pairs.append((int(ids[i]), int(ids[j])))\n",
    "    return pd.DataFrame(pairs, columns=[\"e1\", \"e2\"])\n",
    "\n",
    "overlaps = bucketed.groupby(\"bucket\").applyInPandas(find_overlaps, \"e1 int, e2 int\").dropDuplicates([\"e1\",\"e2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415618e1-b6e0-461b-ac09-9d8ee51428d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overlaps.explain())  \n",
    "print(overlaps.limit(1000).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67facc5-d5aa-45e2-84c5-4aa3dea4f2ec",
   "metadata": {},
   "source": [
    "## Large Scale Mobility Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9fb883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'device_aid', 'device_aid_type', 'latitude', 'longitude',\n",
       "       'horizontal_accuracy', 'altitude', 'altitude_accuracy',\n",
       "       'location_method', 'ip', 'user_agent', 'OS', 'OS_version',\n",
       "       'manufacturer', 'model', 'carrier', 'geography_id_1', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nomad.io.base as loader\n",
    "data_path = 's3://catalog-pickwell/tutorial-sample/'\n",
    "loader.table_columns(data_path, format='parquet', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5f7ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_aid</th>\n",
       "      <th>device_aid_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>horizontal_accuracy</th>\n",
       "      <th>altitude</th>\n",
       "      <th>altitude_accuracy</th>\n",
       "      <th>location_method</th>\n",
       "      <th>ip</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>OS</th>\n",
       "      <th>OS_version</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>carrier</th>\n",
       "      <th>geography_id_1</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1745290992</td>\n",
       "      <td>787280c5-048f-c804-a16d-3377374de6cd</td>\n",
       "      <td>AAID</td>\n",
       "      <td>34.09069300</td>\n",
       "      <td>-117.75457300</td>\n",
       "      <td>66.0</td>\n",
       "      <td>317.4</td>\n",
       "      <td>0</td>\n",
       "      <td>gps</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Android</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1745291018</td>\n",
       "      <td>28c96bdb-92cf-4d9a-8f65-04320322d812</td>\n",
       "      <td>IDFA</td>\n",
       "      <td>34.22806000</td>\n",
       "      <td>-118.46859000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>fused</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>iOS</td>\n",
       "      <td>13.3.1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1745291030</td>\n",
       "      <td>28c96bdb-92cf-4d9a-8f65-04320322d812</td>\n",
       "      <td>IDFA</td>\n",
       "      <td>34.22803000</td>\n",
       "      <td>-118.46860000</td>\n",
       "      <td>14.7</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>fused</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>iOS</td>\n",
       "      <td>13.3.1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1745290995</td>\n",
       "      <td>7730393f-010a-4863-a58d-cae4f2787dca</td>\n",
       "      <td>IDFA</td>\n",
       "      <td>33.95290000</td>\n",
       "      <td>-118.04338000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0</td>\n",
       "      <td>gps</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>iOS</td>\n",
       "      <td>None</td>\n",
       "      <td>Apple</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1745291015</td>\n",
       "      <td>8ce78bfb-2d62-4b3f-93c7-b63a5c96ff5d</td>\n",
       "      <td>IDFA</td>\n",
       "      <td>33.68109000</td>\n",
       "      <td>-117.92448000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-20.4</td>\n",
       "      <td>0</td>\n",
       "      <td>fused</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>iOS</td>\n",
       "      <td>None</td>\n",
       "      <td>Apple</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-04-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp                            device_aid device_aid_type  \\\n",
       "0  1745290992  787280c5-048f-c804-a16d-3377374de6cd            AAID   \n",
       "1  1745291018  28c96bdb-92cf-4d9a-8f65-04320322d812            IDFA   \n",
       "2  1745291030  28c96bdb-92cf-4d9a-8f65-04320322d812            IDFA   \n",
       "3  1745290995  7730393f-010a-4863-a58d-cae4f2787dca            IDFA   \n",
       "4  1745291015  8ce78bfb-2d62-4b3f-93c7-b63a5c96ff5d            IDFA   \n",
       "\n",
       "      latitude      longitude horizontal_accuracy altitude altitude_accuracy  \\\n",
       "0  34.09069300  -117.75457300                66.0    317.4                 0   \n",
       "1  34.22806000  -118.46859000                 4.3      218                 0   \n",
       "2  34.22803000  -118.46860000                14.7      218                 0   \n",
       "3  33.95290000  -118.04338000                 8.0     10.9                 0   \n",
       "4  33.68109000  -117.92448000                12.0    -20.4                 0   \n",
       "\n",
       "  location_method    ip user_agent       OS OS_version manufacturer model  \\\n",
       "0             gps  None       None  Android       None         None  None   \n",
       "1           fused  None       None      iOS     13.3.1        Apple  None   \n",
       "2           fused  None       None      iOS     13.3.1        Apple  None   \n",
       "3             gps  None       None      iOS       None        Apple  None   \n",
       "4           fused  None       None      iOS       None        Apple  None   \n",
       "\n",
       "  carrier geography_id_1        date  \n",
       "0    None             US  2025-04-22  \n",
       "1    None             US  2025-04-22  \n",
       "2    None             US  2025-04-22  \n",
       "3    None             US  2025-04-22  \n",
       "4    None             US  2025-04-22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_cols = {}\n",
    "\n",
    "traj = spark.read.parquet('s3a://catalog-pickwell/tutorial-sample/', header=True, sep=\"\\t\")\n",
    "traj.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b20d96",
   "metadata": {},
   "source": [
    "### Users in Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b62e7d-5fe7-4cdf-b9fd-8188e9c25bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "la_poly = \"POLYGON ((-117.704725 34.093957, -117.730125 34.021371, -117.76769 34.023506, -117.767483 34.004611, -117.785062 34.004809,\"\\\n",
    "          \" -117.802539 33.975551, -117.783287 33.946411, -117.976498 33.94605, -117.976593 33.90281, -118.058918 33.846121, -118.063162\"\\\n",
    "          \" 33.81961, -118.084377 33.803433, -118.096705 33.779085, -118.09197 33.758472, -118.11951 33.737064, -118.1259 33.697151,\"\\\n",
    "          \" -118.237008 33.690595, -118.274239 33.663429, -118.319135 33.659547, -118.345415 33.663427, -118.466962 33.725524, -118.485577 33.753664,\"\\\n",
    "          \" -118.484483 33.803154, -118.443968 33.839057, -118.447254 33.84876, -118.557356 33.987673, -118.727459 33.980307, -118.809827 33.946905,\"\\\n",
    "          \" -118.841116 33.955371, -118.873998 33.983314, -118.951721 33.992858, -118.940965 34.07483, -118.788889 34.168214, -118.668152 34.168195,\"\\\n",
    "          \" -118.667713 34.240404, -118.632495 34.240426, -118.636789 34.291804, -118.894634 34.817972, -118.881729 34.817802, -118.883381 34.808637,\"\\\n",
    "          \" -118.870926 34.803109, -118.854114 34.803279, -118.854253 34.817772, -117.667292 34.822526, -117.667034 34.558008, -117.659994 34.55804,\"\\\n",
    "          \" -117.646374 34.28917, -117.704725 34.093957))\"\n",
    "\n",
    "\n",
    "poly = gpd.GeoSeries.from_wkt([la_poly])[0]\n",
    "min_lon, min_lat, max_lon, max_lat = poly.bounds\n",
    "\n",
    "filtered = (\n",
    "    traj\n",
    "    .filter(F.col(\"location_method\").isin(\"gps\", \"fused\")) # remove signals with location based on WIFI\n",
    "    .filter(f\"longitude BETWEEN {min_lon} AND {max_lon}\")\n",
    "    .filter(f\"latitude  BETWEEN {min_lat} AND {max_lat}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140c8d7-fa47-47d2-81f4-6120a78f17b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "approx_total_records = filtered.rdd.countApprox(timeout=10000, confidence=0.95) # in ms\n",
    "print(f\"Approximate total records: {approx_total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76b803-3ef8-4e6c-b64b-8458bdba00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_num_users = (\n",
    "    filtered\n",
    "    .agg(F.approx_count_distinct(\"device_aid\", rsd=0.1).alias(\"approx_num_users\"))\n",
    "    .collect()[0][\"approx_num_users\"]\n",
    ")\n",
    "print(f\"Approximate unique devices (device_aid): {approx_num_users}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f9099",
   "metadata": {},
   "source": [
    "### Let's persist a small sample of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551d43e-4f60-447e-84f7-2c5856e10cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frac_users = 0.08\n",
    "\n",
    "sample_df = (\n",
    "    filtered\n",
    "      .withColumn(\"_bucket\", F.abs(F.xxhash64(\"device_aid\")) % 1000)\n",
    "      .filter(F.col(\"_bucket\") < frac_users*1000)   # keep frac_users of the buckets\n",
    "      .select(\"device_aid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c8ffd9-60da-4d83-923a-61ce9a193b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pandas_df = sample_df.toPandas()\n",
    "pandas_df.to_csv(\"sample_1pct_device_aid.csv\", index=False)\n",
    "print(pandas_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dbb447-2295-4fb3-8472-0e738d54605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better syntax?\n",
    "data = filtered.join(\n",
    "    sample_df.select(\"device_aid\"),  # just need the key column\n",
    "    on=\"device_aid\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c92bf-4d6b-4882-8187-46dfb0e28b25",
   "metadata": {},
   "source": [
    "### Downsample to every 5 minutes and completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd4076-cc30-4190-8427-d9a137f76176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, timestamp, user_id, periods=1, freq='min'):\n",
    "    \"\"\"\n",
    "    Keep at most one row per `periods`×`freq` window per user.\n",
    "    \"\"\"\n",
    "    if not isinstance(periods, int) or periods < 1:\n",
    "        raise ValueError(\"periods must be a positive integer\")\n",
    "    # bucket size in seconds (freq='min' for now)\n",
    "    window = periods * 60\n",
    "    bucket_col = \"_ts_bucket\"\n",
    "    return (\n",
    "        data\n",
    "        .withColumn(bucket_col, F.floor(F.col(timestamp) / window) * window)\n",
    "        .orderBy(user_id, bucket_col, timestamp)\n",
    "        .dropDuplicates([user_id, bucket_col])\n",
    "        .drop(bucket_col)\n",
    "    )\n",
    "\n",
    "data_clean = downsample(data, \"timestamp\", \"device_aid\", periods=2).filter(\"horizontal_accuracy <= 50\")\n",
    "data_clean.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f15856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completeness\n",
    "def completeness(data, timestamp, user_id, relative=False):\n",
    "    \"\"\"\n",
    "    Per-user fraction of non-empty hour buckets.\n",
    "    \"\"\"\n",
    "    # 1. bucket into hour‐start timestamps\n",
    "    df = data.withColumn(\n",
    "        \"_hour\",\n",
    "        F.floor(F.col(timestamp) / 3600) * 3600\n",
    "    )\n",
    "\n",
    "    # 2. single aggregation: hit_hours, first_hour, last_hour\n",
    "    stats = df.groupBy(user_id).agg(\n",
    "        F.countDistinct(\"_hour\").   alias(\"hit_hours\"),\n",
    "        F.min(\"_hour\").             alias(\"first_hour\"),\n",
    "        F.max(\"_hour\").             alias(\"last_hour\"),\n",
    "    )\n",
    "\n",
    "    if relative:\n",
    "        stats = stats.withColumn(\n",
    "            \"total_hours\",\n",
    "            (F.col(\"last_hour\") - F.col(\"first_hour\"))/3600 + F.lit(1)\n",
    "        )\n",
    "    else:\n",
    "        glob = df.agg(\n",
    "            F.min(\"_hour\").alias(\"gmin\"),\n",
    "            F.max(\"_hour\").alias(\"gmax\")\n",
    "        ).first()\n",
    "        total = int((glob[\"gmax\"] - glob[\"gmin\"])/3600 + 1)\n",
    "        stats = stats.withColumn(\n",
    "            \"total_hours\",\n",
    "            F.lit(total)\n",
    "        )\n",
    "\n",
    "    # 3. completeness ratio\n",
    "    return stats.withColumn(\n",
    "        \"completeness\",\n",
    "        F.col(\"hit_hours\") / F.col(\"total_hours\")\n",
    "    ).select(user_id, \"completeness\")\n",
    "\n",
    "\n",
    "q_hourly = filters.completeness(traj, periods=1, freq='h', traj_cols=tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6ab10-c509-4276-a886-210880ee7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_q = q_hourly.toPandas()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "ax.hist(_q, bins=20)\n",
    "ax.set_title('Completeness (Hourly)')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5c3a8",
   "metadata": {},
   "source": [
    "### Stop and persist stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5f0fe-f8a3-41da-82e6-3f7ab1b5294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.stop_detection.lachesis as LACHESIS\n",
    "\n",
    "def lachesis_per_user(\n",
    "    data_spark,\n",
    "    dt_max,\n",
    "    delta_roam,\n",
    "    dur_min=5,\n",
    "    complete_output=False,\n",
    "    passthrough_cols=None,\n",
    "    traj_cols=None,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Run LACHESIS stop detection on every user in parallel (Spark).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_spark : pyspark.sql.DataFrame\n",
    "    dt_max, delta_roam, dur_min, complete_output, passthrough_cols, traj_cols\n",
    "        Same meaning as in the original pandas implementation.\n",
    "    **kwargs : forwarded to LACHESIS.lachesis\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame  (stops)\n",
    "    \"\"\"\n",
    "    passthrough_cols = passthrough_cols or []\n",
    "    traj_cols = traj_cols or {}\n",
    "    uid = traj_cols.get(\"user_id\", \"device_aid\")\n",
    "\n",
    "    def _lachesis(pdf):\n",
    "        return LACHESIS.lachesis(\n",
    "            pdf,\n",
    "            dt_max          = dt_max,\n",
    "            delta_roam      = delta_roam,\n",
    "            dur_min         = dur_min,\n",
    "            complete_output = complete_output,\n",
    "            passthrough_cols= passthrough_cols + [uid],\n",
    "            traj_cols       = traj_cols,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    schema = (\n",
    "        f\"{uid} string, \"\n",
    "        \"start_ts long, end_ts long, \"\n",
    "        \"lat double, lon double, \"\n",
    "        \"duration_min double\"\n",
    "    )\n",
    "\n",
    "    stops = (\n",
    "        data_spark\n",
    "        .groupBy(uid)\n",
    "        .applyInPandas(_lachesis, schema)\n",
    "    )\n",
    "\n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = {'longitude':'longitude',\n",
    "             'latitude':'latitude',\n",
    "             'ha':'horizontal_accuracy',\n",
    "             'user_id':'device_aid',\n",
    "             'timestamp':'timestamp',\n",
    "             'date':'date'}\n",
    "\n",
    "stops_df = lachesis_per_user(\n",
    "    data_clean,\n",
    "    dt_max=240,\n",
    "    delta_roam=30,\n",
    "    complete_output=True,\n",
    "    passthrough_cols=[\"tz_offset\"],\n",
    "    traj_cols=tc)\n",
    "\n",
    "# write to parquet, partitioned by user\n",
    "(stops_df.write\n",
    "         .mode(\"overwrite\")\n",
    "         .partitionBy(\"device_aid\")\n",
    "         .parquet(\"stops_data/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4d2d1",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b5653-5061-4857-9527-db016635a765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c76bf4f-ed84-4434-8088-2dc88623ab8a",
   "metadata": {},
   "source": [
    "### Mobility metrics: % time at home, and radius of gyration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d020c9a-06c9-4c04-9d8b-da2c514a085e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f388eb9b-f048-4782-8db6-dd7e7d9aeffd",
   "metadata": {},
   "source": [
    "### Let's aggregate per Census Block Group and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3a499-c3c2-4ade-a30f-b848a97f9b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "942d294f-f696-44de-ac82-e1bf076d2544",
   "metadata": {},
   "source": [
    "### Post-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ca6a6-c681-4fad-a841-8bb28b3e09a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

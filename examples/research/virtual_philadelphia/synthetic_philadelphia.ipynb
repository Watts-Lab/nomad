{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf872541-c40e-4f6c-8c41-8b47835d551c",
   "metadata": {},
   "source": [
    "# Synthetic Philadelphia - Production Pipeline\n",
    "\n",
    "Full rasterization pipeline with EPR destination diary generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13f0a6-9073-42b7-86ea-c8746c909d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "\n",
    "import nomad.map_utils as nm\n",
    "from nomad.city_gen import RasterCity\n",
    "from nomad.traj_gen import Population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec81266",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d04e8b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "LARGE_BOX = box(-75.1905, 39.9235, -75.1425, 39.9535)\n",
    "\n",
    "USE_FULL_CITY = False\n",
    "OUTPUT_DIR = Path(\"sandbox\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if USE_FULL_CITY:\n",
    "    BOX_NAME = \"full\"\n",
    "    POLY = \"Philadelphia, Pennsylvania, USA\"\n",
    "else:\n",
    "    BOX_NAME = \"large\"\n",
    "    POLY = LARGE_BOX\n",
    "\n",
    "SANDBOX_GPKG = OUTPUT_DIR / f\"sandbox_data_{BOX_NAME}.gpkg\"\n",
    "REGENERATE_DATA = False\n",
    "\n",
    "config = {\n",
    "    \"box_name\": BOX_NAME,\n",
    "    \"block_side_length\": 15.0,\n",
    "    \"hub_size\": 100,\n",
    "    \"N\": 10,\n",
    "    \"name_seed\": 42,\n",
    "    \"name_count\": 2,\n",
    "    \"epr_params\": {\n",
    "        \"datetime\": \"2024-01-01 00:00-05:00\",\n",
    "        \"end_time\": \"2024-01-08 00:00-05:00\",\n",
    "        \"epr_time_res\": 15,\n",
    "        \"rho\": 0.4,\n",
    "        \"gamma\": 0.3,\n",
    "        \"seed_base\": 100\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be88c3",
   "metadata": {},
   "source": [
    "## Data Generation (OSM Download + Rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0185669",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REGENERATE_DATA or not SANDBOX_GPKG.exists():\n",
    "    print(\"=\"*50)\n",
    "    print(\"DATA GENERATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    buildings = nm.download_osm_buildings(\n",
    "        POLY,\n",
    "        crs=\"EPSG:3857\",\n",
    "        schema=\"garden_city\",\n",
    "        clip=True,\n",
    "        infer_building_types=True,\n",
    "        explode=True,\n",
    "    )\n",
    "    download_buildings_time = time.time() - t0\n",
    "    print(f\"Buildings download: {download_buildings_time:>6.2f}s ({len(buildings):,} buildings)\")\n",
    "    \n",
    "    if USE_FULL_CITY:\n",
    "        boundary_polygon = nm.get_city_boundary_osm(POLY, simplify=True)[0]\n",
    "        boundary_polygon = gpd.GeoSeries([boundary_polygon], crs=\"EPSG:4326\").to_crs(\"EPSG:3857\").iloc[0]\n",
    "    else:\n",
    "        boundary_polygon = gpd.GeoDataFrame(geometry=[POLY], crs=\"EPSG:4326\").to_crs(\"EPSG:3857\").geometry.iloc[0]\n",
    "    \n",
    "    outside_mask = ~buildings.geometry.within(boundary_polygon)\n",
    "    if outside_mask.any():\n",
    "        buildings = gpd.clip(buildings, gpd.GeoDataFrame(geometry=[boundary_polygon], crs=\"EPSG:3857\"))\n",
    "    buildings = nm.remove_overlaps(buildings).reset_index(drop=True)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    streets = nm.download_osm_streets(\n",
    "        POLY,\n",
    "        crs=\"EPSG:3857\",\n",
    "        clip=True,\n",
    "        explode=True,\n",
    "        graphml_path=OUTPUT_DIR / \"streets_consolidated.graphml\",\n",
    "    )\n",
    "    download_streets_time = time.time() - t1\n",
    "    print(f\"Streets download:   {download_streets_time:>6.2f}s ({len(streets):,} streets)\")\n",
    "    \n",
    "    streets = streets.reset_index(drop=True)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    rotated_streets, rotation_deg = nm.rotate_streets_to_align(streets, k=200)\n",
    "    rotation_time = time.time() - t2\n",
    "    print(f\"Grid rotation:      {rotation_time:>6.2f}s ({rotation_deg:.2f}°)\")\n",
    "    \n",
    "    rotated_buildings = nm.rotate(buildings, rotation_deg=rotation_deg)\n",
    "    rotated_boundary = nm.rotate(\n",
    "        gpd.GeoDataFrame(geometry=[boundary_polygon], crs=\"EPSG:3857\"),\n",
    "        rotation_deg=rotation_deg\n",
    "    )\n",
    "    \n",
    "    if SANDBOX_GPKG.exists():\n",
    "        SANDBOX_GPKG.unlink()\n",
    "    \n",
    "    rotated_buildings.to_file(SANDBOX_GPKG, layer=\"buildings\", driver=\"GPKG\")\n",
    "    rotated_streets.to_file(SANDBOX_GPKG, layer=\"streets\", driver=\"GPKG\", mode=\"a\")\n",
    "    rotated_boundary.to_file(SANDBOX_GPKG, layer=\"boundary\", driver=\"GPKG\", mode=\"a\")\n",
    "    \n",
    "    data_gen_time = download_buildings_time + download_streets_time + rotation_time\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Data generation:    {data_gen_time:>6.2f}s\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "else:\n",
    "    print(f\"Loading existing data from {SANDBOX_GPKG}\")\n",
    "    data_gen_time = 0.0\n",
    "\n",
    "buildings = gpd.read_file(SANDBOX_GPKG, layer=\"buildings\")\n",
    "streets = gpd.read_file(SANDBOX_GPKG, layer=\"streets\")\n",
    "boundary = gpd.read_file(SANDBOX_GPKG, layer=\"boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7953dba",
   "metadata": {},
   "source": [
    "## Rasterization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294a739",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"RASTERIZATION PIPELINE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "t0 = time.time()\n",
    "city = RasterCity(\n",
    "    boundary.geometry.iloc[0],\n",
    "    streets,\n",
    "    buildings,\n",
    "    block_side_length=config[\"block_side_length\"],\n",
    "    resolve_overlaps=True\n",
    ")\n",
    "gen_time = time.time() - t0\n",
    "print(f\"City generation:    {gen_time:>6.2f}s\")\n",
    "\n",
    "t1 = time.time()\n",
    "G = city.get_street_graph()\n",
    "graph_time = time.time() - t1\n",
    "print(f\"Street graph:       {graph_time:>6.2f}s\")\n",
    "\n",
    "t2 = time.time()\n",
    "city._build_hub_network(hub_size=config[\"hub_size\"])\n",
    "hub_time = time.time() - t2\n",
    "print(f\"Hub network:        {hub_time:>6.2f}s\")\n",
    "\n",
    "t3 = time.time()\n",
    "city.compute_gravity(exponent=2.0, callable_only=True)\n",
    "grav_time = time.time() - t3\n",
    "print(f\"Gravity computation: {grav_time:>6.2f}s\")\n",
    "\n",
    "raster_time = gen_time + graph_time + hub_time + grav_time\n",
    "print(\"-\"*50)\n",
    "print(f\"Rasterization:      {raster_time:>6.2f}s\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if data_gen_time > 0:\n",
    "    total_time = data_gen_time + raster_time\n",
    "    print(f\"\\nTotal (with data):  {total_time:>6.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59b2ac",
   "metadata": {},
   "source": [
    "## Summary: City Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_mb(obj):\n",
    "    if isinstance(obj, (pd.DataFrame, gpd.GeoDataFrame)):\n",
    "        return obj.memory_usage(deep=True).sum() / 1024**2\n",
    "    elif hasattr(obj, 'nodes') and hasattr(obj, 'edges'):\n",
    "        return (len(obj.nodes) * 64 + len(obj.edges) * 96) / 1024**2\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Component': ['Blocks', 'Streets', 'Buildings', 'Graph Nodes', 'Graph Edges', 'Hub Network', 'Hub Info', 'Nearby Doors', 'Gravity (callable)'],\n",
    "    'Count/Shape': [\n",
    "        f\"{len(city.blocks_gdf):,}\",\n",
    "        f\"{len(city.streets_gdf):,}\",\n",
    "        f\"{len(city.buildings_gdf):,}\",\n",
    "        f\"{len(G.nodes):,}\",\n",
    "        f\"{len(G.edges):,}\",\n",
    "        f\"{city.hub_df.shape[0]}×{city.hub_df.shape[1]}\",\n",
    "        f\"{city.grav_hub_info.shape[0]}×{city.grav_hub_info.shape[1]}\",\n",
    "        f\"{len(city.mh_dist_nearby_doors):,} pairs\",\n",
    "        \"function\"\n",
    "    ],\n",
    "    'Memory (MB)': [\n",
    "        f\"{get_size_mb(city.blocks_gdf):.1f}\",\n",
    "        f\"{get_size_mb(city.streets_gdf):.1f}\",\n",
    "        f\"{get_size_mb(city.buildings_gdf):.1f}\",\n",
    "        f\"{get_size_mb(G):.1f}\",\n",
    "        \"-\",\n",
    "        f\"{get_size_mb(city.hub_df):.1f}\",\n",
    "        f\"{get_size_mb(city.grav_hub_info):.1f}\",\n",
    "        f\"{get_size_mb(city.mh_dist_nearby_doors):.1f}\",\n",
    "        \"<0.1\"\n",
    "    ]\n",
    "})\n",
    "print(\"\\n\" + summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286b2970",
   "metadata": {},
   "source": [
    "## Generate Population and Destination Diaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa96f9-80d0-4a9f-9bcd-54311b602856",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tqdm import tqdm\n",
    "from nomad.traj_gen import Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DESTINATION DIARY GENERATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "config_path = OUTPUT_DIR / f\"config_{BOX_NAME}.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "\n",
    "population = Population(city)\n",
    "population.generate_agents(\n",
    "    N=config[\"N\"],\n",
    "    seed=config[\"name_seed\"],\n",
    "    name_count=config[\"name_count\"],\n",
    "    datetimes=config[\"epr_params\"][\"datetime\"]\n",
    ")\n",
    "\n",
    "end_time = pd.Timestamp(config[\"epr_params\"][\"end_time\"])\n",
    "diary_dir = OUTPUT_DIR / f\"diaries_{BOX_NAME}\"\n",
    "diary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "t1 = time.time()\n",
    "for i, agent in tqdm(enumerate(population.roster.values()), total=config[\"N\"]):\n",
    "    print(agent.identifier)\n",
    "    agent.generate_dest_diary(\n",
    "        end_time=end_time,\n",
    "        epr_time_res=config[\"epr_params\"][\"epr_time_res\"],\n",
    "        rho=config[\"epr_params\"][\"rho\"],\n",
    "        gamma=config[\"epr_params\"][\"gamma\"],\n",
    "        seed=config[\"epr_params\"][\"seed_base\"] + i\n",
    "    )\n",
    "    agent.destination_diary.to_csv(diary_dir / f\"{agent.identifier}.csv\", index=False)\n",
    "\n",
    "diary_gen_time = time.time() - t1\n",
    "print(f\"Diary generation:   {diary_gen_time:>6.2f}s\")\n",
    "\n",
    "total_entries = sum(len(agent.destination_diary) for agent in population.roster.values())\n",
    "print(f\"Total entries:      {total_entries:,}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Total EPR:          {diary_gen_time:>6.2f}s\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nConfig saved to {config_path}\")\n",
    "print(f\"Diaries saved to {diary_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a801bd85-b13f-445c-8119-28a6bd086972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.buildings_gdf.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34c4ba-aab2-469c-a105-98a7b562c3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "nomad-kernel",
   "language": "python",
   "name": "nomad-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

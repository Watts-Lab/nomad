{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fb0ef-73cc-4592-8ce5-9ad5f3027e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import nomad.io.base as loader\n",
    "import numpy as np\n",
    "import nomad.stop_detection.hdbscan as HDBSCAN\n",
    "import nomad.stop_detection.lachesis as LACHESIS\n",
    "import nomad.stop_detection.ta_dbscan as TADBSCAN\n",
    "import geopandas as gpd\n",
    "import nomad.visit_attribution as va\n",
    "import nomad.filters as filters\n",
    "from nomad.contact_estimation import overlapping_visits, compute_visitation_errors, compute_precision_recall_f1\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c3d06-7bc1-4669-a2bf-f04d8b3bd6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'uid':'uid',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}\n",
    "\n",
    "diaries_df = loader.from_file(\"../../nomad/data/diaries\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                       parse_dates=True)\n",
    "sparse_df = loader.from_file(\"../../nomad/data/sparse_traj/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                      parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b250543-e378-45cb-8c12-6762b2c76009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject from gc_coords to web mercator\n",
    "sparse_df.loc[:,'x'] = (sparse_df['x'] - 4265699)/15\n",
    "sparse_df.loc[:,'y'] = (sparse_df['y'] + 4392976)/15\n",
    "\n",
    "diaries_df.loc[:,'x'] = (diaries_df['x'] - 4265699)/15\n",
    "diaries_df.loc[:,'y'] = (diaries_df['y'] + 4392976)/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58f567-17c2-4773-b8ba-32d7777a32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data from 2 users\n",
    "user1 = diaries_df.uid.unique()[0]\n",
    "user2 = diaries_df.uid.unique()[10]\n",
    "\n",
    "sparse1 = sparse_df.loc[sparse_df['uid'] == user1]\n",
    "sparse2 = sparse_df.loc[sparse_df['uid'] == user2]\n",
    "\n",
    "diary1 = diaries_df.loc[diaries_df.uid == user1]\n",
    "diary2 = diaries_df.loc[diaries_df.uid == user2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f51807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "completeness_df = filters.q_stats(sparse_df, user_id='uid', timestamp='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_df.q_stat.quantile([0.5, 0.7, 0.85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea573424",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "completeness_df.boxplot(column=\"q_stat\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e76c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DUR_MIN=5\n",
    "DT_MAX=60\n",
    "DELTA_ROAM=100\n",
    "\n",
    "stop_table_lachesis = LACHESIS.lachesis(traj=sparse1,\n",
    "                                        dur_min=DUR_MIN,\n",
    "                                        dt_max=DT_MAX,\n",
    "                                        delta_roam=DELTA_ROAM,\n",
    "                                        traj_cols=traj_cols,\n",
    "                                        keep_col_names=True,\n",
    "                                        complete_output=True)\n",
    "\n",
    "\n",
    "labels_lachesis = LACHESIS._lachesis_labels(traj=sparse1,\n",
    "                                            dur_min=DUR_MIN,\n",
    "                                            dt_max=DT_MAX,\n",
    "                                            delta_roam=DELTA_ROAM,\n",
    "                                            traj_cols=traj_cols)\n",
    "labels_lachesis.name = 'cluster'\n",
    "\n",
    "\n",
    "pred_lachesis = va.point_in_polygon(traj=sparse1,\n",
    "                 labels=labels_lachesis,\n",
    "                 stop_table=stop_table_lachesis,\n",
    "                 traj_cols=traj_cols,\n",
    "                 is_datetime=False,\n",
    "                 is_long_lat=False)\n",
    "\n",
    "pred_lachesis.location.nunique()\n",
    "\n",
    "# truth_df = diary1\n",
    "\n",
    "# va.majority_poi(traj=sparse1,\n",
    "#              labels=labels_lachesis,\n",
    "#              stop_table=stop_table_lachesis,\n",
    "#              traj_cols=traj_cols,\n",
    "#              is_datetime=False,\n",
    "#              is_long_lat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d026728",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_table_hdbscan = HDBSCAN.st_hdbscan(\n",
    "                traj=sparse1,\n",
    "                traj_cols=traj_cols,\n",
    "                time_thresh=60,\n",
    "                min_pts=2,\n",
    "                min_cluster_size=3)\n",
    "\n",
    "labels_hdbscan = HDBSCAN.hdbscan_labels(\n",
    "                traj=sparse1,\n",
    "                traj_cols=traj_cols,\n",
    "                time_thresh=60,\n",
    "                min_pts=2,\n",
    "                min_cluster_size=3)\n",
    "\n",
    "labels_hdbscan.name = 'cluster'\n",
    "\n",
    "pred_hdbscan = va.point_in_polygon(traj=sparse1,\n",
    "                 labels=labels_hdbscan,\n",
    "                 stop_table=stop_table_hdbscan,\n",
    "                 traj_cols=traj_cols,\n",
    "                 is_datetime=False,\n",
    "                 is_long_lat=False)\n",
    "\n",
    "pred_hdbscan.location.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_hdbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diary1.location.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16ade4-d727-4073-9425-4741225f8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e83346-8e18-45da-9fb7-a45aa2fe806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute overlaps\n",
    "overlaps = overlapping_visits(left=pred_hdbscan,\n",
    "                              right=diary1,\n",
    "                              match_location=False)\n",
    "\n",
    "# Step 2: Compute visitation errors (missed, merged, split)\n",
    "errors = compute_visitation_errors(overlaps=overlaps,\n",
    "                                   true_visits=diary1)\n",
    "print(\"Visitation Errors:\", errors)\n",
    "\n",
    "# Step 3: Compute precision, recall, and F1\n",
    "prf1 = compute_precision_recall_f1(overlaps=overlaps,\n",
    "                                   pred_visits=pred_hdbscan,\n",
    "                                   true_visits=diary1)\n",
    "print(\"Precision / Recall / F1:\", prf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fcefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_table_hdbscan = HDBSCAN.st_hdbscan(\n",
    "                traj=sparse1,\n",
    "                traj_cols=traj_cols,\n",
    "                time_thresh=60,\n",
    "                min_pts=2,\n",
    "                min_cluster_size=3\n",
    "            )\n",
    "\n",
    "labels_hdbscan = HDBSCAN.hdbscan_labels(\n",
    "                traj=sparse1,\n",
    "                traj_cols=traj_cols,\n",
    "                time_thresh=60,\n",
    "                min_pts=2,\n",
    "                min_cluster_size=3\n",
    "            )\n",
    "\n",
    "labels_hdbscan.name = 'cluster'\n",
    "\n",
    "va.point_in_polygon(traj=sparse1,\n",
    "                 labels=labels_hdbscan,\n",
    "                 stop_table=stop_table_hdbscan,\n",
    "                 traj_cols=traj_cols,\n",
    "                 is_datetime=False,\n",
    "                 is_long_lat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37410cd6-9b14-43ec-838c-a4366059f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'uid':'uid',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}\n",
    "stop_detection_algos = ['lachesis', 'ta-dbscan', 'hdbscan']\n",
    "metrics_df = pd.DataFrame()\n",
    "TIME_THRESH=60\n",
    "DIST_THRESH=5\n",
    "MIN_PTS=2\n",
    "\n",
    "DUR_MIN=5\n",
    "DT_MAX=60\n",
    "DELTA_ROAM=3\n",
    "\n",
    "for user in diaries_df.uid.unique():\n",
    "    # truth_df = diaries_df.loc[diaries_df.uid == user].dropna().reset_index(drop=True)\n",
    "    sparse = sparse_df[sparse_df['uid'] == user]\n",
    "    sparse.loc[:,'x'] = (sparse['x'] - 4265699)/15\n",
    "    sparse.loc[:,'y'] = (sparse['y'] + 4392976)/15\n",
    "    \n",
    "    truth = diaries_df.loc[diaries_df['uid'] == user]\n",
    "    truth.loc[:,'x'] = (truth['x'] - 4265699)/15\n",
    "    truth.loc[:,'y'] = (truth['y'] + 4392976)/15\n",
    "\n",
    "    for algo in stop_detection_algos:\n",
    "        if algo == 'lachesis':\n",
    "            stop_table = LACHESIS.lachesis(\n",
    "                traj=sparse,\n",
    "                dur_min=DUR_MIN,\n",
    "                dt_max=DT_MAX,\n",
    "                delta_roam=DELTA_ROAM,\n",
    "                traj_cols=traj_cols\n",
    "            )\n",
    "            labels = LACHESIS._lachesis_labels(\n",
    "                traj=sparse,\n",
    "                dur_min=5,\n",
    "                dt_max=60,\n",
    "                delta_roam=3,\n",
    "                traj_cols=traj_cols\n",
    "            )\n",
    "            labels.name = 'cluster'\n",
    "            # print(algo)\n",
    "            # print(stop_table)\n",
    "            # print(labels)\n",
    "        elif algo == 'ta-dbscan':\n",
    "            stop_table = TADBSCAN.temporal_dbscan(\n",
    "                data=sparse,\n",
    "                time_thresh=TIME_THRESH,\n",
    "                dist_thresh=DIST_THRESH,\n",
    "                min_pts=MIN_PTS,\n",
    "                traj_cols=traj_cols\n",
    "            )\n",
    "            labels = TADBSCAN._temporal_dbscan_labels(\n",
    "                data=sparse,\n",
    "                time_thresh=TIME_THRESH,\n",
    "                dist_thresh=DIST_THRESH,\n",
    "                min_pts=MIN_PTS,\n",
    "                traj_cols=traj_cols\n",
    "            )\n",
    "            labels.name = 'cluster'\n",
    "            # print(algo)\n",
    "            # print(stop_table)\n",
    "            # print(labels)\n",
    "        else:  # 'hdbscan'\n",
    "            stop_table = HDBSCAN.st_hdbscan(\n",
    "                traj=sparse,\n",
    "                traj_cols=traj_cols,\n",
    "                time_thresh=TIME_THRESH,\n",
    "                min_pts=2,\n",
    "                min_cluster_size=3\n",
    "            )\n",
    "            labels = HDBSCAN.hdbscan_labels(\n",
    "                traj=sparse,\n",
    "                traj_cols=traj_cols,\n",
    "                time_thresh=TIME_THRESH,\n",
    "                min_pts=2,\n",
    "                min_cluster_size=3\n",
    "            )\n",
    "            labels.name = 'cluster'\n",
    "            # print(algo)\n",
    "            # print(stop_table)\n",
    "            # print(labels)\n",
    "        \n",
    "        pred = va.point_in_polygon(traj=sparse,\n",
    "                 labels=labels,\n",
    "                 stop_table=stop_table,\n",
    "                 traj_cols=traj_cols,\n",
    "                 is_datetime=False,\n",
    "                 is_long_lat=False)\n",
    "\n",
    "        # Step 1: Compute overlaps\n",
    "        overlaps = overlapping_visits(left=pred,\n",
    "                                      right=truth,\n",
    "                                      match_location=False)\n",
    "\n",
    "        # Step 2: Compute visitation errors (missed, merged, split)\n",
    "        errors = compute_visitation_errors(overlaps=overlaps,\n",
    "                                           true_visits=truth)\n",
    "\n",
    "        # Step 3: Compute precision, recall, and F1\n",
    "        prf1 = compute_precision_recall_f1(overlaps=overlaps,\n",
    "                                           pred_visits=pred,\n",
    "                                           true_visits=truth)\n",
    "\n",
    "        all_metrics = {**errors, **prf1, 'user': user, 'algorithm': algo}\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([all_metrics])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd26163",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"missed_fraction\", \"merged_fraction\", \"split_fraction\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure()\n",
    "    metrics_df.boxplot(column=metric, by='algorithm')\n",
    "    plt.title(f'{metric} by Algorithm')\n",
    "    plt.suptitle('')\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (daphme)",
   "language": "python",
   "name": "daphme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb907a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2bbc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "import itertools\n",
    "import warnings\n",
    "from zoneinfo import ZoneInfo\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import nomad.io.base as loader\n",
    "import nomad.stop_detection.utils as utils\n",
    "import nomad.stop_detection.lachesis as LACHESIS\n",
    "import nomad.stop_detection.ta_dbscan as TADBSCAN\n",
    "import nomad.stop_detection.grid_based as GRID_BASED\n",
    "import nomad.stop_detection.postprocessing as pp\n",
    "\n",
    "import nomad.visit_attribution as visits\n",
    "import nomad.city_gen as cg\n",
    "import nomad.traj_gen as tg\n",
    "import nomad.filters as filters\n",
    "from nomad.traj_gen import Agent, Population\n",
    "from nomad.sparsity import gen_params_target_q\n",
    "\n",
    "from nomad.contact_estimation import overlapping_visits, compute_visitation_errors, compute_precision_recall_f1\n",
    "from metrics import poi_map, identify_stop, prepare_diary, prepare_stop_table, cluster_metrics\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4799df-4d3c-4734-a3c5-4aeb47d66bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# At some point, we should fix the warnings in the codebase, but for now we can ignore them.\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152cdfc-d11f-4b75-9099-2507d61fef59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following functions help with segmenting the analysis to building size/type and stop dwell time. \n",
    "\n",
    "def classify_building_size_from_id(building_id):\n",
    "    building = city.buildings.get(building_id)\n",
    "    n_blocks = len(building.blocks)\n",
    "    if n_blocks == 1:\n",
    "        return 'small'\n",
    "    elif 2 <= n_blocks <= 3:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'big'\n",
    "\n",
    "def classify_building_type_from_id(building_id):\n",
    "    building = city.buildings.get(building_id)\n",
    "    return building.building_type\n",
    "\n",
    "def classify_dwell(duration):\n",
    "    if duration <= 5:\n",
    "        return 'low'\n",
    "    elif 6 <= duration <= 120:\n",
    "        return 'mid'\n",
    "    else:\n",
    "        return 'high'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132f841-e679-4024-9b25-6a9df9764b92",
   "metadata": {},
   "source": [
    "# Robustness to sparsity in pre-processing of human mobility data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572296dc-9bdc-40ab-b030-fd58cb374426",
   "metadata": {},
   "source": [
    "**Francisco Jose Barreras**, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA\n",
    "\n",
    "**Thomas Li**, Graduate School of Business, Stanford University, Palo Alto, CA, USA\n",
    "\n",
    "**Duncan Watts**, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb9c37-4523-4482-b92a-dcb83d524c6f",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4d69d-db7c-4c11-896e-aa6ccd1eb83f",
   "metadata": {},
   "source": [
    "Pre-processing algorithms for human mobility data, such as stop detection, are vulnerable to errors when applied to sparse and bursty GPS datasets, but evaluating their robustness is difficult in the absence of ground truth. We address this challenge with a synthetic benchmarking framework that combines an agent-based generator of realistic trajectories—based on the Exploration and Preferential Return model (EPR)—with a sparse sampler that replicates the temporal structure of real GPS data. This setup allows controlled comparison of algorithm outputs against known ground-truth stops. We evaluate three stop-detection methods—ST-DBScan, Lachesis, and a grid-based algorithm—across varying levels of sparsity, burstiness, and parameterizations. Our analysis identifies failure modes such as stop merging, splitting, and missed stops, quantifies how often they arise under realistic movement patterns, and assesses how parameter tuning can mitigate them. We find that commonly used algorithms are not robust to levels of sparsity commonly found in commercial datasets, and that parameter choices critically affect outcomes. These experiments offer practical guidance for improving the reliability of GPS data processing in applied research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4429317c-fb67-4a78-85e0-caffd176d901",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342cfbe-afab-470d-acae-a1a7740e4f58",
   "metadata": {
    "tags": []
   },
   "source": [
    "Commercial GPS datasets have become central to human mobility research, powering applications in epidemiology, disaster response, transportation, urban planning, and behavioral science \\cite{chang2021mobility, pepe2020covid, couture2021jue, moro2021mobility, gauvin2020gender, song2014prediction}. These datasets provide granular, high-frequency location signals from smartphones, but they are also sparse, bursty, and noisy—particularly when pings are collected opportunistically via apps or under privacy-preserving constraints. To extract useful signals from these raw data, researchers apply pre-processing algorithms to identify stops, trips, and frequently visited locations. However, many of these algorithms, including variants of DBScan \\cite{birant2007st, ester1996density}, rule-based methods like Project Lachesis \\cite{hariharan2004project}, and grid-based heuristics, were not designed with sparse or bursty signals in mind. Their performance in such settings is rarely tested, and robustness to signal degradation remains poorly understood.\n",
    "\n",
    "Evaluating robustness in these settings is nontrivial. Real datasets typically lack ground truth: it is unknown whether a detected stop reflects a real event, or if a missed stop is due to noise, sparsity, or poor parameterization. Even synthetic benchmarks often assume uniformly sampled trajectories, which overlook the temporal irregularities that characterize real data. As a result, existing evaluations often prioritize computational efficiency over behavioral accuracy \\cite{aslak2020infostop, chen2014t}, leaving open questions about how well these algorithms perform under the kinds of signal degradation found in commercial datasets.\n",
    "\n",
    "We address this challenge by introducing a synthetic benchmarking framework designed to test the robustness of stop-detection algorithms under realistic conditions. Our framework builds on the Garden City mobility model \\cite{2412.00913v1}, which uses an Exploration and Preferential Return (EPR) model to simulate human mobility patterns at both macro and micro scales. Agents generate full, minute-level “ground-truth” trajectories as they move through a synthetic city composed of homes, workplaces, and public locations. These trajectories are then sparsified using a self-exciting point process that captures the bursty nature of GPS pings, and measurement noise is added to mimic GPS error. These sparse trajectories, alongside their ground-truth counterparts, allow us to quantify the accuracy and robustness of stop-detection algorithms used in the human mobility literature.\n",
    "\n",
    "Using this framework, we evaluate the robustness of three stop-detection algorithms—ST-DBScan \\cite{birant2007st}, Lachesis \\cite{hariharan2004project}, and a simple grid-based method—by comparing their outputs to the ground-truth mobility diaries of the simulated agents. Our analysis proceeds in three parts. First, we characterize the failure modes of these algorithms using controlled synthetic trajectories, identifying phenomena such as stop merging (over-clustering), stop splitting (under-clustering), and omission of stops altogether. Second, we test whether these failure modes persist under more realistic mobility traces, and analyze their frequency and correlation with features of the signal such as ping density, burst structure, and location size. Finally, we show that careful parameter tuning can mitigate some—but not all—of these issues, and provide practical guidance on how to select parameters in the presence of sparse and noisy data.\n",
    "\n",
    "Our results indicate that most stop-detection algorithms are not robust to realistic forms of sparsity, and that failure rates depend strongly on the temporal structure of the data—not just its average sampling rate. These findings underscore the need for more principled benchmarking and parameter selection in GPS data processing pipelines, especially for applications where downstream metrics are sensitive to stop detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f17698-c695-445b-aaa5-cbc93e407516",
   "metadata": {},
   "source": [
    "## Possible errors in stop detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75f9fa",
   "metadata": {},
   "source": [
    "We focus on errors of two types. Clustering pings that should not be clustered together, in particular, merging of two stops that occur in nearby buildings. This should occur more often when the algorithm parameters are coarser.\n",
    "The other problem is failure to cluster pings that correspond to the same stop, this is a problem when the movement is to broad and the parameters are too fine, but also when there are long gaps in the data. Thus, we anticipate the error to be related to area and dwell times. We call these \"missed stops\" and \"splitting\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185708d1",
   "metadata": {},
   "source": [
    "**Ad-hoc trajectory 1**: 4 one-hour-long visits to nearby buildings.\n",
    "\n",
    "$\\varepsilon$: Stop-detection distance thresholds ($\\varepsilon$) larger than the distance between two buildings guarantee merging. We experiment with $\\varepsilon = 12m$ for DBScan, and $\\varepsilon = 30m$ for Lachesis, to cover a non-trivial regime.\n",
    "\n",
    "![Ad-hoc Trajectory 1](./ad-hoc-traj-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba519dc5",
   "metadata": {},
   "source": [
    "**Ad-hoc trajectory 2**:  5 visits to separate buildings, with varying areas and dwell times.\n",
    "\n",
    "$\\Delta T$: Stop-detection max allowed gap of 90 minutes is common and allows for splitting when dwelling for a long time. We experiment with $\\varepsilon = 18m$ for DBSCan, and $\\varepsilon = 30m$ for Lachesis, to allow some spatial splitting.\n",
    "\n",
    "![Ad-hoc Trajectory 2](./ad-hoc-traj-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f0e80-3e5b-40e2-b994-a7563a04437b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## START CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d7a0a3",
   "metadata": {},
   "source": [
    "Begin by initiating the city and loading the table of POIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726ed92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city = cg.load('../garden-city.pkl')\n",
    "\n",
    "poi_table = gpd.read_file('../garden_city_gc_coords.geojson')\n",
    "poi_table = poi_table.rename({'type':'building_type'}, axis=1)  # building type\n",
    "poi_table['building_size'] = poi_table['building_id'].apply(classify_building_size_from_id)  # building size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d60cd4",
   "metadata": {},
   "source": [
    "### Define the function for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5404d2-2340-41c2-8da9-3393e4a5746c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_stops_with_loc = partial(\n",
    "    utils.summarize_stop,\n",
    "    x='x',\n",
    "    y='y',\n",
    "    keep_col_names=False,\n",
    "    passthrough_cols=['building_id'],\n",
    "    complete_output=True)\n",
    "\n",
    "def run_simulation_for_single_seed(\n",
    "    seed, dt, sim_tasks, agent_home, agent_workplace, destinations,\n",
    "    dbscan_param, lachesis_param, traj_cols, summarize_stops_with_loc\n",
    "):\n",
    "    \"\"\"\n",
    "    This function performs the simulation for a single 'seed'.\n",
    "    It can be run in parallel to speed up the process.\n",
    "\n",
    "    Key Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Random seed for generating the ground-truth trajectory.\n",
    "        IMPORTANT: use a different seed for each process to avoid repetition.\n",
    "    dt : int\n",
    "        Time step in minutes for the trajectory generation.\n",
    "    sim_tasks : pd.DataFrame\n",
    "        DataFrame containing the simulation configurations to run for each seed. \n",
    "        Includes parameters (beta_start, beta_dur, beta_ping, algorithm, ha).\n",
    "    agent_home, agent_workplace : str\n",
    "        Identifiers for the agent's home and workplace buildings.\n",
    "    destinations : pd.DataFrame\n",
    "        DataFrame containing the destination diary for the agent.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrames to store metrics for this seed\n",
    "    seed_all_metrics_df = pd.DataFrame()\n",
    "    seed_metrics_size_df = pd.DataFrame()\n",
    "    seed_metrics_btype_df = pd.DataFrame()\n",
    "    seed_metrics_dwell_df = pd.DataFrame()\n",
    "\n",
    "    # Initialize the agent and generate a trajectory with a destination diary\n",
    "    agent = Agent(\n",
    "        identifier=\"Charlie\",\n",
    "        home=agent_home,\n",
    "        workplace=agent_workplace,\n",
    "        city=city\n",
    "    )\n",
    "    agent.generate_trajectory(\n",
    "        destination_diary=destinations,\n",
    "        dt=dt,\n",
    "        seed=seed)\n",
    "\n",
    "    # Get and prepare ground-truth diary\n",
    "    truth = agent.diary.copy()\n",
    "    truth = truth[truth['location'].notna()]\n",
    "    truth = truth.rename(columns={'location': 'building_id'})\n",
    "    truth['building_size'] = truth['building_id'].apply(classify_building_size_from_id)\n",
    "    truth['building_type'] = truth['building_id'].apply(classify_building_type_from_id)\n",
    "    truth['dwell_length'] = truth['duration'].apply(classify_dwell)\n",
    "\n",
    "    # Iterate over simulation configurations\n",
    "    for i, config in sim_tasks.iterrows():\n",
    "\n",
    "        # Extract simulation configuration\n",
    "        beta_start = config['beta_start']\n",
    "        beta_dur = config['beta_dur']\n",
    "        beta_ping = config['beta_ping']\n",
    "        algo = config['algorithm']\n",
    "        ha = config['ha']\n",
    "\n",
    "        # Sample sparse trajectory\n",
    "        agent.sample_trajectory(\n",
    "            beta_start,\n",
    "            beta_dur,\n",
    "            beta_ping,\n",
    "            seed=seed*100+i,\n",
    "            ha=ha,\n",
    "            replace_sparse_traj=True)\n",
    "        sparse = agent.sparse_traj.copy()\n",
    "\n",
    "        # Compute completeness (q)\n",
    "        # I have no clue why q_stat sometimes (very rarely) throws an exception...\n",
    "        try:\n",
    "            q = filters.q_stats(sparse, traj_cols=traj_cols)\n",
    "            q = q.loc[0, 'q_stat']\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # ----------- RUN STOP DETECTION -----------\n",
    "\n",
    "        if algo == 'ta-dbscan':\n",
    "            TIME_THRESH = dbscan_param['time_thresh']\n",
    "            DIST_THRESH = dbscan_param['dist_thresh']\n",
    "            MIN_PTS = dbscan_param['min_pts']\n",
    "            DUR_MIN = dbscan_param['dur_min']\n",
    "\n",
    "            labels = TADBSCAN._temporal_dbscan_labels(\n",
    "                data=sparse,\n",
    "                time_thresh=TIME_THRESH,\n",
    "                dist_thresh=DIST_THRESH,\n",
    "                min_pts=MIN_PTS,\n",
    "                dur_min=DUR_MIN,\n",
    "                traj_cols=traj_cols)\n",
    "            labels.name = 'cluster'\n",
    "            sparse_with_cluster = sparse.join(labels)\n",
    "\n",
    "        elif algo == 'lachesis':\n",
    "            TIME_THRESH = lachesis_param['dt_max']\n",
    "            DELTA_ROAM = lachesis_param['delta_roam']\n",
    "            DUR_MIN = lachesis_param['dur_min']\n",
    "\n",
    "            labels = LACHESIS._lachesis_labels(\n",
    "                data=sparse,\n",
    "                dt_max=TIME_THRESH,\n",
    "                dur_min=DUR_MIN,\n",
    "                delta_roam=DELTA_ROAM,\n",
    "                traj_cols=traj_cols)\n",
    "            labels.name = 'cluster'\n",
    "            sparse_with_cluster = sparse.join(labels)\n",
    "\n",
    "        else:\n",
    "            print(f\"Algorithm {algo} not in the list! (Seed: {seed})\")\n",
    "            continue \n",
    "\n",
    "        # ----------- PREDICT STOPS FROM LABELS -----------\n",
    "\n",
    "        pred = visits.point_in_polygon(\n",
    "            data=sparse_with_cluster,\n",
    "            poi_table=poi_table,\n",
    "            method='majority',\n",
    "            data_crs='EPSG:4326',\n",
    "            max_distance=15,\n",
    "            cluster_label='cluster',\n",
    "            location_id='building_id',\n",
    "            x='x',\n",
    "            y='y')\n",
    "\n",
    "        pred = sparse_with_cluster.join(pred)\n",
    "        stops = pred[pred.cluster!=-1].groupby('cluster', as_index=False).apply(\n",
    "            summarize_stops_with_loc, include_groups=False)\n",
    "\n",
    "        # ----------- REMOVING OVERLAPS (POST PROCESSING) -----------\n",
    "\n",
    "        if stops.empty:\n",
    "            expected_stop_columns = [\n",
    "                'cluster', 'x', 'y', 'start_timestamp', 'ha', 'diameter', 'n_pings',\n",
    "                'end_timestamp', 'duration', 'max_gap', 'building_id']\n",
    "            stops = pd.DataFrame(columns=expected_stop_columns)\n",
    "\n",
    "        try:\n",
    "            utils.invalid_stops(stops)\n",
    "        except Exception: \n",
    "            stops = pp.remove_overlaps(\n",
    "                sparse_with_cluster, \n",
    "                time_thresh=TIME_THRESH,\n",
    "                min_pts=MIN_PTS,\n",
    "                dur_min=DUR_MIN,\n",
    "                traj_cols=traj_cols,\n",
    "                post_processing='polygon')\n",
    "\n",
    "        stops['building_id'] = stops['building_id'].astype(str)\n",
    "\n",
    "        # Create stop table with filled gaps (for F1 computation)\n",
    "        first_time = truth['timestamp'].iloc[0]\n",
    "        last_time = truth['timestamp'].iloc[-1] + truth['duration'].iloc[-1] * 60\n",
    "        stops_filled = pp.fill_timestamp_gaps(first_time, last_time, stops)\n",
    "\n",
    "        # ----------- COMPUTE METRICS OF INTEREST -----------\n",
    "\n",
    "        # general metrics\n",
    "        overlaps = overlapping_visits(\n",
    "            left=stops,\n",
    "            right=truth,\n",
    "            location_id='building_id',\n",
    "            match_location=False)\n",
    "\n",
    "        overlaps_filled = overlapping_visits(\n",
    "            left=stops_filled, \n",
    "            right=truth, \n",
    "            location_id='building_id', \n",
    "            match_location=False)\n",
    "\n",
    "        errors = compute_visitation_errors(\n",
    "            overlaps=overlaps,\n",
    "            true_visits=truth,\n",
    "            location_id='building_id')\n",
    "\n",
    "        prf1 = compute_precision_recall_f1(\n",
    "            overlaps=overlaps_filled,\n",
    "            pred_visits=stops,\n",
    "            true_visits=truth,\n",
    "            location_id='building_id')\n",
    "\n",
    "        all_metrics = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                       'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                       'seed': seed, 'algorithm': algo, 'noise': ha,\n",
    "                       'q': q}\n",
    "        seed_all_metrics_df = pd.concat([seed_all_metrics_df, pd.DataFrame([all_metrics])], ignore_index=True)\n",
    "\n",
    "        # size metrics\n",
    "        stops_attr = stops.merge(\n",
    "            poi_table[['building_id', 'building_size', 'building_type']], on='building_id')\n",
    "        stops_filled_attr = stops_filled.merge(\n",
    "            poi_table[['building_id', 'building_size', 'building_type']], on='building_id')\n",
    "\n",
    "        for build_size in ['small', 'medium', 'big']:\n",
    "            if (truth.building_size==build_size).sum()==0:\n",
    "                continue\n",
    "\n",
    "            truth_subset = truth.loc[truth.building_size==build_size]\n",
    "\n",
    "            overlaps = overlapping_visits(\n",
    "                left=stops_attr,\n",
    "                right=truth_subset,\n",
    "                location_id='building_id',\n",
    "                match_location=False)\n",
    "\n",
    "            overlaps_filled = overlapping_visits(\n",
    "                left=stops_filled_attr, \n",
    "                right=truth_subset, \n",
    "                location_id='building_id', \n",
    "                match_location=False)\n",
    "\n",
    "            errors = compute_visitation_errors(\n",
    "                overlaps=overlaps,\n",
    "                true_visits=truth_subset,\n",
    "                location_id='building_id')\n",
    "\n",
    "            prf1 = compute_precision_recall_f1(\n",
    "                overlaps=overlaps_filled,\n",
    "                pred_visits=stops_filled_attr,\n",
    "                true_visits=truth_subset,\n",
    "                location_id='building_id')\n",
    "\n",
    "            metrics_size = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                            'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                            'seed': seed, 'algorithm': algo, 'noise': ha,\n",
    "                            'q': q}\n",
    "            seed_metrics_size_df = pd.concat([seed_metrics_size_df, pd.DataFrame([metrics_size])], ignore_index=True)\n",
    "\n",
    "        # btype metrics\n",
    "        for building_type in ['home', 'retail', 'work', 'park']:\n",
    "            if (truth.building_type==building_type).sum() == 0:\n",
    "                continue\n",
    "\n",
    "            truth_subset = truth.loc[truth.building_type==building_type]\n",
    "\n",
    "            overlaps = overlapping_visits(\n",
    "                left=stops_attr,\n",
    "                right=truth_subset,\n",
    "                location_id='building_id',\n",
    "                match_location=False)\n",
    "\n",
    "            overlaps_filled = overlapping_visits(\n",
    "                left=stops_filled_attr, \n",
    "                right=truth_subset, \n",
    "                location_id='building_id', \n",
    "                match_location=False)\n",
    "\n",
    "            errors = compute_visitation_errors(\n",
    "                overlaps=overlaps,\n",
    "                true_visits=truth_subset,\n",
    "                location_id='building_id')\n",
    "\n",
    "            prf1 = compute_precision_recall_f1(\n",
    "                overlaps=overlaps_filled,\n",
    "                pred_visits=stops_filled_attr,\n",
    "                true_visits=truth_subset,\n",
    "                location_id='building_id')\n",
    "\n",
    "            metrics_btype = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                             'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                             'seed': seed, 'algorithm': algo, 'noise': ha,\n",
    "                             'q': q}\n",
    "            seed_metrics_btype_df = pd.concat([seed_metrics_btype_df, pd.DataFrame([metrics_btype])], ignore_index=True)\n",
    "\n",
    "        # dwell metrics\n",
    "        for dwell_length in ['low', 'mid', 'high']:    \n",
    "            if (truth.dwell_length==dwell_length).sum() == 0:\n",
    "                continue\n",
    "\n",
    "            truth_subset = truth.loc[truth.dwell_length==dwell_length]\n",
    "\n",
    "            overlaps = overlapping_visits(\n",
    "                left=stops_attr,\n",
    "                right=truth_subset,\n",
    "                location_id='building_id',\n",
    "                match_location=False)\n",
    "\n",
    "            overlaps_filled = overlapping_visits(\n",
    "                left=stops_filled_attr, \n",
    "                right=truth_subset, \n",
    "                location_id='building_id', \n",
    "                match_location=False)\n",
    "\n",
    "            errors = compute_visitation_errors(\n",
    "                overlaps=overlaps,\n",
    "                true_visits=truth_subset,\n",
    "                location_id='building_id')\n",
    "\n",
    "            prf1 = compute_precision_recall_f1(\n",
    "                overlaps=overlaps_filled,\n",
    "                pred_visits=stops_filled_attr,\n",
    "                true_visits=truth_subset,\n",
    "                location_id='building_id')\n",
    "\n",
    "            metrics_dwell = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                             'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                             'seed': seed, 'algorithm': algo, 'noise': ha,\n",
    "                             'q': q}\n",
    "            seed_metrics_dwell_df = pd.concat([seed_metrics_dwell_df, pd.DataFrame([metrics_dwell])], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished simulation for seed {seed} on process {os.getpid()}\")\n",
    "    return seed_all_metrics_df, seed_metrics_size_df, seed_metrics_btype_df, seed_metrics_dwell_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad4e85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure: Demonstrate Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15bada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = pd.date_range(start='2024-06-01 00:00-04:00', periods=4, freq='60min')\n",
    "tz_offset = loader._offset_seconds_from_ts(start_time[0])\n",
    "unix_timestamp = [int(t.timestamp()) for t in start_time]\n",
    "duration = [60]*4  # in minutes\n",
    "location = ['h-x13-y11'] * 1 + ['h-x13-y9'] * 1 + ['w-x18-y10'] * 1 + ['w-x18-y8'] * 1\n",
    "\n",
    "destinations = pd.DataFrame(\n",
    "    {\"datetime\":start_time,\n",
    "     \"timestamp\":unix_timestamp,\n",
    "     \"duration\":duration,\n",
    "     \"location\":location}\n",
    "     )\n",
    "destinations = tg.condense_destinations(destinations)\n",
    "\n",
    "traj_cols = {'user_id':'identifier',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed485bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    4, 2, figsize=(10, 11),\n",
    "    gridspec_kw={'height_ratios': [4.7, 0.3, 4.7, 0.3], 'hspace': 0.3, 'wspace': 0.1})\n",
    "colors = {'home': 'lightgrey','work': 'lightgrey', 'retail': 'lightgrey', 'park': 'lightgrey'}\n",
    "\n",
    "Charlie = Agent(identifier=\"Charlie\",\n",
    "                home='h-x13-y11',\n",
    "                workplace='w-x18-y8',\n",
    "                city=city)\n",
    "Charlie.generate_trajectory(destination_diary=destinations, seed=2025, dt=0.25)\n",
    "\n",
    "# --- Top Left Subplot: Correct ---\n",
    "\n",
    "Charlie.sample_trajectory(beta_start=None,\n",
    "                          beta_durations=None,\n",
    "                          beta_ping=4,\n",
    "                          seed=42,\n",
    "                          ha=3/5,\n",
    "                          replace_sparse_traj=True,\n",
    "                          deduplicate=True)\n",
    "labels = TADBSCAN._temporal_dbscan_labels(\n",
    "    data=Charlie.sparse_traj,\n",
    "    time_thresh=600,\n",
    "    dist_thresh=0.8,\n",
    "    min_pts=3,\n",
    "    dur_min=5,\n",
    "    traj_cols=traj_cols)\n",
    "\n",
    "city.plot_city(axes[0, 0], doors=True, address=False, zorder=0, colors=colors)\n",
    "tg.plot_sparse_clusters(Charlie.sparse_traj, labels.cluster, axes[0, 0],\n",
    "                        full_traj=Charlie.trajectory, buffer=0.5)\n",
    "axes[0, 0].set_title('A) Correct', fontsize=14, pad=10, fontweight='bold')\n",
    "\n",
    "# Barcode\n",
    "timestamps = Charlie.sparse_traj.timestamp\n",
    "axes[1, 0].vlines(timestamps, ymin=0, ymax=1, colors='black', lw=0.5)\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "axes[1, 0].set_yticks([])\n",
    "axes[1, 0].set_xticks([])\n",
    "axes[1, 0].set_yticklabels([])\n",
    "axes[1, 0].set_title('Mean Time Between Pings = 4 min', fontsize=10, pad=10, loc='left')\n",
    "\n",
    "# --- Top Right Subplot: Splitting ---\n",
    "Charlie.sample_trajectory(beta_start=None,\n",
    "                          beta_durations=None,\n",
    "                          beta_ping=8,\n",
    "                          seed=234,\n",
    "                          ha=3/5,\n",
    "                          replace_sparse_traj=True,\n",
    "                          deduplicate=True)\n",
    "labels = LACHESIS._lachesis_labels(\n",
    "    data=Charlie.sparse_traj,\n",
    "    dt_max=600,\n",
    "    delta_roam=1.5,\n",
    "    dur_min=5,\n",
    "    traj_cols=traj_cols)\n",
    "\n",
    "city.plot_city(axes[0, 1], doors=True, address=False, zorder=0, colors=colors)\n",
    "tg.plot_sparse_clusters(Charlie.sparse_traj, labels, axes[0, 1],\n",
    "                        full_traj=Charlie.trajectory, buffer=0.5)\n",
    "axes[0, 1].set_title('B) Splitting', fontsize=14, pad=10, fontweight='bold')\n",
    "\n",
    "# Barcode\n",
    "timestamps = Charlie.sparse_traj.timestamp\n",
    "axes[1, 1].vlines(timestamps, ymin=0, ymax=1, colors='black', lw=0.5)\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "axes[1, 1].set_yticks([])\n",
    "axes[1, 1].set_xticks([])\n",
    "axes[1, 1].set_yticklabels([])\n",
    "axes[1, 1].set_title('Mean Time Between Pings = 8 min', fontsize=10, pad=10, loc='left')\n",
    "\n",
    "# --- Bottom Left Subplot: Merging ---\n",
    "\n",
    "Charlie.sample_trajectory(beta_start=None,\n",
    "                          beta_durations=None,\n",
    "                          beta_ping=12,\n",
    "                          seed=100,\n",
    "                          ha=3/5,\n",
    "                          replace_sparse_traj=True,\n",
    "                          deduplicate=True)\n",
    "labels = TADBSCAN._temporal_dbscan_labels(\n",
    "    data=Charlie.sparse_traj,\n",
    "    time_thresh=600,\n",
    "    dist_thresh=1.2,\n",
    "    min_pts=3,\n",
    "    dur_min=5,\n",
    "    traj_cols=traj_cols)\n",
    "\n",
    "city.plot_city(axes[2, 0], doors=True, address=False, zorder=0, colors=colors)\n",
    "tg.plot_sparse_clusters(Charlie.sparse_traj, labels.cluster, axes[2, 0],\n",
    "                        full_traj=Charlie.trajectory, buffer=0.5)\n",
    "axes[2, 0].set_title('C) Merging', fontsize=14, pad=10, fontweight='bold')\n",
    "\n",
    "# Barcode\n",
    "timestamps = Charlie.sparse_traj.timestamp\n",
    "axes[3, 0].vlines(timestamps, ymin=0, ymax=1, colors='black', lw=0.5)\n",
    "axes[3, 0].set_ylim(0, 1)\n",
    "axes[3, 0].set_yticks([])\n",
    "axes[3, 0].set_xticks([])\n",
    "axes[3, 0].set_yticklabels([])\n",
    "axes[3, 0].set_title('Mean Time Between Pings = 12 min', fontsize=10, pad=10, loc='left')\n",
    "\n",
    "# --- Bottom Right Subplot: Missing ---\n",
    "Charlie.sample_trajectory(beta_start=None,\n",
    "                          beta_durations=None,\n",
    "                          beta_ping=25,\n",
    "                          seed=1250,\n",
    "                          ha=3/5,\n",
    "                          replace_sparse_traj=True,\n",
    "                          deduplicate=True)\n",
    "labels = LACHESIS._lachesis_labels(\n",
    "    data=Charlie.sparse_traj,\n",
    "    dt_max=600,\n",
    "    delta_roam=2,\n",
    "    dur_min=5,\n",
    "    traj_cols=traj_cols)\n",
    "\n",
    "city.plot_city(axes[2, 1], doors=True, address=False, zorder=0, colors=colors)\n",
    "tg.plot_sparse_clusters(Charlie.sparse_traj, labels, axes[2, 1],\n",
    "                        full_traj=Charlie.trajectory, buffer=0.5)\n",
    "axes[2, 1].set_title('D) Missing', fontsize=14, pad=10, fontweight='bold')\n",
    "\n",
    "# Barcode\n",
    "timestamps = Charlie.sparse_traj.timestamp\n",
    "axes[3, 1].vlines(timestamps, ymin=0, ymax=1, colors='black', lw=0.5)\n",
    "axes[3, 1].set_ylim(0, 1)\n",
    "axes[3, 1].set_yticks([])\n",
    "axes[3, 1].set_xticks([])\n",
    "axes[3, 1].set_yticklabels([])\n",
    "axes[3, 1].set_title('Mean Time Between Pings = 25 min', fontsize=10, pad=10, loc='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all-problems.png\", dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8721423",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 1.1\n",
    "\n",
    "Demonstrates merging. We specify four neighboring small stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1dc60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = pd.date_range(start='2024-06-01 00:00-04:00', periods=4, freq='60min')\n",
    "tz_offset = loader._offset_seconds_from_ts(start_time[0])\n",
    "unix_timestamp = [int(t.timestamp()) for t in start_time]\n",
    "duration = [60]*4  # in minutes\n",
    "location = ['h-x13-y11'] * 1 + ['h-x13-y9'] * 1 + ['w-x18-y10'] * 1 + ['w-x18-y8'] * 1\n",
    "\n",
    "destinations = pd.DataFrame(\n",
    "    {\"datetime\":start_time,\n",
    "     \"timestamp\":unix_timestamp,\n",
    "     \"duration\":duration,\n",
    "     \"location\":location}\n",
    "     )\n",
    "destinations = tg.condense_destinations(destinations)\n",
    "\n",
    "traj_cols = {'user_id':'identifier',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905cc7c",
   "metadata": {},
   "source": [
    "Example plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ab12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Charlie = Agent(identifier=\"Charlie\",\n",
    "                home='h-x13-y11',\n",
    "                workplace='w-x18-y8',\n",
    "                city=city)\n",
    "\n",
    "Charlie.generate_trajectory(destination_diary=destinations, seed=234, dt=0.25)\n",
    "Charlie.sample_trajectory(beta_start=None,\n",
    "                          beta_durations=None,\n",
    "                          beta_ping=6,\n",
    "                          seed=2,\n",
    "                          ha=3/4,\n",
    "                          replace_sparse_traj=True,\n",
    "                          deduplicate=True)\n",
    "\n",
    "dbscan_labels = TADBSCAN._temporal_dbscan_labels(\n",
    "    data=Charlie.sparse_traj,\n",
    "    time_thresh=600,\n",
    "    dist_thresh=0.8,\n",
    "    min_pts=3,\n",
    "    dur_min=5,\n",
    "    traj_cols=traj_cols)\n",
    "\n",
    "lachesis_labels = LACHESIS._lachesis_labels(\n",
    "    data=Charlie.sparse_traj,\n",
    "    dt_max=600,\n",
    "    delta_roam=2.5,\n",
    "    dur_min=5,\n",
    "    traj_cols=traj_cols)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "# --- Left Subplot: DBSCAN ---\n",
    "city.plot_city(axes[0], doors=True, address=False, zorder=0)\n",
    "tg.plot_sparse_clusters(Charlie.sparse_traj, dbscan_labels.cluster, axes[0],\n",
    "                        full_traj=Charlie.trajectory, buffer=0.5)\n",
    "axes[0].set_title('A) DBSCAN', fontsize=14, pad=10)\n",
    "\n",
    "# --- Right Subplot: Lachesis ---\n",
    "city.plot_city(axes[1], doors=True, address=False, zorder=0)\n",
    "tg.plot_sparse_clusters(Charlie.sparse_traj, lachesis_labels, axes[1],\n",
    "                        full_traj=Charlie.trajectory, buffer=0.5)\n",
    "axes[1].set_title('B) Lachesis', fontsize=14, pad=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"exp1-merging.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6a5cb",
   "metadata": {},
   "source": [
    "Set up simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81731c9-dbec-4c56-9ad9-672fa51f3c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BETA_START = [None]\n",
    "BETA_DUR = [None]\n",
    "BETA_PING = np.arange(2, 25.5, 0.5).tolist()\n",
    "ALGOS = ['ta-dbscan', 'lachesis']\n",
    "HOR_ACC = [3/4]\n",
    "\n",
    "dbscan_param = dict(time_thresh=600, dist_thresh=0.8, min_pts=3, dur_min=5)\n",
    "lachesis_param = dict(dur_min=5, dt_max=600, delta_roam=2)\n",
    "\n",
    "N_sim = 1000  # Number of times to run each simulation task (i.e., number of seeds)\n",
    "\n",
    "# Generate all combinations of simulation parameters\n",
    "sim_tasks = list(itertools.product(\n",
    "    BETA_START,\n",
    "    BETA_DUR,\n",
    "    BETA_PING,\n",
    "    ALGOS,\n",
    "    HOR_ACC\n",
    "))\n",
    "sim_tasks = pd.DataFrame(sim_tasks, columns=['beta_start', 'beta_dur', 'beta_ping', 'algorithm', 'ha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c31938",
   "metadata": {},
   "source": [
    "The following code parallelizes the simulation. Run it on Sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb191be-7bb7-4ac0-816b-a79c83b3f78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PARALLELIZED CODE (RUN ON SAGEMAKER)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Set up simulation\n",
    "    dt = 0.25\n",
    "    agent_home='h-x13-y11'\n",
    "    agent_workplace='w-x18-y8'\n",
    "\n",
    "    seeds_to_run = range(N_sim)\n",
    "\n",
    "    # Determine the number of CPU cores to use.\n",
    "    num_processes = cpu_count()\n",
    "    print(f\"Starting multiprocessing pool with {num_processes} processes.\")\n",
    "\n",
    "    parallel_args = [\n",
    "        (seed, dt, sim_tasks, agent_home, agent_workplace, destinations, \n",
    "         dbscan_param, lachesis_param, traj_cols, summarize_stops_with_loc)\n",
    "        for seed in seeds_to_run\n",
    "    ]\n",
    "\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = list(tqdm(pool.starmap(run_simulation_for_single_seed, parallel_args),\n",
    "                            total=len(parallel_args), desc=\"Overall Simulation Progress\"))\n",
    "\n",
    "    print(\"All individual seed simulations completed. Aggregating results...\")\n",
    "\n",
    "    # Initialize empty lists to store results from each simulation\n",
    "    all_metrics_combined_list = []\n",
    "    metrics_size_combined_list = []\n",
    "    metrics_btype_combined_list = []\n",
    "    metrics_dwell_combined_list = []\n",
    "\n",
    "    # Unpack and append results from each parallel run\n",
    "    for res_all_metrics_df, res_metrics_size_df, res_metrics_btype_df, res_metrics_dwell_df in results:\n",
    "        all_metrics_combined_list.append(res_all_metrics_df)\n",
    "        metrics_size_combined_list.append(res_metrics_size_df)\n",
    "        metrics_btype_combined_list.append(res_metrics_btype_df)\n",
    "        metrics_dwell_combined_list.append(res_metrics_dwell_df)\n",
    "\n",
    "    # Concatenate all the individual dataframes into final aggregate dataframes\n",
    "    all_metrics_df = pd.concat(all_metrics_combined_list, ignore_index=True)\n",
    "    metrics_size_df = pd.concat(metrics_size_combined_list, ignore_index=True)\n",
    "    metrics_btype_df = pd.concat(metrics_btype_combined_list, ignore_index=True)\n",
    "    metrics_dwell_df = pd.concat(metrics_dwell_combined_list, ignore_index=True)\n",
    "\n",
    "    # Create a dictionary to hold all your DataFrames\n",
    "    all_results = {\n",
    "        'all_metrics': all_metrics_df,\n",
    "        'metrics_size': metrics_size_df,\n",
    "        'metrics_btype': metrics_btype_df,\n",
    "        'metrics_dwell': metrics_dwell_df\n",
    "    }\n",
    "\n",
    "    # Define the filename for your pickle file\n",
    "    output_filename = 'exp1a_results.pkl'\n",
    "\n",
    "    # Pickle the dictionary to a file\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b7155-1f52-4255-9cfb-f840950e8314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the results from the pickle file\n",
    "with open('exp1a_results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    all_metrics_df = results['all_metrics']\n",
    "    metrics_size_df = results['metrics_size']\n",
    "    metrics_btype_df = results['metrics_btype']\n",
    "    metrics_dwell_df = results['metrics_dwell']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e416d12",
   "metadata": {},
   "source": [
    "Create Exp 1a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd600c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for plotting\n",
    "chart_df1 = all_metrics_df.groupby(['beta_ping', 'algorithm'])['merged_fraction'].agg(['mean', 'sem']).reset_index()\n",
    "chart_df1.rename(columns={'mean': 'merged_fraction_mean', 'sem': 'merged_fraction_sem'}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=chart_df1,\n",
    "    x='beta_ping',\n",
    "    y='merged_fraction_mean',\n",
    "    hue='algorithm',\n",
    "    marker='',\n",
    "    linewidth=3,\n",
    "    ax=ax,\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "ax.set_title('Impact of Ping Frequency on Stop Merging', fontsize=16, pad=10, fontweight='bold')\n",
    "ax.set_xlabel('Mean Time Between Pings (in Minutes)', fontsize=13, labelpad=10)\n",
    "ax.set_ylabel('Proportion of Stops Merged', fontsize=13, labelpad=10)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labels = ['DBSCAN', 'Lachesis']\n",
    "ax.legend(title='Algorithm', labels=labels, handles=handles,\n",
    "          bbox_to_anchor=(0.98, 0.98), loc='upper right', \n",
    "          borderaxespad=0., fontsize=12, title_fontsize=14, frameon=True)\n",
    "\n",
    "ax.grid(True, linestyle=':', alpha=0.6, linewidth=0.7)\n",
    "ax.tick_params(axis='both', which='major', labelsize=11, length=6, width=1.2)\n",
    "ax.tick_params(axis='both', which='minor', length=3, width=0.8)\n",
    "ax.minorticks_on() \n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"exp1a-merging.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42576772-5d38-42b3-b2b7-a278f9181ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 1.2\n",
    "\n",
    "Demonstrates splitting and missing. We specify 5 stops of varying areas and dwell times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16efe8-ed57-4244-bddd-4ce69dc9de2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tz = ZoneInfo(\"America/New_York\")\n",
    "start_time = pd.date_range(start='2024-06-01 03:00', periods=18, freq='60min', tz=tz)\n",
    "unix_timestamp = [int(t.timestamp()) for t in start_time]\n",
    "duration = [60]*18  # in minutes\n",
    "location = ['h-x13-y6'] * 7 + ['r-x15-y0'] * 1 + ['w-x18-y13'] * 6 + ['r-x18-y5'] * 1 + ['p-x13-y11'] * 3\n",
    "\n",
    "destinations = pd.DataFrame(\n",
    "    {\"datetime\":start_time,\n",
    "     \"timestamp\":unix_timestamp,\n",
    "     \"duration\":duration,\n",
    "     \"location\":location}\n",
    "     )\n",
    "destinations = tg.condense_destinations(destinations)\n",
    "\n",
    "traj_cols = {'user_id':'identifier',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e630cbb-10dc-437c-b8f1-372fc4085391",
   "metadata": {},
   "source": [
    "Example plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ba2b8-b20f-489a-a551-4dd3819e2557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo = 'ta-dbscan'  # or 'lachesis'\n",
    "\n",
    "Charlie = Agent(identifier=\"Charlie\",\n",
    "                home='h-x13-y11',\n",
    "                workplace='w-x18-y8',\n",
    "                city=city)\n",
    "\n",
    "Charlie.generate_trajectory(destination_diary=destinations, dt=0.25, seed=300)\n",
    "Charlie.sample_trajectory(*(20, 45, 10), seed=300, replace_sparse_traj=True)\n",
    "\n",
    "if algo == 'ta-dbscan':\n",
    "    labels = TADBSCAN._temporal_dbscan_labels(\n",
    "        data=Charlie.sparse_traj,\n",
    "        time_thresh=90,\n",
    "        dist_thresh=2,\n",
    "        min_pts=2,\n",
    "        traj_cols=traj_cols)\n",
    "    \n",
    "elif algo == 'lachesis':\n",
    "    labels = LACHESIS._lachesis_labels(\n",
    "        data=Charlie.sparse_traj,\n",
    "        dt_max=20,\n",
    "        delta_roam=75,\n",
    "        dur_min=2,\n",
    "        traj_cols=traj_cols)\n",
    "    \n",
    "labels.name = 'cluster'\n",
    "sparse_with_cluster = Charlie.sparse_traj.join(labels)\n",
    "\n",
    "pred = visits.point_in_polygon(\n",
    "    data=sparse_with_cluster,\n",
    "    poi_table=poi_table,\n",
    "    method='majority',\n",
    "    data_crs='EPSG:4326',\n",
    "    max_distance=15,\n",
    "    cluster_label='cluster',\n",
    "    location_id='building_id',\n",
    "    x='x',\n",
    "    y='y')\n",
    "\n",
    "pred = sparse_with_cluster.join(pred)\n",
    "stops = pred[pred.cluster!=-1].groupby('cluster', as_index=False).apply(\n",
    "    summarize_stops_with_loc, include_groups=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "city.plot_city(ax, doors=True, address=False, zorder=0)\n",
    "\n",
    "tg.plot_sparse_clusters(\n",
    "    Charlie.sparse_traj, \n",
    "    labels.cluster, # or simply `labels``, if Lachesis\n",
    "    ax,\n",
    "    full_traj=Charlie.trajectory, \n",
    "    buffer=0.25)\n",
    "\n",
    "# plt.savefig(\"exp2-splitting-dbscan.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b508bf58",
   "metadata": {},
   "source": [
    "Set up simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172279eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXP_Q = 0.4\n",
    "BETA_START = np.arange(10, 200, 10)\n",
    "BETA_PING = [10]\n",
    "ALGOS = ['ta-dbscan', 'lachesis']\n",
    "HOR_ACC = [3/4]\n",
    "\n",
    "dbscan_param = dict(time_thresh=90, dist_thresh=1.2, min_pts=2, dur_min=5)\n",
    "lachesis_param = dict(dur_min=5, dt_max=90, delta_roam=2)\n",
    "\n",
    "N_sim = 1000  # Number of times to run each simulation task (i.e., number of seeds)\n",
    "\n",
    "# Generate all combinations of simulation parameters\n",
    "sim_tasks = list(itertools.product(\n",
    "    BETA_START,\n",
    "    BETA_PING,\n",
    "    ALGOS,\n",
    "    HOR_ACC\n",
    "))\n",
    "sim_tasks = pd.DataFrame(sim_tasks, columns=['beta_start', 'beta_ping', 'algorithm', 'ha'])\n",
    "sim_tasks['beta_dur'] = sim_tasks['beta_start'] * EXP_Q\n",
    "\n",
    "agent = Agent(\n",
    "    identifier=\"Charlie\",\n",
    "    home='h-x13-y11',\n",
    "    workplace='w-x18-y8',\n",
    "    city=city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d3977",
   "metadata": {},
   "source": [
    "The following code parallelizes the simulation. Run it on Sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1fdedc-98ca-46df-92d0-781140fffea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PARALLELIZED CODE (RUN ON SAGEMAKER)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dt_val = 0.25\n",
    "    agent_home='h-x13-y11'\n",
    "    agent_workplace='w-x18-y8'\n",
    "\n",
    "    seeds_to_run = range(N_sim)\n",
    "\n",
    "    # Determine the number of CPU cores to use.\n",
    "    num_processes = cpu_count()\n",
    "    print(f\"Starting multiprocessing pool with {num_processes} processes.\")\n",
    "\n",
    "    parallel_args = [\n",
    "        (seed, dt_val, sim_tasks, agent_home, agent_workplace, destinations,\n",
    "         dbscan_param, lachesis_param, traj_cols, summarize_stops_with_loc)\n",
    "        for seed in seeds_to_run\n",
    "    ]\n",
    "\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = list(tqdm(pool.starmap(run_simulation_for_single_seed, parallel_args),\n",
    "                            total=len(parallel_args), desc=\"Overall Simulation Progress\"))\n",
    "\n",
    "    print(\"All individual seed simulations completed. Aggregating results...\")\n",
    "\n",
    "    # Initialize empty lists to store results from each simulation\n",
    "    all_metrics_combined_list = []\n",
    "    metrics_size_combined_list = []\n",
    "    metrics_btype_combined_list = []\n",
    "    metrics_dwell_combined_list = []\n",
    "\n",
    "    # Unpack and append results from each parallel run\n",
    "    for res_all_metrics_df, res_metrics_size_df, res_metrics_btype_df, res_metrics_dwell_df in results:\n",
    "        all_metrics_combined_list.append(res_all_metrics_df)\n",
    "        metrics_size_combined_list.append(res_metrics_size_df)\n",
    "        metrics_btype_combined_list.append(res_metrics_btype_df)\n",
    "        metrics_dwell_combined_list.append(res_metrics_dwell_df)\n",
    "\n",
    "    # Concatenate all the individual dataframes into final aggregate dataframes\n",
    "    all_metrics_df = pd.concat(all_metrics_combined_list, ignore_index=True)\n",
    "    metrics_size_df = pd.concat(metrics_size_combined_list, ignore_index=True)\n",
    "    metrics_btype_df = pd.concat(metrics_btype_combined_list, ignore_index=True)\n",
    "    metrics_dwell_df = pd.concat(metrics_dwell_combined_list, ignore_index=True)\n",
    "\n",
    "    # Create a dictionary to hold all your DataFrames\n",
    "    all_results = {\n",
    "        'all_metrics': all_metrics_df,\n",
    "        'metrics_size': metrics_size_df,\n",
    "        'metrics_btype': metrics_btype_df,\n",
    "        'metrics_dwell': metrics_dwell_df\n",
    "    }\n",
    "\n",
    "    # Define the filename for your pickle file\n",
    "    output_filename = 'exp1b_results.pkl'\n",
    "\n",
    "    # Pickle the dictionary to a file\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6f140-b8ef-442e-a28a-63b8283f71d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the results from the pickle file\n",
    "with open('exp1b_results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    all_metrics_df = results['all_metrics']\n",
    "    metrics_size_df = results['metrics_size']\n",
    "    metrics_btype_df = results['metrics_btype']\n",
    "    metrics_dwell_df = results['metrics_dwell']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca303008",
   "metadata": {},
   "source": [
    "Create Exp 1b plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f5465-f17f-47d4-94f2-12b4d0498f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate mean and standard error of the mean for each metric\n",
    "chart_df2 = all_metrics_df.groupby(['beta_start', 'algorithm']).agg(\n",
    "    split_fraction_mean=('split_fraction', 'mean'),\n",
    "    split_fraction_sem=('split_fraction', 'sem'),\n",
    "    missed_fraction_mean=('missed_fraction', 'mean'),\n",
    "    missed_fraction_sem=('missed_fraction', 'sem')\n",
    ").reset_index()\n",
    "\n",
    "chart_df2['both_mean'] = chart_df2['split_fraction_mean'] + chart_df2['missed_fraction_mean']\n",
    "chart_df2['both_sem'] = (chart_df2['split_fraction_sem']**2 + chart_df2['missed_fraction_sem']**2)**0.5\n",
    "\n",
    "chart_df2_dbscan = chart_df2[chart_df2.algorithm == 'ta-dbscan']\n",
    "chart_df2_lachesis = chart_df2[chart_df2.algorithm == 'lachesis']\n",
    "\n",
    "# --- Charting ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 5), sharey=True)\n",
    "colors = sns.color_palette(\"tab10\", n_colors=3)\n",
    "\n",
    "# Plot for DBSCAN (Left Subplot)\n",
    "sns.lineplot(\n",
    "    data=chart_df2_dbscan,\n",
    "    x='beta_start',\n",
    "    y='split_fraction_mean',\n",
    "    ax=axes[0],\n",
    "    #label='Splitting',\n",
    "    marker='',\n",
    "    linewidth=3,\n",
    "    color=colors[0],\n",
    "    errorbar='se'\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=chart_df2_dbscan,\n",
    "    x='beta_start',\n",
    "    y='missed_fraction_mean',\n",
    "    ax=axes[0],\n",
    "    #label='Missing',\n",
    "    marker='',\n",
    "    linewidth=3,\n",
    "    color=colors[1],\n",
    "    errorbar='se'\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=chart_df2_dbscan,\n",
    "    x='beta_start',\n",
    "    y='both_mean',\n",
    "    ax=axes[0],\n",
    "    #label='Split or Missed',\n",
    "    linestyle='--',\n",
    "    linewidth=3,\n",
    "    color='gray',\n",
    "    marker='',\n",
    "    errorbar='se'\n",
    ")\n",
    "\n",
    "axes[0].set_title('A) DBSCAN Performance', fontsize=18, pad=10, fontweight='bold')\n",
    "axes[0].set_xlabel('Mean Time Between Bursts (in Minutes)', fontsize=14, labelpad=8)\n",
    "axes[0].set_ylabel('Proportion of Stops', fontsize=14, labelpad=8)\n",
    "axes[0].grid(True, linestyle=':', alpha=0.6, linewidth=0.7)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=10, length=5, width=1)\n",
    "axes[0].minorticks_on()\n",
    "axes[0].tick_params(axis='both', which='minor', length=2.5, width=0.7)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Plot for Lachesis (Right Subplot)\n",
    "sns.lineplot(\n",
    "    data=chart_df2_lachesis,\n",
    "    x='beta_start',\n",
    "    y='split_fraction_mean',\n",
    "    ax=axes[1],\n",
    "    #label='Splitting',\n",
    "    marker='',\n",
    "    linewidth=3,\n",
    "    color=colors[0],\n",
    "    errorbar='se'\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=chart_df2_lachesis,\n",
    "    x='beta_start',\n",
    "    y='missed_fraction_mean',\n",
    "    ax=axes[1],\n",
    "    #label='Missing',\n",
    "    marker='',\n",
    "    linewidth=3,\n",
    "    color=colors[1],\n",
    "    errorbar='se'\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=chart_df2_lachesis,\n",
    "    x='beta_start',\n",
    "    y='both_mean',\n",
    "    ax=axes[1],\n",
    "    #label='Split or Missed',\n",
    "    linestyle='--',\n",
    "    linewidth=3,\n",
    "    color='gray',\n",
    "    marker='',\n",
    "    errorbar='se'\n",
    ")\n",
    "axes[1].set_title('B) Lachesis Performance', fontsize=18, pad=10, fontweight='bold')\n",
    "axes[1].set_xlabel('Mean Time Between Bursts (in Minutes)', fontsize=14, labelpad=8)\n",
    "axes[1].grid(True, linestyle=':', alpha=0.6, linewidth=0.7)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=10, length=5, width=1)\n",
    "axes[1].minorticks_on()\n",
    "axes[1].tick_params(axis='both', which='minor', length=2.5, width=0.7)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "legend_labels = ['Splitting', 'Missing', 'Split or Missed']\n",
    "handles = [\n",
    "    axes[0].lines[0],\n",
    "    axes[0].lines[1],\n",
    "    axes[0].lines[2]\n",
    "]\n",
    "fig.legend(\n",
    "    handles,\n",
    "    legend_labels,\n",
    "    loc='lower center',\n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    ncol=len(legend_labels),\n",
    "    fontsize=16,\n",
    "    title_fontsize=18,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.savefig(\"exp1b-splitting-missing.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed9bdd",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "3 weeks of realistic trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b538f2c-9fd0-4891-96d8-ad80f4ab22fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize_stops_with_loc = partial(\n",
    "    utils.summarize_stop,\n",
    "    x='x',\n",
    "    y='y',\n",
    "    keep_col_names=False,\n",
    "    passthrough_cols=['building_id'],\n",
    "    complete_output=True)\n",
    "\n",
    "def run_simulation_for_single_agent(\n",
    "    agent_seed, dt, N_sim, dbscan_param, lachesis_param, \n",
    "    traj_cols, poi_table, city, summarize_stops_with_loc\n",
    "):\n",
    "    \"\"\"\n",
    "    This function performs the simulation for a single 'agent'.\n",
    "    It's designed to be run in a separate process for parallelization.\n",
    "    \"\"\"\n",
    "    # Initialize DataFrames to store metrics for this seed\n",
    "    seed_all_metrics_df = pd.DataFrame()\n",
    "    seed_metrics_size_df = pd.DataFrame()\n",
    "    seed_metrics_btype_df = pd.DataFrame()\n",
    "    seed_metrics_dwell_df = pd.DataFrame()\n",
    "\n",
    "    agent = Agent(\n",
    "        identifier=\"Charlie\",\n",
    "        city=city,\n",
    "        seed=agent_seed\n",
    "    )\n",
    "    agent.generate_trajectory(\n",
    "        datetime = \"2024-01-01T08:00 -04:00\",\n",
    "        end_time = pd.Timestamp('2024-01-21T08:30:00 -04:00'),\n",
    "        seed=agent_seed,\n",
    "        dt=dt)\n",
    "\n",
    "    # Get ground-truth diary\n",
    "    truth = agent.diary.copy()\n",
    "    truth = truth[truth['location'].notna()]\n",
    "    truth = truth.rename(columns={'location': 'building_id'})\n",
    "    truth['building_size'] = truth['building_id'].apply(classify_building_size_from_id)\n",
    "    truth['building_type'] = truth['building_id'].apply(classify_building_type_from_id)\n",
    "    truth['dwell_length'] = truth['duration'].apply(classify_dwell)\n",
    "\n",
    "    beta_params = gen_params_target_q(q_range=(0.4, 0.85), seed=agent_seed)\n",
    "    ha = np.random.uniform(10/15, 16/15, size=1)[0]\n",
    "\n",
    "    # Iterate over simulation configurations\n",
    "    for i in range(N_sim):\n",
    "        for algo in ['oracle', 'ta-dbscan', 'lachesis']:\n",
    "\n",
    "            # Extract simulation configuration\n",
    "            beta_start = beta_params['beta_start']\n",
    "            beta_dur = beta_params['beta_durations']\n",
    "            beta_ping = beta_params['beta_ping']\n",
    "            algo = algo\n",
    "            ha = ha\n",
    "\n",
    "            # Sample sparse trajectory\n",
    "            agent.sample_trajectory(\n",
    "                beta_start,\n",
    "                beta_dur,\n",
    "                beta_ping,\n",
    "                seed=i,\n",
    "                ha=ha,\n",
    "                replace_sparse_traj=True)\n",
    "            sparse = agent.sparse_traj.copy()\n",
    "\n",
    "            # Compute completeness (q)\n",
    "            q = filters.q_stats(sparse, traj_cols=traj_cols)\n",
    "            q = q.loc[0, 'q_stat']\n",
    "\n",
    "            # ----------- RUN STOP DETECTION -----------\n",
    "            if algo == 'oracle':\n",
    "                TIME_THRESH = dbscan_param['time_thresh']  # should be the same for dbscan and lachesis\n",
    "\n",
    "                # oracle says correct poi for each ping\n",
    "                location = visits.oracle_map(\n",
    "                    sparse,\n",
    "                    truth,\n",
    "                    timestamp='timestamp',\n",
    "                    location_id='building_id')\n",
    "                # find cluster labels with naive grid-based continuity\n",
    "                labels = GRID_BASED.grid_based_labels(\n",
    "                    data=sparse.join(location),\n",
    "                    time_thresh=TIME_THRESH,\n",
    "                    min_pts=0, #we allow stops of duration 0, patched later\n",
    "                    location_id='building_id',\n",
    "                    traj_cols=traj_cols)\n",
    "\n",
    "            elif algo == 'ta-dbscan':\n",
    "                TIME_THRESH = dbscan_param['time_thresh']\n",
    "                DIST_THRESH = dbscan_param['dist_thresh']\n",
    "                MIN_PTS = dbscan_param['min_pts']\n",
    "                DUR_MIN = dbscan_param['dur_min']\n",
    "\n",
    "                labels = TADBSCAN._temporal_dbscan_labels(\n",
    "                    data=sparse,\n",
    "                    time_thresh=TIME_THRESH,\n",
    "                    dist_thresh=DIST_THRESH,\n",
    "                    min_pts=MIN_PTS,\n",
    "                    dur_min=DUR_MIN,\n",
    "                    traj_cols=traj_cols)\n",
    "                labels.name = 'cluster'\n",
    "                sparse_with_cluster = sparse.join(labels)\n",
    "\n",
    "            elif algo == 'lachesis':\n",
    "                TIME_THRESH = lachesis_param['dt_max']\n",
    "                DELTA_ROAM = lachesis_param['delta_roam']\n",
    "                DUR_MIN = lachesis_param['dur_min']\n",
    "\n",
    "                labels = LACHESIS._lachesis_labels(\n",
    "                    data=sparse,\n",
    "                    dt_max=TIME_THRESH,\n",
    "                    dur_min=DUR_MIN,\n",
    "                    delta_roam=DELTA_ROAM,\n",
    "                    traj_cols=traj_cols)\n",
    "                labels.name = 'cluster'\n",
    "                sparse_with_cluster = sparse.join(labels)\n",
    "\n",
    "            else:\n",
    "                print(f\"Algorithm {algo} not in the list!\")\n",
    "                continue \n",
    "\n",
    "            # ----------- COMPUTE STOPS FROM LABELS -----------\n",
    "\n",
    "            if algo != 'oracle':\n",
    "                pred = visits.point_in_polygon(\n",
    "                    data=sparse_with_cluster,\n",
    "                    poi_table=poi_table,\n",
    "                    method='majority',\n",
    "                    data_crs='EPSG:4326',\n",
    "                    max_distance=15,\n",
    "                    cluster_label='cluster',\n",
    "                    location_id='building_id',\n",
    "                    x='x',\n",
    "                    y='y')\n",
    "\n",
    "                pred = sparse_with_cluster.join(pred)\n",
    "                stops = pred[pred.cluster!=-1].groupby('cluster', as_index=False).apply(\n",
    "                    summarize_stops_with_loc, include_groups=False)\n",
    "\n",
    "            # ----------- REMOVING OVERLAPS (POST PROCESSING) -----------\n",
    "\n",
    "                if stops.empty:\n",
    "                    expected_stop_columns = [\n",
    "                        'cluster', 'x', 'y', 'start_timestamp', 'ha', 'diameter', 'n_pings',\n",
    "                        'end_timestamp', 'duration', 'max_gap', 'building_id']\n",
    "                    stops = pd.DataFrame(columns=expected_stop_columns)\n",
    "\n",
    "                try:\n",
    "                    utils.invalid_stops(stops)\n",
    "                except Exception: \n",
    "                    stops = pp.remove_overlaps(\n",
    "                        sparse_with_cluster,\n",
    "                        time_thresh=TIME_THRESH,\n",
    "                        min_pts=MIN_PTS,\n",
    "                        dur_min=DUR_MIN,\n",
    "                        traj_cols=traj_cols,\n",
    "                        post_processing='polygon')\n",
    "\n",
    "                stops['building_id'] = stops['building_id'].astype(str)\n",
    "\n",
    "            else:  # location exists by oracle, we join everything\n",
    "                pred = sparse.join(location).join(labels)\n",
    "                stops = pred[pred.cluster!=-1].groupby(\n",
    "                    'cluster', as_index=False).apply(summarize_stops_with_loc, include_groups=False)\n",
    "                # we add a 5min duration to oracle stops with just one ping\n",
    "                stops = utils.pad_short_stops(stops, pad=5, dur_min=0, start_timestamp = 'start_timestamp')\n",
    "\n",
    "            first_time = truth['timestamp'].iloc[0]\n",
    "            last_time = truth['timestamp'].iloc[-1] + truth['duration'].iloc[-1] * 60\n",
    "            stops_filled = pp.fill_timestamp_gaps(first_time, last_time, stops)\n",
    "\n",
    "            # ----------- COMPUTE METRICS OF INTEREST -----------\n",
    "\n",
    "            # general metrics\n",
    "            overlaps = overlapping_visits(\n",
    "                left=stops,\n",
    "                right=truth,\n",
    "                location_id='building_id',\n",
    "                match_location=False)\n",
    "\n",
    "            overlaps_filled = overlapping_visits(\n",
    "                left=stops_filled, \n",
    "                right=truth, \n",
    "                location_id='building_id', \n",
    "                match_location=False)\n",
    "\n",
    "            errors = compute_visitation_errors(\n",
    "                overlaps=overlaps,\n",
    "                true_visits=truth,\n",
    "                location_id='building_id')\n",
    "\n",
    "            prf1 = compute_precision_recall_f1(\n",
    "                overlaps=overlaps_filled,\n",
    "                pred_visits=stops,\n",
    "                true_visits=truth,\n",
    "                location_id='building_id')\n",
    "\n",
    "            all_metrics = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                           'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                           'agent': agent_seed, 'seed': i, 'algorithm': algo, \n",
    "                           'noise': ha, 'q': q}\n",
    "            seed_all_metrics_df = pd.concat([seed_all_metrics_df, pd.DataFrame([all_metrics])], ignore_index=True)\n",
    "\n",
    "            # size metrics\n",
    "            stops_attr = stops.merge(\n",
    "                poi_table[['building_id', 'building_size', 'building_type']], on='building_id')\n",
    "            stops_filled_attr = stops_filled.merge(\n",
    "                poi_table[['building_id', 'building_size', 'building_type']], on='building_id')\n",
    "\n",
    "            for build_size in ['small', 'medium', 'big']:\n",
    "                if (truth.building_size==build_size).sum()==0:\n",
    "                    continue\n",
    "\n",
    "                truth_subset = truth.loc[truth.building_size==build_size]\n",
    "\n",
    "                overlaps = overlapping_visits(\n",
    "                    left=stops_attr,\n",
    "                    right=truth_subset,\n",
    "                    location_id='building_id',\n",
    "                    match_location=False)\n",
    "\n",
    "                overlaps_filled = overlapping_visits(\n",
    "                    left=stops_filled_attr, \n",
    "                    right=truth_subset, \n",
    "                    location_id='building_id', \n",
    "                    match_location=False)\n",
    "\n",
    "                errors = compute_visitation_errors(\n",
    "                    overlaps=overlaps,\n",
    "                    true_visits=truth_subset,\n",
    "                    location_id='building_id')\n",
    "\n",
    "                prf1 = compute_precision_recall_f1(\n",
    "                    overlaps=overlaps_filled,\n",
    "                    pred_visits=stops_filled_attr,\n",
    "                    true_visits=truth_subset,\n",
    "                    location_id='building_id')\n",
    "\n",
    "                metrics_size = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                           'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                           'agent': agent_seed, 'seed': i, 'algorithm': algo, \n",
    "                           'noise': ha, 'q': q}\n",
    "                seed_metrics_size_df = pd.concat([seed_metrics_size_df, pd.DataFrame([metrics_size])], ignore_index=True)\n",
    "\n",
    "            # btype metrics\n",
    "            for building_type in ['home', 'retail', 'work', 'park']:\n",
    "                if (truth.building_type==building_type).sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                truth_subset = truth.loc[truth.building_type==building_type]\n",
    "\n",
    "                overlaps = overlapping_visits(\n",
    "                    left=stops_attr,\n",
    "                    right=truth_subset,\n",
    "                    location_id='building_id',\n",
    "                    match_location=False)\n",
    "\n",
    "                overlaps_filled = overlapping_visits(\n",
    "                    left=stops_filled_attr, \n",
    "                    right=truth_subset, \n",
    "                    location_id='building_id', \n",
    "                    match_location=False)\n",
    "\n",
    "                errors = compute_visitation_errors(\n",
    "                    overlaps=overlaps,\n",
    "                    true_visits=truth_subset,\n",
    "                    location_id='building_id')\n",
    "\n",
    "                prf1 = compute_precision_recall_f1(\n",
    "                    overlaps=overlaps_filled,\n",
    "                    pred_visits=stops_filled_attr,\n",
    "                    true_visits=truth_subset,\n",
    "                    location_id='building_id')\n",
    "\n",
    "                metrics_btype = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                           'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                           'agent': agent_seed, 'seed': i, 'algorithm': algo, \n",
    "                           'noise': ha, 'q': q}\n",
    "                seed_metrics_btype_df = pd.concat([seed_metrics_btype_df, pd.DataFrame([metrics_btype])], ignore_index=True)\n",
    "\n",
    "            # dwell metrics\n",
    "            for dwell_length in ['low', 'mid', 'high']:    \n",
    "                if (truth.dwell_length==dwell_length).sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                truth_subset = truth.loc[truth.dwell_length==dwell_length]\n",
    "\n",
    "                overlaps = overlapping_visits(\n",
    "                    left=stops_attr,\n",
    "                    right=truth_subset,\n",
    "                    location_id='building_id',\n",
    "                    match_location=False)\n",
    "\n",
    "                overlaps_filled = overlapping_visits(\n",
    "                    left=stops_filled_attr, \n",
    "                    right=truth_subset, \n",
    "                    location_id='building_id', \n",
    "                    match_location=False)\n",
    "\n",
    "                errors = compute_visitation_errors(\n",
    "                    overlaps=overlaps,\n",
    "                    true_visits=truth_subset,\n",
    "                    location_id='building_id')\n",
    "\n",
    "                prf1 = compute_precision_recall_f1(\n",
    "                    overlaps=overlaps_filled,\n",
    "                    pred_visits=stops_filled_attr,\n",
    "                    true_visits=truth_subset,\n",
    "                    location_id='building_id')\n",
    "\n",
    "                metrics_dwell = {**errors, **prf1, 'beta_start': beta_start,\n",
    "                           'beta_dur': beta_dur, 'beta_ping': beta_ping, \n",
    "                           'agent': agent_seed, 'seed': i, 'algorithm': algo, \n",
    "                           'noise': ha, 'q': q}\n",
    "                seed_metrics_dwell_df = pd.concat([seed_metrics_dwell_df, pd.DataFrame([metrics_dwell])], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished simulation for seed {agent_seed} on process {os.getpid()}\")\n",
    "    return seed_all_metrics_df, seed_metrics_size_df, seed_metrics_btype_df, seed_metrics_dwell_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e1acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_agents = 100\n",
    "N_sim = 10  # number of simulations per agent\n",
    "\n",
    "dbscan_param = dict(time_thresh=600, dist_thresh=0.8, min_pts=3, dur_min=5)\n",
    "lachesis_param = dict(dur_min=5, dt_max=600, delta_roam=2)\n",
    "\n",
    "traj_cols = {'user_id':'identifier',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4bfef-053a-4609-bc4b-c9c317a6206d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PARALLELIZED CODE (RUN ON SAGEMAKER)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dt_val = 0.25\n",
    "\n",
    "    seeds_to_run = range(1, N_agents+1)\n",
    "\n",
    "    # Determine the number of CPU cores to use.\n",
    "    num_processes = cpu_count()\n",
    "    print(f\"Starting multiprocessing pool with {num_processes} processes.\")\n",
    "\n",
    "    parallel_args = [\n",
    "        (agent_seed, dt_val, N_sim, dbscan_param, lachesis_param, \n",
    "         traj_cols, poi_table, city, summarize_stops_with_loc)\n",
    "        for agent_seed in seeds_to_run\n",
    "    ]\n",
    "\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = list(tqdm(pool.starmap(run_simulation_for_single_agent, parallel_args),\n",
    "                            total=len(parallel_args), desc=\"Overall Simulation Progress\"))\n",
    "\n",
    "    print(\"All individual seed simulations completed. Aggregating results...\")\n",
    "\n",
    "    # Initialize empty lists to store results from each simulation\n",
    "    all_metrics_combined_list = []\n",
    "    metrics_size_combined_list = []\n",
    "    metrics_btype_combined_list = []\n",
    "    metrics_dwell_combined_list = []\n",
    "\n",
    "    # Unpack and append results from each parallel run\n",
    "    for res_all_metrics_df, res_metrics_size_df, res_metrics_btype_df, res_metrics_dwell_df in results:\n",
    "        all_metrics_combined_list.append(res_all_metrics_df)\n",
    "        metrics_size_combined_list.append(res_metrics_size_df)\n",
    "        metrics_btype_combined_list.append(res_metrics_btype_df)\n",
    "        metrics_dwell_combined_list.append(res_metrics_dwell_df)\n",
    "\n",
    "    # Concatenate all the individual dataframes into final aggregate dataframes\n",
    "    all_metrics_df = pd.concat(all_metrics_combined_list, ignore_index=True)\n",
    "    metrics_size_df = pd.concat(metrics_size_combined_list, ignore_index=True)\n",
    "    metrics_btype_df = pd.concat(metrics_btype_combined_list, ignore_index=True)\n",
    "    metrics_dwell_df = pd.concat(metrics_dwell_combined_list, ignore_index=True)\n",
    "\n",
    "    # Create a dictionary to hold all your DataFrames\n",
    "    all_results = {\n",
    "        'all_metrics': all_metrics_df,\n",
    "        'metrics_size': metrics_size_df,\n",
    "        'metrics_btype': metrics_btype_df,\n",
    "        'metrics_dwell': metrics_dwell_df\n",
    "    }\n",
    "\n",
    "    # Define the filename for your pickle file\n",
    "    output_filename = 'exp2_results.pkl'\n",
    "\n",
    "    # Pickle the dictionary to a file\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49532cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the results from the pickle file\n",
    "with open('exp2_results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    all_metrics_df = results['all_metrics']\n",
    "    metrics_size_df = results['metrics_size']\n",
    "    metrics_btype_df = results['metrics_btype']\n",
    "    metrics_dwell_df = results['metrics_dwell']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b9663",
   "metadata": {},
   "source": [
    "Table of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c72d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = all_metrics_df.groupby('algorithm')[['missed_fraction', 'merged_fraction', 'split_fraction', 'precision', 'recall', 'f1']].mean()\n",
    "summary.columns = ['missed', 'merged', 'split', 'precision', 'recall', 'f1']\n",
    "print(summary.to_latex(float_format=\"%.3f\", caption=\"Stop Detection Metrics by Algorithm\", label=\"tab:exp2_metrics\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e5833",
   "metadata": {},
   "source": [
    "Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb64cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chart_df3 = all_metrics_df.groupby(['agent', 'algorithm']).mean().reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 5), sharey=True)\n",
    "colors = sns.color_palette(\"tab10\", n_colors=3)\n",
    "\n",
    "algorithms = ['oracle', 'ta-dbscan', 'lachesis']\n",
    "\n",
    "# Left Subplot: F1 over Q (Scatter with Line of Best Fit)\n",
    "for i, algo in enumerate(algorithms):\n",
    "    algo_data = chart_df3[chart_df3.algorithm == algo]\n",
    "    \n",
    "    sns.regplot(\n",
    "        data=algo_data,\n",
    "        x='q',\n",
    "        y='f1',\n",
    "        ax=axes[0],\n",
    "        label=algo,\n",
    "        color=colors[i],\n",
    "        scatter_kws={'alpha': 0.3, 's': 10},\n",
    "        line_kws={'lw': 3},\n",
    "        ci=95,\n",
    "        lowess=True\n",
    "    )\n",
    "\n",
    "axes[0].set_title('A) Completeness', fontsize=18, pad=10, fontweight='bold')\n",
    "axes[0].set_xlabel('Completeness (q)', fontsize=14, labelpad=8)\n",
    "axes[0].set_ylabel('F1 Score', fontsize=14, labelpad=8)\n",
    "axes[0].grid(True, linestyle=':', alpha=0.6, linewidth=0.7)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=10, length=5, width=1)\n",
    "axes[0].minorticks_on()\n",
    "axes[0].tick_params(axis='both', which='minor', length=2.5, width=0.7)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Right Subplot: F1 over Noise (ha) (Scatter with Line of Best Fit)\n",
    "for i, algo in enumerate(algorithms):\n",
    "    algo_data = chart_df3[chart_df3.algorithm == algo]\n",
    "\n",
    "    sns.regplot(\n",
    "        data=algo_data,\n",
    "        x='noise',\n",
    "        y='f1',\n",
    "        ax=axes[1],\n",
    "        label=algo,\n",
    "        color=colors[i],\n",
    "        scatter_kws={'alpha': 0.3, 's': 10},\n",
    "        line_kws={'lw': 3},\n",
    "        ci=95,\n",
    "        lowess=True\n",
    "    )\n",
    "\n",
    "axes[1].set_title('B) Noise', fontsize=18, pad=10, fontweight='bold')\n",
    "axes[1].set_xlabel('Noise (Horizontal Accuracy in Meters)', fontsize=14, labelpad=8)\n",
    "axes[1].set_ylabel('')\n",
    "axes[1].grid(True, linestyle=':', alpha=0.6, linewidth=0.7)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=10, length=5, width=1)\n",
    "axes[1].minorticks_on()\n",
    "axes[1].tick_params(axis='both', which='minor', length=2.5, width=0.7)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "# for i, algo in enumerate(algorithms):\n",
    "#     algo_data = chart_df3[chart_df3.algorithm == algo]\n",
    "\n",
    "#     sns.regplot(\n",
    "#         data=algo_data,\n",
    "#         x='beta_ping',\n",
    "#         y='f1',\n",
    "#         ax=axes[2],\n",
    "#         label=algo,\n",
    "#         color=colors[i],\n",
    "#         scatter_kws={'alpha': 0.6, 's': 50},\n",
    "#         line_kws={'lw': 2},\n",
    "#         ci=95,\n",
    "#         lowess=True\n",
    "#     )\n",
    "\n",
    "# axes[2].set_title('F1 Score vs. Time Between Pings', fontsize=14, pad=10)\n",
    "# axes[2].set_xlabel('Mean Time Between Pings (Minutes)', fontsize=12, labelpad=8)\n",
    "# axes[2].set_ylabel('F1 Score', fontsize=12, labelpad=8)\n",
    "# axes[2].legend(title='Algorithm', fontsize=10, frameon=False)\n",
    "# axes[2].grid(True, linestyle=':', alpha=0.6, linewidth=0.7)\n",
    "# axes[2].tick_params(axis='both', which='major', labelsize=10, length=5, width=1)\n",
    "# axes[2].minorticks_on()\n",
    "# axes[2].tick_params(axis='both', which='minor', length=2.5, width=0.7)\n",
    "# axes[2].set_ylim(0, 1)\n",
    "\n",
    "legend_labels = ['Oracle', 'TA-DBSCAN', 'Lachesis']\n",
    "handles = [\n",
    "    axes[0].lines[0],\n",
    "    axes[0].lines[1],\n",
    "    axes[0].lines[2]\n",
    "]\n",
    "fig.legend(\n",
    "    handles,\n",
    "    legend_labels,\n",
    "    loc='lower center',         \n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    ncol=len(legend_labels),\n",
    "    fontsize=16,\n",
    "    title_fontsize=18,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.08, 1, 1])\n",
    "plt.savefig(\"exp2-f1.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c01d62-ee41-4ec1-af6b-bcc78204e9f3",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550feba-2bc3-40df-8fe1-8b8ca8e9f878",
   "metadata": {},
   "source": [
    "- We explain garden city and how we produced ground truth, heavily referencing the Arxiv version\n",
    "- We divide in three sections after that\n",
    "- Possible problems in stop detection\n",
    "- Are these problems present in real (global) trajectories? + covariates\n",
    "- Can the parameterizations address these issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05e21c-520a-41eb-8675-09268e6d9fc1",
   "metadata": {},
   "source": [
    "There are regimes in which certain problems disappear.\n",
    "- E.g. going from extremely complete signals to very complete signals, might not make a difference in terms of quality---they are both good enough. This analysis could be visualized in a plot with q in the x-axis, showing that for high q and very low q things break down. \n",
    "- E.g. a very bad parameterization of DBScan for retail, might obscure a small effect of beta ping on retail. \n",
    "- Some problems might mostly affect users that explore a lot (this is application-relevant). \n",
    "- Maybe the conclusion is that you need a hierarchical DBScan\n",
    "\n",
    "We show problems. Can we THEN show solutions? Then maybe we can hint at solutions while describing problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459fbcc6-cb76-4e25-a607-8b6584faa570",
   "metadata": {},
   "source": [
    "## Global problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a619daca-fa35-418c-9cfb-78bb33d76734",
   "metadata": {},
   "source": [
    "Related to the intensity and clustering of the bursts. It can affect if stops are missed (recall), it can also mess with accuracy by building type (typically long/short dwells).\n",
    "\n",
    "- Missingness is more severe for home and work compared to retail and park. Maybe a ratio statistic alongside the magnitude decreases. Pick a \"reasonable\" DBScan (based on recall). Parameters of a typical user in a typical dataset (avoid a regime where nothing/everything works). \n",
    "- Obvious plot is you have less signal (gray rectangles) then you miss more stops/time-at-right-stop overall. Show regimes? Specially for exploration-prone users? + nuance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fdbab3-915b-4463-b1c2-528a850ef497",
   "metadata": {},
   "source": [
    "## Parameterization problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8204a114-9b40-46b6-a761-62834642b437",
   "metadata": {},
   "source": [
    "You can truly choose the wrong parameters, and you might want to incorporate user signal parameters and building areas, and whatnot. Quality of algorithms and how to choose. x-axis is parameter of DBScan and y-axis is quality of clusters.\n",
    "- What would you do with a complete and regular signal? Maybe a \"reasonable\" DBScan would fail miserably and Lachesis would succeed? min_pts would save the day? \n",
    "- Time parameter ranges from 1 hour to 16 hours. Long-dwell \"bridging\" of huge gaps would increase (obviously) but, the nuance is overestimating time at work or at home. Absolute vs Relative. \n",
    "- Epsilon affects splitting and merging. Pick a \"default and reasonable\" beta_ping and change epsilon. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

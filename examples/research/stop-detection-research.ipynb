{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1364ba7a-c457-424d-b68d-0eabde1d9ac4",
   "metadata": {},
   "source": [
    "# ST-HDBSCAN: Spatiotemporal Hierarchical DBSCAN for Trajectory Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf66e7f6-4f0c-4308-a2e9-5165e423dc63",
   "metadata": {},
   "source": [
    "Francisco Barreras\n",
    "\n",
    "Duncan Watts\n",
    "\n",
    "Bethanny Hsiao\n",
    "\n",
    "Andres Mondragon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff17d8-0050-4885-89f8-0b3aabd43ec7",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16e0da-f862-43b5-a4fb-2d4f1e8c32f6",
   "metadata": {},
   "source": [
    "The study of human mobility has advanced greatly in recent years due to the availability of\n",
    "commercial large-scale GPS trajectory datasets [3]. However, the validity of findings that use\n",
    "these datasets depends heavily on the robustness of their pre-processing methods. An important\n",
    "step in the processing of mobility data is the detection of stops within GPS trajectories, for\n",
    "which many clustering algorithms have been proposed [4, 8, 6, 1]. Yet, the high sparsity of\n",
    "commercial GPS data can affect the performance of these stop-detection algorithms.\n",
    "In the case of DBSCAN, while it initially identifies dense regions, it can often over-cluster\n",
    "or under-cluster due to noise and weakly connected points given the chosen ε. ST-DBSCAN [4]\n",
    "uses two distance thresholds, Eps1 for spatial and Eps2 for non-spatial values. The algorithm\n",
    "compares the average non-spatial value, such as temperature, of a cluster with a new com-\n",
    "ing value, to prevent merging adjacent clusters. Nevertheless, datasets that include this kind\n",
    "of information are not comparable to realistic GPS-based trajectories. A promising algorithm\n",
    "is T-DBSCAN [6], which searches forward in time for a continuous density-based neighbor-\n",
    "hood of core points. Points spatially close, within Eps, and within a roaming threshold, CEps, are included in a cluster. Additionally, we used a time-augmented DBSCAN algorithm, TA-DBSCAN, which recursively processes the clusters obtained from DBSCAN to address the issue of initial clusters overlapping in time. However, methods [9] that validate stop-detection algorithms based on synthetic data show that these can omit, merge, or split stops based on the selection of epsilon and sparsity of the data.\n",
    "\n",
    "If we define parameters that may be considered fine (low ε), it might completely miss a stop at a larger location. In contrast, coarse parameters (large ε) may struggle to differentiate stops within small neighboring locations [3]. Since different venues vary in stop durations and areas, this could influence the parameter choices [9]. To address this parameter selection limitation, we propose a spatiotemporal variation of Hierarchical DBSCAN [5], ST-HDBSCAN. Unlike DBSCAN, which relies on one threshold of density to cluster points, our variation constructs separate structures for space and time distances that preserve density-based connections in these two dimensions. This approach ensures that when pruning the hierarchical tree structure needed for cluster formation, we account for varying spatiotemporal densities. As a result, clusters emerge naturally without requiring specific time and space thresholds, working effectively across different data sparsity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a6f7135-4d17-456d-9059-ee6a54c3a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b8502ca-e6d1-4df1-9f2f-7bfceafd598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import pygeohash as gh\n",
    "import geopandas as gpd\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from pyproj import Transformer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1af0f24-ab30-43a4-bfa6-5ed0dcb24dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.base as loader\n",
    "import nomad.constants as constants\n",
    "import nomad.stop_detection.hdbscan as HDBSCAN\n",
    "import nomad.filters as filters\n",
    "import nomad.city_gen as cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07cd9276-30ed-435a-b8fe-4687a87d2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'user_id':'uid',\n",
    "             'datetime':'local_datetime',\n",
    "             'latitude':'latitude',\n",
    "             'longitude':'longitude'}\n",
    "\n",
    "data = loader.from_file(\"../../nomad/data/gc_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "119f0da7-8c0a-4228-b57b-819f56875105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a time offset column with different UTC offsets (in seconds)\n",
    "data['tz_offset'] = 0\n",
    "data.loc[data.index[:5000],'tz_offset'] = -7200\n",
    "data.loc[data.index[-5000:], 'tz_offset'] = 3600\n",
    "\n",
    "# create datetime column as a string\n",
    "data['local_datetime'] = loader._unix_offset_to_str(data.timestamp, data.tz_offset)\n",
    "data['local_datetime'] = pd.to_datetime(data['local_datetime'], utc=True)\n",
    "\n",
    "# create x, y columns in web mercator\n",
    "gdf = gpd.GeoSeries(gpd.points_from_xy(data.longitude, data.latitude),\n",
    "                        crs=\"EPSG:4326\")\n",
    "projected = gdf.to_crs(\"EPSG:3857\")\n",
    "data['x'] = projected.x\n",
    "data['y'] = projected.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d083d50c-8f65-4c7d-ba7e-963b6ddc2a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tz_offset</th>\n",
       "      <th>local_datetime</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wizardly_joliot</td>\n",
       "      <td>1704119340</td>\n",
       "      <td>38.321711</td>\n",
       "      <td>-36.667334</td>\n",
       "      <td>-7200</td>\n",
       "      <td>2024-01-01 14:29:00+00:00</td>\n",
       "      <td>-4.081789e+06</td>\n",
       "      <td>4.624973e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wizardly_joliot</td>\n",
       "      <td>1704119700</td>\n",
       "      <td>38.321676</td>\n",
       "      <td>-36.667365</td>\n",
       "      <td>-7200</td>\n",
       "      <td>2024-01-01 14:35:00+00:00</td>\n",
       "      <td>-4.081792e+06</td>\n",
       "      <td>4.624968e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wizardly_joliot</td>\n",
       "      <td>1704155880</td>\n",
       "      <td>38.320959</td>\n",
       "      <td>-36.666748</td>\n",
       "      <td>-7200</td>\n",
       "      <td>2024-01-02 00:38:00+00:00</td>\n",
       "      <td>-4.081724e+06</td>\n",
       "      <td>4.624866e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wizardly_joliot</td>\n",
       "      <td>1704156000</td>\n",
       "      <td>38.320936</td>\n",
       "      <td>-36.666739</td>\n",
       "      <td>-7200</td>\n",
       "      <td>2024-01-02 00:40:00+00:00</td>\n",
       "      <td>-4.081723e+06</td>\n",
       "      <td>4.624863e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wizardly_joliot</td>\n",
       "      <td>1704156840</td>\n",
       "      <td>38.320924</td>\n",
       "      <td>-36.666747</td>\n",
       "      <td>-7200</td>\n",
       "      <td>2024-01-02 00:54:00+00:00</td>\n",
       "      <td>-4.081724e+06</td>\n",
       "      <td>4.624861e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25830</th>\n",
       "      <td>angry_spence</td>\n",
       "      <td>1705303380</td>\n",
       "      <td>38.320399</td>\n",
       "      <td>-36.667438</td>\n",
       "      <td>3600</td>\n",
       "      <td>2024-01-15 07:23:00+00:00</td>\n",
       "      <td>-4.081801e+06</td>\n",
       "      <td>4.624787e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25831</th>\n",
       "      <td>angry_spence</td>\n",
       "      <td>1705303740</td>\n",
       "      <td>38.320413</td>\n",
       "      <td>-36.667469</td>\n",
       "      <td>3600</td>\n",
       "      <td>2024-01-15 07:29:00+00:00</td>\n",
       "      <td>-4.081804e+06</td>\n",
       "      <td>4.624789e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25832</th>\n",
       "      <td>angry_spence</td>\n",
       "      <td>1705303980</td>\n",
       "      <td>38.320384</td>\n",
       "      <td>-36.667455</td>\n",
       "      <td>3600</td>\n",
       "      <td>2024-01-15 07:33:00+00:00</td>\n",
       "      <td>-4.081802e+06</td>\n",
       "      <td>4.624785e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25833</th>\n",
       "      <td>angry_spence</td>\n",
       "      <td>1705304340</td>\n",
       "      <td>38.320349</td>\n",
       "      <td>-36.667473</td>\n",
       "      <td>3600</td>\n",
       "      <td>2024-01-15 07:39:00+00:00</td>\n",
       "      <td>-4.081804e+06</td>\n",
       "      <td>4.624780e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25834</th>\n",
       "      <td>angry_spence</td>\n",
       "      <td>1705305000</td>\n",
       "      <td>38.320947</td>\n",
       "      <td>-36.667530</td>\n",
       "      <td>3600</td>\n",
       "      <td>2024-01-15 07:50:00+00:00</td>\n",
       "      <td>-4.081811e+06</td>\n",
       "      <td>4.624865e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25835 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   uid   timestamp   latitude  longitude  tz_offset  \\\n",
       "0      wizardly_joliot  1704119340  38.321711 -36.667334      -7200   \n",
       "1      wizardly_joliot  1704119700  38.321676 -36.667365      -7200   \n",
       "2      wizardly_joliot  1704155880  38.320959 -36.666748      -7200   \n",
       "3      wizardly_joliot  1704156000  38.320936 -36.666739      -7200   \n",
       "4      wizardly_joliot  1704156840  38.320924 -36.666747      -7200   \n",
       "...                ...         ...        ...        ...        ...   \n",
       "25830     angry_spence  1705303380  38.320399 -36.667438       3600   \n",
       "25831     angry_spence  1705303740  38.320413 -36.667469       3600   \n",
       "25832     angry_spence  1705303980  38.320384 -36.667455       3600   \n",
       "25833     angry_spence  1705304340  38.320349 -36.667473       3600   \n",
       "25834     angry_spence  1705305000  38.320947 -36.667530       3600   \n",
       "\n",
       "                 local_datetime             x             y  \n",
       "0     2024-01-01 14:29:00+00:00 -4.081789e+06  4.624973e+06  \n",
       "1     2024-01-01 14:35:00+00:00 -4.081792e+06  4.624968e+06  \n",
       "2     2024-01-02 00:38:00+00:00 -4.081724e+06  4.624866e+06  \n",
       "3     2024-01-02 00:40:00+00:00 -4.081723e+06  4.624863e+06  \n",
       "4     2024-01-02 00:54:00+00:00 -4.081724e+06  4.624861e+06  \n",
       "...                         ...           ...           ...  \n",
       "25830 2024-01-15 07:23:00+00:00 -4.081801e+06  4.624787e+06  \n",
       "25831 2024-01-15 07:29:00+00:00 -4.081804e+06  4.624789e+06  \n",
       "25832 2024-01-15 07:33:00+00:00 -4.081802e+06  4.624785e+06  \n",
       "25833 2024-01-15 07:39:00+00:00 -4.081804e+06  4.624780e+06  \n",
       "25834 2024-01-15 07:50:00+00:00 -4.081811e+06  4.624865e+06  \n",
       "\n",
       "[25835 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f2e83ba-85ee-4816-9545-102362e9aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sample = data.loc[data.uid == \"angry_spence\"]\n",
    "user_sample = user_sample[['timestamp', 'x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03e9fab6-2bcb-4a61-838a-c1ebf2658300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>1704104460</td>\n",
       "      <td>-4.081702e+06</td>\n",
       "      <td>4.624871e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>1704104820</td>\n",
       "      <td>-4.081697e+06</td>\n",
       "      <td>4.624867e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24141</th>\n",
       "      <td>1704104940</td>\n",
       "      <td>-4.081696e+06</td>\n",
       "      <td>4.624866e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24142</th>\n",
       "      <td>1704105540</td>\n",
       "      <td>-4.081698e+06</td>\n",
       "      <td>4.624865e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24143</th>\n",
       "      <td>1704105720</td>\n",
       "      <td>-4.081699e+06</td>\n",
       "      <td>4.624866e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25830</th>\n",
       "      <td>1705303380</td>\n",
       "      <td>-4.081801e+06</td>\n",
       "      <td>4.624787e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25831</th>\n",
       "      <td>1705303740</td>\n",
       "      <td>-4.081804e+06</td>\n",
       "      <td>4.624789e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25832</th>\n",
       "      <td>1705303980</td>\n",
       "      <td>-4.081802e+06</td>\n",
       "      <td>4.624785e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25833</th>\n",
       "      <td>1705304340</td>\n",
       "      <td>-4.081804e+06</td>\n",
       "      <td>4.624780e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25834</th>\n",
       "      <td>1705305000</td>\n",
       "      <td>-4.081811e+06</td>\n",
       "      <td>4.624865e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1696 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp             x             y\n",
       "24139  1704104460 -4.081702e+06  4.624871e+06\n",
       "24140  1704104820 -4.081697e+06  4.624867e+06\n",
       "24141  1704104940 -4.081696e+06  4.624866e+06\n",
       "24142  1704105540 -4.081698e+06  4.624865e+06\n",
       "24143  1704105720 -4.081699e+06  4.624866e+06\n",
       "...           ...           ...           ...\n",
       "25830  1705303380 -4.081801e+06  4.624787e+06\n",
       "25831  1705303740 -4.081804e+06  4.624789e+06\n",
       "25832  1705303980 -4.081802e+06  4.624785e+06\n",
       "25833  1705304340 -4.081804e+06  4.624780e+06\n",
       "25834  1705305000 -4.081811e+06  4.624865e+06\n",
       "\n",
       "[1696 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77af6f9d-e6b8-4244-8aad-a5ce3bee4f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_pairs = HDBSCAN._find_bursts(user_sample['timestamp'], 120)\n",
    "core_distances = HDBSCAN._compute_core_distance(user_sample, time_pairs, 4)\n",
    "mrd = HDBSCAN._compute_mrd_graph(user_sample, core_distances)\n",
    "mst_edges = HDBSCAN._mst(mrd)\n",
    "mstext_edges = mst_ext(mst_edges, core_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "33c456fe-7946-4b2b-b97c-56db6a367e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_map, hierarchy = HDBSCAN.hdbscan(mstext_edges, min_cluster_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ff4b04f8-50b4-439a-827b-e96b876a2e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({-1: 1647, 15: 2, 106: 2, 50: 2, 148: 2, 18: 2, 127: 2, 20: 2, 59: 2, 30: 1, 25: 1, 36: 1, 33: 1, 9: 1, 16: 1, 112: 1, 146: 1, 32: 1, 159: 1, 38: 1, 91: 1, 46: 1, 84: 1, 72: 1, 14: 1, 124: 1, 156: 1, 116: 1, 152: 1, 104: 1, 89: 1, 73: 1, 10: 1, 64: 1, 82: 1, 94: 1, 134: 1, 67: 1, 130: 1, 80: 1, 62: 1, 93: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(label_map.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4955d06d-391c-4b63-beb5-ad9017bd569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def _compute_cluster_stability(hierarchy, label_map, timestamps, min_cluster_size):\n",
    "    \"\"\"\n",
    "    Compute the stability of each cluster from the hierarchy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hierarchy : list of tuples\n",
    "        Each tuple is (scale, parent_cluster_id, [child_cluster_ids]).\n",
    "    label_map : dict\n",
    "        Final label mapping of each timestamp.\n",
    "    timestamps : set\n",
    "        All unique timestamps.\n",
    "    min_cluster_size : int\n",
    "        The minimum cluster size allowed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stability : dict\n",
    "        {cluster_id: stability score}\n",
    "    \"\"\"\n",
    "    lambda_min = {0: 0.0} # λ_min(Ci) is the minimum density level at which Ci exists\n",
    "    lambda_max = {} # λ_max(xj,Ci) is the density level beyond which object xj no longer belongs to cluster Ci\n",
    "    \n",
    "    # Track which cluster each timestamp was in at which scale\n",
    "    membership = defaultdict(list)  # timestamp: [(cluster_id, scale_exit)]\n",
    "\n",
    "    # Initially all points are in cluster 0\n",
    "    for ts in timestamps:\n",
    "        membership[ts].append((0, None))\n",
    "\n",
    "    for scale, parent_id, child_ids in hierarchy:\n",
    "        # Parent no longer exists at this scale\n",
    "        lambda_max[parent_id] = scale\n",
    "        # Children begin to exist at this scale\n",
    "        for child_id in child_ids:\n",
    "            lambda_min[child_id] = scale\n",
    "\n",
    "        # Reassign points in label_map to child clusters\n",
    "        for ts, label in label_map.items():\n",
    "            if label in child_ids:\n",
    "                membership[ts].append((label, None))\n",
    "        \n",
    "        # For all points in parent that aren't reassigned (noise), mark their exit\n",
    "        for ts, ts_evolution in membership.items():\n",
    "            for i in range(len(ts_evolution)):\n",
    "                cid, exit_scale = ts_evolution[i]\n",
    "                if cid == parent_id and exit_scale is None:\n",
    "                    ts_evolution[i] = (cid, scale)\n",
    "\n",
    "    # Stability : S(Ci)= Σx_j ∈ C_i {λ_max(xj,Ci) − λ_min(Ci)}\n",
    "    stability = defaultdict(float)\n",
    "    for ts in timestamps:\n",
    "        for cid, exit_scale in membership[ts]:\n",
    "            if cid not in lambda_min:\n",
    "                continue\n",
    "            birth = lambda_min[cid] # λ_min(Ci)\n",
    "            death = exit_scale if exit_scale is not None else lambda_max.get(cid, birth) # λ_max(xj,Ci)\n",
    "            if death is not None and death > birth: \n",
    "                stability[cid] += death - birth # λ_max(xj,Ci) − λ_min(Ci)\n",
    "\n",
    "    return dict(stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7612594e-11a6-4ca8-b998-5c0f98a410b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_stable_clusters(hierarchy, stability):\n",
    "    \"\"\"\n",
    "    Implements the HDBSCAN bottom-up optimization algorithm for selecting\n",
    "    the most stable, non-overlapping clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hierarchy : list of (scale, parent_id, [child_ids])\n",
    "        The cluster split history.\n",
    "    stability : dict\n",
    "        {cluster_id: stability score}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_clusters : set\n",
    "        Set of selected cluster IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build tree (parent -> children)\n",
    "    tree = defaultdict(list)\n",
    "    parents = {}\n",
    "    for _, parent, children in hierarchy:\n",
    "        tree[parent].extend(children)\n",
    "        for child in children:\n",
    "            parents[child] = parent\n",
    "\n",
    "    # List of all cluster ids\n",
    "    all_clusters = set(stability.keys()) | set(parents.keys()) | set(tree.keys())\n",
    "\n",
    "    # Leaf clusters\n",
    "    leaf_clusters = [cid for cid in all_clusters if cid not in tree]\n",
    "\n",
    "    # Bottom-up dynamic programming\n",
    "    best_stability = {}\n",
    "    selected = {}\n",
    "\n",
    "    def dfs(cluster_id):\n",
    "        if cluster_id not in tree:\n",
    "            best_stability[cluster_id] = stability.get(cluster_id, 0.0)\n",
    "            selected[cluster_id] = True\n",
    "            return best_stability[cluster_id]\n",
    "\n",
    "        child_stabilities = 0\n",
    "        \n",
    "        for child in tree[cluster_id]:\n",
    "            child_stabilities += dfs(child)\n",
    "\n",
    "        current_stability = stability.get(cluster_id, 0.0)\n",
    "\n",
    "        if current_stability >= child_stabilities:\n",
    "            best_stability[cluster_id] = current_stability\n",
    "            selected[cluster_id] = True\n",
    "            for child in tree[cluster_id]:\n",
    "                selected[child] = False\n",
    "        else:\n",
    "            best_stability[cluster_id] = child_stabilities\n",
    "            selected[cluster_id] = False\n",
    "\n",
    "        return best_stability[cluster_id]\n",
    "\n",
    "    dfs(0)\n",
    "\n",
    "    final_clusters = {cid for cid, selected in selected.items() if selected}\n",
    "\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2f2917f-c764-4527-abd9-d91581d2e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hdbscan_labels(label_map, final_clusters):\n",
    "    \"\"\"\n",
    "    Assign final labels to each timestamp based on selected stable clusters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    label_map : dict\n",
    "        {Original timestamp: cluster_id mapping}\n",
    "    final_clusters : set\n",
    "        Set of selected cluster IDs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_labels : dict\n",
    "        {timestamp: final cluster label (-1 if noise)}\n",
    "    \"\"\"\n",
    "    final_labels = {}\n",
    "    \n",
    "    for ts, cid in label_map.items():\n",
    "        if cid in final_clusters:\n",
    "            final_labels[ts] = cid\n",
    "        else:\n",
    "            final_labels[ts] = -1  # noise\n",
    "\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4c21627-cd2e-4a08-81ee-452f5294effb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stability = _compute_cluster_stability(hierarchy, label_map, user_sample['timestamp'], 4)\n",
    "final_clusters = _select_stable_clusters(hierarchy, stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bd1463cb-e1a8-4e66-a148-9f507355811e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: np.float64(92577.55222618669)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50203491-fbf7-46c0-8935-63e6219a3a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nomad_env)",
   "language": "python",
   "name": "nomad_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

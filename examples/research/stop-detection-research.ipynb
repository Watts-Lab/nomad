{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1364ba7a-c457-424d-b68d-0eabde1d9ac4",
   "metadata": {},
   "source": [
    "# ST-HDBSCAN: Spatiotemporal Hierarchical DBSCAN for Trajectory Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf66e7f6-4f0c-4308-a2e9-5165e423dc63",
   "metadata": {},
   "source": [
    "Francisco Barreras\n",
    "\n",
    "Duncan Watts\n",
    "\n",
    "Bethanny Hsiao\n",
    "\n",
    "Andres Mondragon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff17d8-0050-4885-89f8-0b3aabd43ec7",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16e0da-f862-43b5-a4fb-2d4f1e8c32f6",
   "metadata": {},
   "source": [
    "The study of human mobility has advanced greatly in recent years due to the availability of\n",
    "commercial large-scale GPS trajectory datasets [3]. However, the validity of findings that use\n",
    "these datasets depends heavily on the robustness of their pre-processing methods. An important\n",
    "step in the processing of mobility data is the detection of stops within GPS trajectories, for\n",
    "which many clustering algorithms have been proposed [4, 8, 6, 1]. Yet, the high sparsity of\n",
    "commercial GPS data can affect the performance of these stop-detection algorithms.\n",
    "In the case of DBSCAN, while it initially identifies dense regions, it can often over-cluster\n",
    "or under-cluster due to noise and weakly connected points given the chosen ε. ST-DBSCAN [4]\n",
    "uses two distance thresholds, Eps1 for spatial and Eps2 for non-spatial values. The algorithm\n",
    "compares the average non-spatial value, such as temperature, of a cluster with a new com-\n",
    "ing value, to prevent merging adjacent clusters. Nevertheless, datasets that include this kind\n",
    "of information are not comparable to realistic GPS-based trajectories. A promising algorithm\n",
    "is T-DBSCAN [6], which searches forward in time for a continuous density-based neighbor-\n",
    "hood of core points. Points spatially close, within Eps, and within a roaming threshold, CEps, are included in a cluster. Additionally, we used a time-augmented DBSCAN algorithm, TA-DBSCAN, which recursively processes the clusters obtained from DBSCAN to address the issue of initial clusters overlapping in time. However, methods [9] that validate stop-detection algorithms based on synthetic data show that these can omit, merge, or split stops based on the selection of epsilon and sparsity of the data.\n",
    "\n",
    "If we define parameters that may be considered fine (low ε), it might completely miss a stop at a larger location. In contrast, coarse parameters (large ε) may struggle to differentiate stops within small neighboring locations [3]. Since different venues vary in stop durations and areas, this could influence the parameter choices [9]. To address this parameter selection limitation, we propose a spatiotemporal variation of Hierarchical DBSCAN [5], ST-HDBSCAN. Unlike DBSCAN, which relies on one threshold of density to cluster points, our variation constructs separate structures for space and time distances that preserve density-based connections in these two dimensions. This approach ensures that when pruning the hierarchical tree structure needed for cluster formation, we account for varying spatiotemporal densities. As a result, clusters emerge naturally without requiring specific time and space thresholds, working effectively across different data sparsity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6f7135-4d17-456d-9059-ee6a54c3a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8502ca-e6d1-4df1-9f2f-7bfceafd598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer\n",
    "import nomad.io.base as loader\n",
    "import nomad.stop_detection.hdbscan as HDBSCAN\n",
    "import nomad.stop_detection.lachesis as LACHESIS\n",
    "import nomad.stop_detection.ta_dbscan as TADBSCAN\n",
    "import nomad.city_gen as cg\n",
    "import nomad.visit_attribution as va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd9276-30ed-435a-b8fe-4687a87d2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'user_id':'uid',\n",
    "             'datetime':'local_datetime',\n",
    "             'latitude':'latitude',\n",
    "             'longitude':'longitude'}\n",
    "\n",
    "# data = loader.from_file(\"../../nomad/data/gc_sample.csv\")\n",
    "data = loader.from_file(\"../../nomad/data/gc_3_stops.csv\", timestamp='unix_timestamp', datetime='local_timestamp', user_id='identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'unix_timestamp':'timestamp'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083d50c-8f65-4c7d-ba7e-963b6ddc2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7e6ee-3bd8-4803-843e-97c84826f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_df = data.copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.box(on=True)\n",
    "\n",
    "# Plotting Pings\n",
    "ax.scatter(x=plot_df['x'], \n",
    "           y=plot_df['y'],\n",
    "           s=6,\n",
    "           color='black',\n",
    "           alpha=1,\n",
    "           zorder=2)\n",
    "\n",
    "# Plotting Garden City Map\n",
    "city = cg.load('../garden-city.pkl')\n",
    "city.plot_city(ax, doors=True, address=False)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim(12, 22)\n",
    "ax.set_ylim(7, 14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp': 'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pairs, times = HDBSCAN._find_temp_neighbors(times = data['timestamp'], time_thresh = 60, is_datetime=False)\n",
    "core_distances, coords = HDBSCAN._compute_core_distance(data, time_pairs, times, is_long_lat=False, traj_cols=traj_cols, min_pts=5)\n",
    "mrd = HDBSCAN._compute_mrd_graph(coords, times, time_pairs, core_distances, is_long_lat=False)\n",
    "mst_edges = HDBSCAN._mst(mrd)\n",
    "mstext_edges = HDBSCAN.mst_ext(mst_edges, core_distances)\n",
    "label_history_df, hierarchy_df = HDBSCAN.hdbscan(mstext_edges, min_cluster_size = 10)\n",
    "cluster_stability_df = HDBSCAN.compute_cluster_stability(label_history_df)\n",
    "selected_clusters = HDBSCAN.select_most_stable_clusters(hierarchy_df, cluster_stability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ed4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels_hdbscan = HDBSCAN.hdbscan_labels(traj = data,\n",
    "                       traj_cols = traj_cols,\n",
    "                       time_thresh = 60,\n",
    "                       min_pts = 5,\n",
    "                       min_cluster_size = 10)\n",
    "sample_labels_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80240de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.merge(sample_labels_hdbscan, left_on='timestamp', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/metrics_simulated.csv\")\n",
    "\n",
    "metrics = ['f1-score', 'splitting', 'merging']\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure()\n",
    "    df.boxplot(column=metric, by='method')\n",
    "    plt.title(f'{metric} by Method')\n",
    "    plt.suptitle('')\n",
    "    plt.xlabel('Method')\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dcb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Merging sample data with labels\n",
    "merged_data_hdbscan = data.merge(sample_labels_hdbscan, left_on='timestamp', right_index=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.box(on=True)\n",
    "\n",
    "# Plotting Garden City Map\n",
    "city = cg.load('../garden-city.pkl')\n",
    "city.plot_city(ax, doors=True, address=False)\n",
    "\n",
    "# Getting colors for clusters\n",
    "unique_clusters = sorted(merged_data_hdbscan['cluster'].unique())\n",
    "cluster_mapping = {cluster: i for i, cluster in enumerate(unique_clusters)}\n",
    "del cluster_mapping[-1]\n",
    "mapped_clusters = merged_data_hdbscan['cluster'].map(cluster_mapping).to_numpy()\n",
    "cmap_base = plt.get_cmap('Dark2', len(unique_clusters) - (1 if -1 in unique_clusters else 0))\n",
    "# colors = ['gray'] + list(cmap_base.colors)\n",
    "colors = list(cmap_base.colors)\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Plotting Pings\n",
    "ax.scatter(merged_data_hdbscan['x'], \n",
    "           merged_data_hdbscan['y'], \n",
    "           c=mapped_clusters, \n",
    "           cmap=extended_cmap, \n",
    "           s=6,\n",
    "           alpha=1,\n",
    "           zorder=2)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "# ax.set_title(\"HDBSCAN Stops for Sample User\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlim(12, 22)\n",
    "ax.set_ylim(7, 14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('gc_empty.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29994b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'uid':'uid',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}\n",
    "hdbscan_stop_table = HDBSCAN.st_hdbscan(traj = data,\n",
    "                                        is_long_lat = False,\n",
    "                                        is_datetime = False,\n",
    "                                        traj_cols = traj_cols,\n",
    "                                        complete_output = True,\n",
    "                                        time_thresh = 60,\n",
    "                                        min_pts = 5,\n",
    "                                        min_cluster_size = 10)\n",
    "hdbscan_stop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_stop_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5717b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "va.point_in_polygon(traj=data,\n",
    "                    labels=sample_labels_hdbscan,\n",
    "                    stop_table=hdbscan_stop_table,\n",
    "                    traj_cols=traj_cols,\n",
    "                    is_datetime=False,\n",
    "                    is_long_lat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32411437",
   "metadata": {},
   "source": [
    "## Testing on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = loader.from_file(\"../../nomad/data/sparse_traj/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                      parse_dates=True)\n",
    "diaries_df = loader.from_file(\"../../nomad/data/diaries/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                       parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a528ac",
   "metadata": {},
   "source": [
    "### One Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71127c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = sparse_df[sparse_df['uid'] == 'adoring_keldysh']\n",
    "traj.loc[:,'local_timestamp'] = pd.to_datetime(traj['local_timestamp'])\n",
    "diary = diaries_df[diaries_df['uid'] == 'adoring_keldysh']\n",
    "traj_cols = {'uid':'uid',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b26784",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_traj = traj[traj['date'] == '2024-01-01']\n",
    "one_day_traj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77640943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_df = traj.copy()\n",
    "# plot_df = one_day_traj.copy()\n",
    "plot_df.loc[:,'x'] = (plot_df['x'] - 4265699)/15\n",
    "plot_df.loc[:,'y'] = (plot_df['y'] + 4392976)/15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.box(on=True)\n",
    "\n",
    "# Plotting Pings\n",
    "ax.scatter(x=plot_df['x'], \n",
    "           y=plot_df['y'],\n",
    "           s=6,\n",
    "           color='black',\n",
    "           alpha=1,\n",
    "           zorder=2)\n",
    "\n",
    "# Plotting Garden City Map\n",
    "city = cg.load('../garden-city.pkl')\n",
    "city.plot_city(ax, doors=True, address=False)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import warnings\n",
    "\n",
    "def poi_map(traj, poi_table, traj_cols=None, max_distance=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Map pings in the trajectory to the POI table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : pd.DataFrame\n",
    "        The trajectory DataFrame containing x and y coordinates.\n",
    "    poi_table : gpd.GeoDataFrame\n",
    "        The POI table containing building geometries and IDs.\n",
    "    traj_cols : list\n",
    "        The columns in the trajectory DataFrame to be used for mapping.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        A Series containing the building IDs corresponding to the pings in the trajectory.\n",
    "    \"\"\"\n",
    "    # Build pings GeoDataFrame\n",
    "    pings_df = traj[['x', 'y']].copy()\n",
    "    pings_df[\"pings_geometry\"] = pings_df.apply(lambda row: Point(row[\"x\"], row[\"y\"]), axis=1)\n",
    "    pings_df = gpd.GeoDataFrame(pings_df, geometry=\"pings_geometry\", crs=poi_table.crs)\n",
    "    \n",
    "    # First spatial join (within)\n",
    "    pings_df = gpd.sjoin(pings_df, poi_table, how=\"left\", predicate=\"within\")\n",
    "    \n",
    "    # Identify unmatched pings\n",
    "    unmatched_mask = pings_df[\"building_id\"].isna()\n",
    "    unmatched_pings = pings_df[unmatched_mask].drop(columns=[\"building_id\", \"index_right\"])\n",
    "    \n",
    "    if not unmatched_pings.empty:\n",
    "        # Nearest spatial join for unmatched pings\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Geometry is in a geographic CRS.*\")\n",
    "            nearest = gpd.sjoin_nearest(unmatched_pings, poi_table, how=\"left\", max_distance=max_distance)\n",
    "\n",
    "        # Keep only the first match for each original ping\n",
    "        nearest = nearest.groupby(nearest.index).first()\n",
    "\n",
    "        # Update original DataFrame with nearest matches\n",
    "        pings_df.loc[unmatched_mask, \"building_id\"] = nearest[\"building_id\"].values\n",
    "\n",
    "    return pings_df[\"building_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3589648",
   "metadata": {},
   "source": [
    "### One day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = one_day_traj.copy()\n",
    "plot_df.loc[:,'x'] = (plot_df['x'] - 4265699)/15\n",
    "plot_df.loc[:,'y'] = (plot_df['y'] + 4392976)/15\n",
    "gdf = gpd.read_file('../garden_city.geojson')\n",
    "poi_labels = poi_map(plot_df,\n",
    "                     poi_table=gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a1c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_building_traj = one_day_traj.merge(poi_labels, left_index=True, right_index=True)\n",
    "test_building_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pairs, times = HDBSCAN._find_temp_neighbors(times = one_day_traj['timestamp'], time_thresh = 600, is_datetime=False)\n",
    "core_distances, coords = HDBSCAN._compute_core_distance(one_day_traj, time_pairs, times, is_long_lat=False, traj_cols=traj_cols, min_pts=2)\n",
    "mrd = HDBSCAN._compute_mrd_graph(coords, times, time_pairs, core_distances, is_long_lat=False)\n",
    "mst_edges = HDBSCAN._mst(mrd)\n",
    "mstext_edges = HDBSCAN.mst_ext(mst_edges, core_distances)\n",
    "label_history_df, hierarchy_df = HDBSCAN.hdbscan(mstext_edges, min_cluster_size = 3)\n",
    "cluster_stability_df = HDBSCAN.compute_cluster_stability(label_history_df)\n",
    "selected_clusters = HDBSCAN.select_most_stable_clusters(hierarchy_df, cluster_stability_df)\n",
    "sample_labels_hdbscan = HDBSCAN.hdbscan_labels(label_history_df, selected_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e291966",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_hdbscan = test_building_traj.merge(sample_labels_hdbscan, left_on='timestamp', right_on='time')\n",
    "merged_data_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Merging sample data with labels\n",
    "merged_data_hdbscan = one_day_traj.merge(sample_labels_hdbscan, left_on='timestamp', right_on='time')\n",
    "merged_data_hdbscan.loc[:,'x'] = (merged_data_hdbscan['x'] - 4265699)/15\n",
    "merged_data_hdbscan.loc[:,'y'] = (merged_data_hdbscan['y'] + 4392976)/15\n",
    "# merged_data_hdbscan = merged_data_hdbscan[~(merged_data_hdbscan['cluster'] == -1)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.box(on=True)\n",
    "\n",
    "# Plotting Garden City Map\n",
    "city = cg.load('../garden-city.pkl')\n",
    "city.plot_city(ax, doors=True, address=False)\n",
    "\n",
    "# Getting colors for clusters\n",
    "unique_clusters = sorted(merged_data_hdbscan['cluster'].unique())\n",
    "cluster_mapping = {cluster: i for i, cluster in enumerate(unique_clusters)}\n",
    "# del cluster_mapping[-1]\n",
    "cmap_base = plt.get_cmap('tab10', len(unique_clusters) - (1 if -1 in unique_clusters else 0))\n",
    "colors = ['black'] + list(cmap_base.colors)\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "mapped_clusters = merged_data_hdbscan['cluster'].map(lambda x: cluster_mapping[x] + 1 if x != -1 else 0).to_numpy()\n",
    "\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Plotting Pings\n",
    "ax.scatter(merged_data_hdbscan['x'], \n",
    "           merged_data_hdbscan['y'], \n",
    "           c=mapped_clusters, \n",
    "           cmap=extended_cmap, \n",
    "           s=6,\n",
    "           alpha=1,\n",
    "           zorder=2)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "# ax.set_title(\"HDBSCAN Stops for Sample User\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('gc_empty.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19bd95",
   "metadata": {},
   "source": [
    "### All days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'uid':'uid',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}\n",
    "\n",
    "time_pairs, times = HDBSCAN._find_temp_neighbors(times = traj['timestamp'], time_thresh = 600, is_datetime=False)\n",
    "core_distances, coords = HDBSCAN._compute_core_distance(traj, time_pairs, times, is_long_lat=False, traj_cols=traj_cols, min_pts=2)\n",
    "mrd = HDBSCAN._compute_mrd_graph(coords, times, time_pairs, core_distances, is_long_lat=False)\n",
    "mst_edges = HDBSCAN._mst(mrd)\n",
    "mstext_edges = HDBSCAN.mst_ext(mst_edges, core_distances)\n",
    "label_history_df, hierarchy_df = HDBSCAN.hdbscan(mstext_edges, min_cluster_size = 3)\n",
    "cluster_stability_df = HDBSCAN.compute_cluster_stability(label_history_df)\n",
    "selected_clusters = HDBSCAN.select_most_stable_clusters(hierarchy_df, cluster_stability_df)\n",
    "sample_labels_hdbscan = HDBSCAN.hdbscan_labels(label_history_df, selected_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca208ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels_hdbscan['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c6ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Merging sample data with labels\n",
    "merged_data_hdbscan = traj.merge(sample_labels_hdbscan, left_on='timestamp', right_on='time')\n",
    "merged_data_hdbscan.loc[:,'x'] = (merged_data_hdbscan['x'] - 4265699)/15\n",
    "merged_data_hdbscan.loc[:,'y'] = (merged_data_hdbscan['y'] + 4392976)/15\n",
    "# merged_data_hdbscan = merged_data_hdbscan[~(merged_data_hdbscan['cluster'] == -1)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.box(on=True)\n",
    "\n",
    "# Plotting Garden City Map\n",
    "city = cg.load('../garden-city.pkl')\n",
    "city.plot_city(ax, doors=True, address=False)\n",
    "\n",
    "# Getting colors for clusters\n",
    "unique_clusters = sorted(merged_data_hdbscan['cluster'].unique())\n",
    "cluster_mapping = {cluster: i for i, cluster in enumerate(unique_clusters)}\n",
    "# del cluster_mapping[-1]\n",
    "cmap_base = plt.get_cmap('tab10', len(unique_clusters) - (1 if -1 in unique_clusters else 0))\n",
    "colors = ['black'] + list(cmap_base.colors)\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "mapped_clusters = merged_data_hdbscan['cluster'].map(lambda x: cluster_mapping[x] + 1 if x != -1 else 0).to_numpy()\n",
    "\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Plotting Pings\n",
    "ax.scatter(merged_data_hdbscan['x'], \n",
    "           merged_data_hdbscan['y'], \n",
    "           c=mapped_clusters, \n",
    "           cmap=extended_cmap, \n",
    "           s=6,\n",
    "           alpha=1,\n",
    "           zorder=2)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "# ax.set_title(\"HDBSCAN Stops for Sample User\")\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('gc_empty.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e67de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_stop_table = HDBSCAN.st_hdbscan(traj = traj,\n",
    "                                        is_long_lat = False,\n",
    "                                        is_datetime = False,\n",
    "                                        traj_cols = traj_cols,\n",
    "                                        complete_output = True,\n",
    "                                        time_thresh = 600,\n",
    "                                        min_pts = 2,\n",
    "                                        min_cluster_size = 3)\n",
    "hdbscan_stop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lachesis_labels = LACHESIS._lachesis_labels(traj=traj,\n",
    "                                            dur_min=5,\n",
    "                                            dt_max=60,\n",
    "                                            delta_roam=3,\n",
    "                                            traj_cols=traj_cols)\n",
    "\n",
    "lachesis_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Merging sample data with labels\n",
    "merged_data_lachesis = traj.merge(lachesis_labels.to_frame(name='cluster'), left_on='timestamp', right_index=True)\n",
    "merged_data_lachesis.loc[:,'x'] = (merged_data_lachesis['x'] - 4265699)/15\n",
    "merged_data_lachesis.loc[:,'y'] = (merged_data_lachesis['y'] + 4392976)/15\n",
    "# merged_data_lachesis = merged_data_lachesis[~(merged_data_lachesis['cluster'] == -1)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.box(on=True)\n",
    "\n",
    "# Plotting Garden City Map\n",
    "city = cg.load('../garden-city.pkl')\n",
    "city.plot_city(ax, doors=True, address=False)\n",
    "\n",
    "# Getting colors for clusters\n",
    "unique_clusters = sorted(merged_data_lachesis['cluster'].unique())\n",
    "cluster_mapping = {cluster: i for i, cluster in enumerate(unique_clusters)}\n",
    "# del cluster_mapping[-1]\n",
    "cmap_base = plt.get_cmap('tab10', len(unique_clusters) - (1 if -1 in unique_clusters else 0))\n",
    "colors = ['black'] + list(cmap_base.colors)\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "mapped_clusters = merged_data_lachesis['cluster'].map(lambda x: cluster_mapping[x] + 1 if x != -1 else 0).to_numpy()\n",
    "\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Plotting Pings\n",
    "ax.scatter(merged_data_lachesis['x'], \n",
    "           merged_data_lachesis['y'], \n",
    "           c=mapped_clusters, \n",
    "           cmap=extended_cmap, \n",
    "           s=6,\n",
    "           alpha=1,\n",
    "           zorder=2)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_title(\"Lachesis Stops for Sample User\")\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('gc_empty.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8271a53",
   "metadata": {},
   "source": [
    "### HDBSCAN by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels_hdbscan_by_date = traj.groupby(['date']).apply(lambda x: HDBSCAN.st_hdbscan(traj = x,\n",
    "                                                          is_long_lat = False,\n",
    "                                                          is_datetime = False,\n",
    "                                                          traj_cols = traj_cols,\n",
    "                                                          complete_output = True,\n",
    "                                                          time_thresh = 600,\n",
    "                                                          min_pts = 2,\n",
    "                                                          min_cluster_size = 3),\n",
    "                            include_groups=False)\n",
    "sample_labels_hdbscan_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels_hdbscan_by_date['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Merging sample data with labels\n",
    "sample_labels_hdbscan_by_date.loc[:,'x'] = (sample_labels_hdbscan_by_date['x'] - 4265699)/15\n",
    "sample_labels_hdbscan_by_date.loc[:,'y'] = (sample_labels_hdbscan_by_date['y'] + 4392976)/15\n",
    "# merged_data_hdbscan = merged_data_hdbscan[~(merged_data_hdbscan['cluster'] == -1)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.box(on=True)\n",
    "\n",
    "# Plotting Garden City Map\n",
    "city = cg.load('../garden-city.pkl')\n",
    "city.plot_city(ax, doors=True, address=False)\n",
    "\n",
    "# Getting colors for clusters\n",
    "unique_clusters = sorted(sample_labels_hdbscan_by_date['cluster'].unique())\n",
    "cluster_mapping = {cluster: i for i, cluster in enumerate(unique_clusters)}\n",
    "# del cluster_mapping[-1]\n",
    "cmap_base = plt.get_cmap('tab10', len(unique_clusters) - (1 if -1 in unique_clusters else 0))\n",
    "colors = ['black'] + list(cmap_base.colors)\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "mapped_clusters = sample_labels_hdbscan_by_date['cluster'].map(lambda x: cluster_mapping[x] + 1 if x != -1 else 0).to_numpy()\n",
    "\n",
    "extended_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Plotting Pings\n",
    "ax.scatter(sample_labels_hdbscan_by_date['x'], \n",
    "           sample_labels_hdbscan_by_date['y'], \n",
    "           c=mapped_clusters, \n",
    "           cmap=extended_cmap, \n",
    "           s=6,\n",
    "           alpha=1,\n",
    "           zorder=2)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "# ax.set_title(\"HDBSCAN Stops for Sample User\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('gc_empty.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110006d2",
   "metadata": {},
   "source": [
    "## Simple test synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset with connected 2 components connected by an edge with weight infinity\n",
    "def synthetic_graph_with_cc():\n",
    "    # MST edges within cluster A\n",
    "    edges_a = [(1, 2, 0.15), (2, 3, 0.20)]\n",
    "    # MST edges within cluster B\n",
    "    edges_b = [(4, 5, 0.1), (5, 6, 0.19)]\n",
    "    # Artificial high-weight edge between cluster A and B\n",
    "    bridge_edge = [(3, 4, np.inf)]\n",
    "\n",
    "    # Combine into full MST+ext\n",
    "    mst_ext_df = pd.DataFrame(edges_a + edges_b + bridge_edge, columns=[\"from\", \"to\", \"weight\"])\n",
    "\n",
    "    return mst_ext_df\n",
    "\n",
    "# Synthetic dataset with connected 4 components\n",
    "def synthetic_graph_with_4cc():\n",
    "    # Cluster A\n",
    "    edges_a = [(1, 2, 5), (2, 3, 7)]\n",
    "    # Cluster B\n",
    "    edges_b = [(4, 5, 5), (5, 6, 8)]\n",
    "    # Cluster C\n",
    "    edges_c = [(7, 8, 2), (8, 9, 6)]\n",
    "    # Cluster D\n",
    "    edges_d = [(10, 11, 4), (11, 12, 8)]\n",
    "\n",
    "    # Bridge edges with high weights\n",
    "    bridges = [\n",
    "        (3, 4, np.inf),  # A to B\n",
    "        (6, 7, 20),  # B to C\n",
    "        (9, 10, 15)  # C to D\n",
    "    ]\n",
    "\n",
    "    all_edges = edges_a + edges_b + edges_c + edges_d + bridges\n",
    "    mst_ext_df = pd.DataFrame(all_edges, columns=[\"from\", \"to\", \"weight\"])\n",
    "\n",
    "    return mst_ext_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "def visualize_mst_evolution(mst_df, gif_filename=\"mst_evolution.gif\", duration=500.0):\n",
    "    # Build full graph and collect all nodes\n",
    "    full_edges = []\n",
    "    all_nodes = set()\n",
    "\n",
    "    for u, v, w in mst_df.itertuples(index=False):\n",
    "        w_val = 1e6 if np.isinf(w) else w\n",
    "        inv_w = 1.0 / w_val if w_val > 0 else 0.001\n",
    "        label = \"∞\" if np.isinf(w) else f\"{w:.2f}\"\n",
    "        full_edges.append((u, v, {'weight': w_val, 'inv_weight': inv_w, 'label': label}))\n",
    "        all_nodes.update([u, v])\n",
    "\n",
    "    # Sort edges by decreasing weight\n",
    "    full_edges_sorted = sorted(full_edges, key=lambda x: -x[2]['weight'])\n",
    "\n",
    "    # Fixed layout (use inverse weights)\n",
    "    G_full = nx.Graph()\n",
    "    G_full.add_nodes_from(all_nodes)\n",
    "    G_full.add_edges_from(full_edges)\n",
    "    pos = nx.spring_layout(G_full, weight='inv_weight', seed=50)\n",
    "\n",
    "    # Iteratively remove edges and save frames\n",
    "    frames = []\n",
    "    for i in range(len(full_edges_sorted) + 1):\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(all_nodes)\n",
    "        remaining_edges = full_edges_sorted[i:]\n",
    "        G.add_edges_from(remaining_edges)\n",
    "\n",
    "        edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "\n",
    "        # Draw and save\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=200, edge_color='gray', width=2)\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, label_pos=0.5, rotate=False,\n",
    "                                     font_size=10, bbox=dict(facecolor='white', edgecolor='none'))\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Add epsilon text (for removed edge weight)\n",
    "        if i > 0:\n",
    "            removed_edge = full_edges_sorted[i - 1]\n",
    "            removed_weight = removed_edge[2]['weight']\n",
    "            epsilon_display = \"∞\" if removed_weight >= 1e6 else f\"{removed_weight:.2f}\"\n",
    "            plt.text(\n",
    "                0.05, 0.95, f\"ε = {epsilon_display}\",\n",
    "                transform=plt.gca().transAxes,\n",
    "                fontsize=14, fontweight='bold',\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(facecolor='white', edgecolor='none', pad=0.5)\n",
    "            )\n",
    "\n",
    "        fname = f\"mst_frame_{i:02d}.png\"\n",
    "        plt.savefig(fname)\n",
    "        frames.append(fname)\n",
    "        plt.close()\n",
    "\n",
    "    # Create GIF\n",
    "    with imageio.get_writer(gif_filename, mode=\"I\", duration=duration, loop=0) as writer:\n",
    "        for fname in frames:\n",
    "            writer.append_data(imageio.imread(fname))\n",
    "\n",
    "        # Add final frame pause\n",
    "        final_img = imageio.imread(frames[-1])\n",
    "        for _ in range(5):\n",
    "            writer.append_data(final_img)\n",
    "\n",
    "    for fname in frames:\n",
    "        os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mst_4cc = synthetic_graph_with_4cc()\n",
    "display(mst_4cc)\n",
    "visualize_mst_evolution(mst_4cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mst_ext_df = synthetic_graph_with_cc()\n",
    "# display(mst_ext_df)\n",
    "# visualize_mst(mst_ext_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986c67f",
   "metadata": {},
   "source": [
    "- λ_min(Ci): minimum density level at which Ci exists\n",
    "    - ε_max(Ci): maximum ε value (scale) at which Ci exisits\n",
    "- λ_max(xj,Ci): the density level beyond which object xj no longer belongs to cluster Ci\n",
    "    - ε_min(xj , Ci): ε value (scale) beyond which object xj no longer belongs to cluster Ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab18fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_stability_df = pd.DataFrame({\n",
    "#     \"cluster_id\": [2,3,4,5,6,7,8,9,10,11],\n",
    "#     \"cluster_stability\": [7,5,6,6,2,1,1,1,2,2]\n",
    "# })\n",
    "\n",
    "# hierarchy_df = pd.DataFrame({\n",
    "#     \"child\": [2,3,4,5,6,7,8,9,10,11],\n",
    "#     \"parent\": [0,0,2,2,3,3,5,5,8,8],\n",
    "#     \"scale\": [np.inf,np.inf,np.inf,np.inf,np.inf,np.inf,np.inf,np.inf,np.inf,np.inf]\n",
    "# }) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beab498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0006e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import date, time, datetime, timedelta\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37389d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nomad.io.base as loader\n",
    "import nomad.visit_attribution as visits\n",
    "import nomad.stop_detection.lachesis as LACHESIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2f11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dawn_time(day_part, dawn_hour=6): # extracts the duration of dawn for a day part\n",
    "    s,e = day_part\n",
    "    return np.min([(e.hour*60 + e.minute),dawn_hour*60]) - np.min([(s.hour*60 + s.minute),dawn_hour*60]) \n",
    "\n",
    "def dusk_time(day_part, dusk_hour=19): # extracts the duration of dusk for a day part\n",
    "    s,e = day_part\n",
    "    return np.max([(e.hour*60 + e.minute)-dusk_hour*60,0]) - np.max([(s.hour*60 + s.minute)-dusk_hour*60, 0])\n",
    "\n",
    "def slice_datetimes_interval_fast(start, end): # counts full days and tails\n",
    "    full_days = (datetime.combine(end, time.min) - datetime.combine(start, time.max)).days\n",
    "    if full_days >= 0:\n",
    "        day_parts = [(start.time(), time.max), (time.min, end.time())]\n",
    "    else:\n",
    "        full_days = 0\n",
    "        day_parts = [(start.time(), end.time()), (start.time(), start.time())]\n",
    "    return full_days, day_parts\n",
    "\n",
    "def duration_at_night_fast(start, end): #computes overlap\n",
    "    dawn_hour = 6\n",
    "    dusk_hour = 19\n",
    "    full_days, (part1, part2) = slice_datetimes_interval_fast(start, end)\n",
    "    total_dawn_time = dawn_time(part1, dawn_hour)+dawn_time(part2, dawn_hour)\n",
    "    total_dusk_time = dusk_time(part1, dusk_hour)+dusk_time(part2, dusk_hour)\n",
    "    return int(total_dawn_time + total_dusk_time + full_days*(dawn_hour + (24-dusk_hour))*60)\n",
    "\n",
    "def clip_stays_date(traj, dates):\n",
    "    start = pd.to_datetime(traj['start_datetime'])\n",
    "    duration = traj['duration']\n",
    "\n",
    "    # Ensure timezone-aware clipping bounds\n",
    "    tz = start.dt.tz\n",
    "    date_0 = pd.Timestamp(parse(dates[0]), tz=tz)\n",
    "    date_1 = pd.Timestamp(parse(dates[1]), tz=tz)\n",
    "\n",
    "    end = start + pd.to_timedelta(duration, unit='m')\n",
    "\n",
    "    # Clip to date range\n",
    "    start_clipped = start.clip(lower=date_0, upper=date_1)\n",
    "    end_clipped = end.clip(lower=date_0, upper=date_1)\n",
    "\n",
    "    # Recompute durations\n",
    "    duration_clipped = ((end_clipped - start_clipped).dt.total_seconds() // 60).astype(int)\n",
    "    duration_night = [duration_at_night_fast(s, e) for s, e in zip(start_clipped, end_clipped)]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'id': traj['id'].values,\n",
    "        'start': start_clipped,\n",
    "        'duration': duration_clipped,\n",
    "        'duration_night': duration_night,\n",
    "        'location': traj['location']\n",
    "    })\n",
    "\n",
    "def count_nights(usr_polygon):   \n",
    "    min_dwell = 10\n",
    "    dawn_hour = 6\n",
    "    dusk_hour = 19\n",
    "    nights = set()\n",
    "    weeks = set()\n",
    "\n",
    "    for _, row in usr_polygon.iterrows():\n",
    "        d = row['start']\n",
    "        d = pd.to_datetime(d)\n",
    "        full_days, (part1, part2) = slice_datetimes_interval_fast(d, d + pd.to_timedelta(row['duration'], unit='m'))\n",
    "\n",
    "        dawn1 = dawn_time(part1, dawn_hour)\n",
    "        dusk1 = dusk_time(part1, dusk_hour)\n",
    "        dawn2 = dawn_time(part2, dawn_hour)\n",
    "        dusk2 = dusk_time(part2, dusk_hour)\n",
    "\n",
    "        if full_days == 0:\n",
    "            if dawn1 >= min_dwell:\n",
    "                night = d - timedelta(days=1)\n",
    "                nights.add(night.date())\n",
    "                weeks.add((night - timedelta(days=night.weekday())).date())\n",
    "\n",
    "            if (dusk1 + dawn2) >= min_dwell:\n",
    "                night = d\n",
    "                nights.add(night.date())\n",
    "                weeks.add((night - timedelta(days=night.weekday())).date())\n",
    "\n",
    "            if dusk2 >= min_dwell:\n",
    "                night = d + timedelta(days=1)\n",
    "                nights.add(night.date())\n",
    "                weeks.add((night - timedelta(days=night.weekday())).date())\n",
    "        else:\n",
    "            if dawn1 >= min_dwell:\n",
    "                night = d - timedelta(days=1)\n",
    "                nights.add(night.date())\n",
    "                weeks.add((night - timedelta(days=night.weekday())).date())\n",
    "\n",
    "            for t in range(full_days + 1):\n",
    "                night = d + timedelta(days=t)\n",
    "                nights.add(night.date())\n",
    "                weeks.add((night - timedelta(days=night.weekday())).date())\n",
    "\n",
    "            if dusk2 >= min_dwell:\n",
    "                night = d + timedelta(days=full_days + 1)\n",
    "                nights.add(night.date())\n",
    "                weeks.add((night - timedelta(days=night.weekday())).date())\n",
    "\n",
    "    identifier = usr_polygon['id'].iloc[0]\n",
    "    location = usr_polygon['location'].iloc[0]\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        'id': identifier,\n",
    "        'location': location,\n",
    "        'night_count': len(nights),\n",
    "        'week_count': len(weeks)\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0922eec3-4582-4528-8ddd-efb067c61cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "garden_city.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m poi_table \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgarden_city.gpkg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m poi_table\u001b[38;5;241m.\u001b[39mcrs\n",
      "File \u001b[1;32m~\\daphme\\lib\\site-packages\\geopandas\\io\\file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[0;32m    295\u001b[0m         filename, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, columns\u001b[38;5;241m=\u001b[39mcolumns, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[1;32m~\\daphme\\lib\\site-packages\\geopandas\\io\\file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyogrio\u001b[38;5;241m.\u001b[39mread_dataframe(path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\daphme\\lib\\site-packages\\pyogrio\\geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m read_func(\n\u001b[0;32m    266\u001b[0m     path_or_buffer,\n\u001b[0;32m    267\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    268\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    269\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    270\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[0;32m    271\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mgdal_force_2d,\n\u001b[0;32m    272\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[0;32m    273\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features,\n\u001b[0;32m    274\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    275\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m    276\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    277\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[0;32m    278\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[0;32m    279\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[0;32m    280\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mfid_as_index,\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    282\u001b[0m )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\daphme\\lib\\site-packages\\pyogrio\\raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDataSourceError\u001b[0m: garden_city.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "poi_table = gpd.read_file('garden_city.gpkg')\n",
    "poi_table.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {'user_id':'uid',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'timestamp':'timestamp'}\n",
    "\n",
    "sparse_df = loader.from_file(\"./long-gc-data/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                       parse_dates=True)\n",
    "\n",
    "# Reproject from gc_coords to web mercator\n",
    "sparse_df.loc[:,'x'] = (sparse_df['x'] - 4265699)/15\n",
    "sparse_df.loc[:,'y'] = (sparse_df['y'] + 4392976)/15\n",
    "\n",
    "# Select data from 1 user\n",
    "user = sparse_df.uid.unique()[0]\n",
    "user_sample = sparse_df.loc[sparse_df.uid == user].copy()\n",
    "\n",
    "user_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUR_MIN=5\n",
    "DT_MAX=60\n",
    "DELTA_ROAM=100\n",
    "\n",
    "traj_cols = {'user_id':'uid',\n",
    "             'x':'x',\n",
    "             'y':'y',\n",
    "             'datetime':'datetime'}\n",
    "\n",
    "stop_table_lachesis = LACHESIS.lachesis(traj=user_sample,\n",
    "                                        dur_min=DUR_MIN,\n",
    "                                        dt_max=DT_MAX,\n",
    "                                        delta_roam=DELTA_ROAM,\n",
    "                                        traj_cols=traj_cols,\n",
    "                                        keep_col_names=False,\n",
    "                                        complete_output=True,\n",
    "                                        datetime = 'datetime')\n",
    "\n",
    "user_sample['cluster'] = LACHESIS._lachesis_labels(traj=user_sample,\n",
    "                                            dur_min=DUR_MIN,\n",
    "                                            dt_max=DT_MAX,\n",
    "                                            delta_roam=DELTA_ROAM,\n",
    "                                            traj_cols=traj_cols,\n",
    "                                            datetime = 'datetime').values\n",
    "\n",
    "pred_lachesis = visits.point_in_polygon(\n",
    "                 data=user_sample,\n",
    "                 poi_table=poi_table,\n",
    "                 traj_cols=traj_cols,\n",
    "                 max_distance=2,\n",
    "                 x='x',\n",
    "                 y='y',\n",
    "                 data_crs='EPSG:4326')\n",
    "\n",
    "pred_lachesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a09e39-3449-4375-961b-4b46cadc9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LACHESIS._lachesis_labels(traj=user_sample,\n",
    "                                            dur_min=DUR_MIN,\n",
    "                                            dt_max=DT_MAX,\n",
    "                                            delta_roam=DELTA_ROAM,\n",
    "                                            traj_cols=traj_cols,\n",
    "                                            datetime = 'datetime')\n",
    "user_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348091f-3f50-4075-be24-0f0a93a1aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.point_in_polygon(user_sample, poi_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa5470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop detection output\n",
    "stop_table_lachesis['start_datetime'] = pd.to_datetime(stop_table_lachesis['start_datetime'])\n",
    "\n",
    "if 'id' not in stop_table_lachesis.columns:\n",
    "    stop_table_lachesis['id'] = user\n",
    "\n",
    "# Date range\n",
    "start_date = \"2024-01-02\"\n",
    "weeks = 2\n",
    "end_date = (parse(start_date) + timedelta(weeks=weeks)).date().isoformat()\n",
    "dates = (start_date, end_date)\n",
    "df_clipped = clip_stays_date(stop_table_lachesis, dates)\n",
    "df_clipped = df_clipped[(df_clipped['duration'] > 0) & (df_clipped['duration_night'] >= 15)]\n",
    "df_clipped.groupby(['id', 'location'], group_keys=False).apply(count_nights).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (daphme)",
   "language": "python",
   "name": "daphme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

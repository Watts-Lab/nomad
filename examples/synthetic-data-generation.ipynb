{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c2bbc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "from pyproj import Transformer\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import numpy.random as npr\n",
    "import matplotlib.dates as mdates\n",
    "from itertools import product\n",
    "import copy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nomad.io.base as loader\n",
    "import nomad.city_gen as cg\n",
    "from nomad.city_gen import City, Building, Street\n",
    "import nomad.traj_gen as tg\n",
    "from nomad.traj_gen import Agent, Population\n",
    "import nomad.stop_detection.ta_dbscan as DBSCAN\n",
    "import nomad.stop_detection.lachesis as Lachesis\n",
    "from nomad.constants import DEFAULT_SPEEDS, FAST_SPEEDS, SLOW_SPEEDS, DEFAULT_STILL_PROBS\n",
    "from nomad.constants import FAST_STILL_PROBS, SLOW_STILL_PROBS, ALLOWED_BUILDINGS\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd1f76-2bc8-4526-b82b-5ff823b58080",
   "metadata": {},
   "source": [
    "### Generate N agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7458fd",
   "metadata": {},
   "source": [
    "The following code maps our Garden City coordinates to a location in the Atlantic Ocean (Atlantis?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61096f8-ac2f-4861-8973-aa29cfe8a583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "\n",
    "def garden_city_to_lat_long(agent, \n",
    "                            sparse_traj=True, \n",
    "                            full_traj=True):\n",
    "    if sparse_traj:\n",
    "        df = agent.sparse_traj\n",
    "        df['x'] = 15*df['x'] + 4265699\n",
    "        df['y'] = 15*df['y'] - 4392976\n",
    "\n",
    "        df['longitude'], df['latitude'] = transformer.transform(\n",
    "            df['x'].values, df['y'].values)\n",
    "\n",
    "        df['date'] = df['local_timestamp'].dt.date  # for partitioning purposes\n",
    "\n",
    "        df = df[['identifier', 'unix_timestamp', 'tz_offset', 'longitude', 'latitude', 'date']]\n",
    "        df = df.rename(columns={'identifier': 'uid', 'unix_timestamp': 'timestamp'})\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        agent.sparse_traj = df\n",
    "\n",
    "    if full_traj:\n",
    "        df = agent.trajectory\n",
    "        df['x'] = 15*df['x'] + 4265699\n",
    "        df['y'] = 15*df['y'] - 4392976\n",
    "\n",
    "        df['longitude'], df['latitude'] = transformer.transform(\n",
    "            df['x'].values, df['y'].values)\n",
    "\n",
    "        df['date'] = df['local_timestamp'].dt.date  # for partitioning purposes\n",
    "\n",
    "        df = df[['identifier', 'unix_timestamp', 'tz_offset', 'longitude', 'latitude', 'date']]\n",
    "        df = df.rename(columns={'identifier': 'uid', 'unix_timestamp': 'timestamp'})\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        agent.trajectory = df\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53d3fc",
   "metadata": {},
   "source": [
    "Initiate $N$ empty agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a6aad3-6295-42df-9eaa-156f82bb5bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 100  # can modify\n",
    "\n",
    "population = Population(city)\n",
    "population.generate_agents(N=100, seed=16, name_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc42f4e",
   "metadata": {},
   "source": [
    "## Simple trajectory generation\n",
    "\n",
    "For simple trajectory generation tasks that don't require too much computation power and can be done on a personal laptop, the following code generates a trajectory for each agent and saves it to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96eced70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent_trajectory(agent_id, agent, seed):\n",
    "    \n",
    "    beta_duration = npr.uniform(12, 150)\n",
    "    beta_start = max(npr.uniform(30, 600), beta_duration)\n",
    "    beta_ping = min(npr.uniform(3, 20), beta_duration//2)\n",
    "    print(beta_ping, beta_start, beta_duration)\n",
    "    agent.generate_trajectory(\n",
    "        local_timestamp = \"2024-01-01T06:00 +02:00\",\n",
    "        end_time = pd.Timestamp('2024-01-08T13:30:00 +02:00'),\n",
    "        seed=100,\n",
    "        dt=0.5)\n",
    "    print('finished generating trajectory')\n",
    "    agent.sample_trajectory(\n",
    "        beta_start=beta_start,\n",
    "        beta_duration=beta_duration,\n",
    "        beta_ping = beta_ping,\n",
    "        seed=seed,\n",
    "        replace_sparse_traj=True)\n",
    "    \n",
    "    garden_city_to_lat_long(agent,\n",
    "                            sparse_traj=True,\n",
    "                            full_traj=False)\n",
    "    \n",
    "    return agent_id, copy.deepcopy(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37e54865-9e90-4361-8deb-9aff11502a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adoring_keldysh'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_id, agent = [(agent_id, agent) for agent_id, agent in population.roster.items()][0]\n",
    "agent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5375aa3-7041-44fb-a74d-f49fb857e3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.672309028016706 545.5630261073721 146.43329817344105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_agent_trajectory(agent_id, agent, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "roster = population_n.roster\n",
    "sparse_trajs = pd.concat([agent.sparse_traj for _, agent in roster.items()]).reset_index(drop=True)\n",
    "sparse_trajs.to_csv('../nomad/data/gc_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fff2b5",
   "metadata": {},
   "source": [
    "## Parallelized Trajectory Generation\n",
    "\n",
    "For larger trajectory generation tasks that require a lot of compute power, we can parallelize the trajectory generation using the following code. We generate ground-truth trajectories in agent-month \"chunks\", sparsify each chunk, then reset the ground-truth trajectory field to lessen the memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a7903-4257-4932-9bee-42dd1ebaf2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing agents:  10%|â–‰         | 592/6000 [27:37<4:19:55,  2.88s/it] "
     ]
    }
   ],
   "source": [
    "# Using parallel processing (e.g., using a cluster)\n",
    "%%time\n",
    "\n",
    "def generate_agent_trajectory(agent_id, agent, seed):\n",
    "    \n",
    "    beta_duration = npr.uniform(15, 180)\n",
    "    beta_start = max(npr.uniform(60, 1200), beta_duration*3)\n",
    "    beta_ping = npr.uniform(1.5, 30)\n",
    "    \n",
    "    param = (beta_start, beta_duration, beta_ping)\n",
    "    \n",
    "    for month in range(1,13):\n",
    "        days = calendar.monthrange(2024, month)[1]\n",
    "        population_n.generate_trajectory(agent, \n",
    "                                         T=datetime(2024, month, days, hour=23, minute=59), \n",
    "                                         seed=seed)\n",
    "    \n",
    "        agent.sample_traj_hier_nhpp(*param, \n",
    "                                    seed=seed,\n",
    "                                    reset_traj=True)\n",
    "    \n",
    "    garden_city_to_lat_long(agent,\n",
    "                            sparse_traj=True,\n",
    "                            full_traj=False)\n",
    "    \n",
    "    return agent_id, copy.deepcopy(agent)\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "shared_roster = manager.dict(population_n.roster)\n",
    "\n",
    "start = 6001  # 12001  # can modify\n",
    "end = 12001   # 18001  # can modify\n",
    "roster = dict(population_n.roster)\n",
    "batch = islice(roster.items(), start, end)\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    with tqdm(total=(end-start), desc=\"Processing agents\") as pbar:\n",
    "        futures = [\n",
    "            executor.submit(generate_agent_trajectory, agent_id, agent, i+15000)\n",
    "            for i, (agent_id, agent) in enumerate(batch, start=start)\n",
    "        ]\n",
    "        results = []\n",
    "        for future in futures:\n",
    "            results.append(future.result())\n",
    "            pbar.update(1)\n",
    "\n",
    "for agent_id, agent in results:\n",
    "    population_n.roster[agent_id] = agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966166ca",
   "metadata": {},
   "source": [
    "This code saves the generated trajectories in a parquet file, using the date as the partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc2d3a-a348-42f5-9281-0a7501b4a4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partition_cols = {\n",
    "    'sparse_traj': ['date'],\n",
    "    'diaries': ['identifier']\n",
    "}\n",
    "\n",
    "roster = dict(islice(population_n.roster.items(), start, end))\n",
    "\n",
    "population_n.save_pop(bucket=\"synthetic-raw-data\",\n",
    "                      prefix=f\"agents-{start+15000}-{end+15000-1}/\",\n",
    "                      save_full_traj=False,\n",
    "                      save_sparse_traj=True,\n",
    "                      save_homes=True,\n",
    "                      save_diaries=True,\n",
    "                      partition_cols=partition_cols,\n",
    "                      roster=roster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88b11b-1b79-4921-a434-e1a3f39f522c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Parquet files\n",
    "\n",
    "s3_path = \"s3://synthetic-raw-data/agents-1-1001/sparse_trajectories.parquet/\"\n",
    "df1 = pd.read_parquet(s3_path)\n",
    "s3_path = \"s3://synthetic-raw-data/agents-1001-2000/sparse_trajectories.parquet/\"\n",
    "df2 = pd.read_parquet(s3_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

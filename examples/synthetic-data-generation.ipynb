{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fd0c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "from matplotlib import cm\n",
    "import geopandas as gpd\n",
    "\n",
    "from pyproj import Transformer\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import numpy.random as npr\n",
    "import matplotlib.dates as mdates\n",
    "from itertools import product\n",
    "import copy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nomad.io.base as loader\n",
    "import nomad.city_gen as cg\n",
    "from nomad.city_gen import City, Building\n",
    "import nomad.traj_gen as tg\n",
    "from nomad.traj_gen import Agent, Population\n",
    "import nomad.stop_detection.ta_dbscan as DBSCAN\n",
    "import nomad.stop_detection.lachesis as Lachesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79a7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_geojson = gpd.read_file('garden_city.geojson')\n",
    "city = cg.load('garden-city.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22f6e1",
   "metadata": {},
   "source": [
    "### Generate N agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af174e5",
   "metadata": {},
   "source": [
    "The following code maps our Garden City coordinates to a location in the Atlantic Ocean (Atlantis?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b6dc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def garden_city_to_lat_long(agent, sparse_traj=True, full_traj=False, diaries=True):\n",
    "    def project_city_blocks_to_web_mercator(df):\n",
    "        \"\"\"Convert (x, y) from 15m block units to Web Mercator meters via affine shift and projection.\"\"\"\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\", always_xy=True)\n",
    "        df['x'] = 15 * df['x'] - 4265699\n",
    "        df['y'] = 15 * df['y'] + 4392976\n",
    "        if 'ha' in df:\n",
    "            df['ha'] = 15 * df['ha']\n",
    "        df['longitude'], df['latitude'] = transformer.transform(df['x'].values, df['y'].values)\n",
    "        df['date'] = df['datetime'].dt.date\n",
    "        return df\n",
    "\n",
    "    def finalize(df):\n",
    "        front = ['identifier', 'timestamp', 'longitude', 'latitude', 'x', 'y', 'date']\n",
    "        cols = [col for col in front if col in df] + [col for col in df.columns if col not in front]\n",
    "        return df[cols].rename(columns={'identifier': 'uid', 'timestamp': 'timestamp'}).reset_index(drop=True)\n",
    "\n",
    "    if sparse_traj:\n",
    "        agent.sparse_traj = finalize(project_city_blocks_to_web_mercator(agent.sparse_traj))\n",
    "    if full_traj:\n",
    "        agent.trajectory = finalize(project_city_blocks_to_web_mercator(agent.trajectory))\n",
    "        \n",
    "    if diaries:\n",
    "        diary = agent.diary.copy()\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for loc in diary[\"location\"]:\n",
    "            if loc is None:\n",
    "                xs.append(None)\n",
    "                ys.append(None)\n",
    "            else:\n",
    "                pt = agent.city.buildings[loc].geometry.centroid\n",
    "                xs.append(pt.x)\n",
    "                ys.append(pt.y)\n",
    "        diary[\"x\"] = xs\n",
    "        diary[\"y\"] = ys\n",
    "        agent.diary = finalize(project_city_blocks_to_web_mercator(diary))\n",
    "\n",
    "def gen_params_target_q(q_range=(0.3, 0.9), beta_dur_range=(25, 240), seed=None):\n",
    "    rng = npr.default_rng(seed)\n",
    "    c = rng.uniform(*q_range)\n",
    "    beta_durations = rng.uniform(*beta_dur_range)\n",
    "    beta_start = beta_durations / c\n",
    "    beta_ping = min(\n",
    "        (rng.uniform(2, 8) if rng.random() < 0.5 else rng.uniform(22, 28)),\n",
    "        beta_durations\n",
    "    )\n",
    "    return {\n",
    "        \"beta_durations\": beta_durations,\n",
    "        \"beta_start\": beta_start,\n",
    "        \"beta_ping\": beta_ping\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a5abe",
   "metadata": {},
   "source": [
    "Initiate $N$ empty agents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27199b",
   "metadata": {},
   "source": [
    "## Simple trajectory generation\n",
    "\n",
    "For simple trajectory generation tasks that don't require too much computation power and can be done on a personal laptop, the following code generates a trajectory for each agent and saves it to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e1beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent_trajectory(agent_id, agent, seed):\n",
    "\n",
    "    beta_params = gen_params_target_q(q_range=(0.4, 0.85), seed=seed)\n",
    "\n",
    "    agent.generate_trajectory(\n",
    "        datetime = \"2024-01-01T08:00 -04:00\",\n",
    "        end_time = pd.Timestamp('2024-01-21T08:30:00 -04:00'),\n",
    "        seed=1,\n",
    "        dt=0.25)\n",
    "    print('finished generating trajectory')\n",
    "    agent.sample_trajectory(\n",
    "        **beta_params,\n",
    "        seed=seed,\n",
    "        ha=13/15, # <<<<<<\n",
    "        replace_sparse_traj=True)\n",
    "    \n",
    "    garden_city_to_lat_long(agent,\n",
    "                            sparse_traj=True,\n",
    "                            full_traj=False)\n",
    "    agent.reset_trajectory(trajectory = True, sparse = False, diary = False)\n",
    "    \n",
    "    return agent_id, copy.deepcopy(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828c0340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admiring_adoring_allen'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = Population(city)\n",
    "population.generate_agents(N=1, seed=1, name_count=3)\n",
    "agent_id, agent = [(agent_id, agent) for agent_id, agent in population.roster.items()][0]\n",
    "agent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e588c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_agent_trajectory(agent_id, agent, 1)\n",
    "print(agent.sparse_traj)\n",
    "agent.reset_trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2c0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating trajectories: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [08:45<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "def generate_trajectory_data(agent_id, agent, seed):\n",
    "    beta_params = gen_params_target_q(q_range=(0.4, 0.85), seed=seed)\n",
    "    ha_sample = npr.uniform(11.5/15, 14.5/15)\n",
    "\n",
    "    agent.reset_trajectory()\n",
    "    agent.generate_trajectory(\n",
    "        datetime = \"2024-01-01T08:00 -04:00\",\n",
    "        end_time = pd.Timestamp('2024-01-21T08:00:00 -04:00'),\n",
    "        seed=1,\n",
    "        dt=1)\n",
    "\n",
    "    agent.sample_trajectory(\n",
    "        **beta_params,\n",
    "        seed=seed,\n",
    "        ha=ha_sample,\n",
    "        replace_sparse_traj=True)\n",
    "\n",
    "    garden_city_to_lat_long(agent, sparse_traj=True, full_traj=False)\n",
    "    agent.reset_trajectory(trajectory = True, sparse = False, diary = False)\n",
    "    return None\n",
    "\n",
    "# Generate trajectories with progress bar\n",
    "N = 200  \n",
    "population = Population(city)\n",
    "population.generate_agents(N=N, seed=1, name_count=3)\n",
    "\n",
    "for agent_id, agent in tqdm(population.roster.items(), desc=\"Generating trajectories\"):\n",
    "    generate_trajectory_data(agent_id, agent, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4286bf1-b6f9-4fd0-a284-b39fcbfb613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Documents\\Nomad\\nomad-repo\\nomad\\io\\base.py:82: UserWarning: Trajectory column 'duration' specified for 'duration' not found in DataFrame.\n",
      "  warnings.warn(f\"Trajectory column '{value}' specified for '{key}' not found in DataFrame.\")\n"
     ]
    }
   ],
   "source": [
    "traj_cols = {\n",
    "    \"user_id\": \"uid\",\n",
    "    \"timestamp\": \"timestamp\",\n",
    "    \"latitude\": \"latitude\",\n",
    "    \"longitude\": \"longitude\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"y\",\n",
    "    \"duration\": \"duration\",\n",
    "    \"datetime\": \"datetime\"}\n",
    "# Save only sparse trajectories and diaries\n",
    "population.save_pop(\n",
    "    sparse_path=\"output/sparse_traj/\",\n",
    "    diaries_path=\"output/diaries/\",\n",
    "    partition_cols={\"sparse_traj\": [\"date\"]},\n",
    "    traj_cols=traj_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79e81d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Documents\\Nomad\\nomad-repo\\nomad\\io\\base.py:82: UserWarning: Trajectory column 'duration' specified for 'duration' not found in DataFrame.\n",
      "  warnings.warn(f\"Trajectory column '{value}' specified for '{key}' not found in DataFrame.\")\n"
     ]
    }
   ],
   "source": [
    "sparse_df = loader.from_file(\"output/sparse_traj/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                      parse_dates=True)\n",
    "diaries_df = loader.from_file(\"output/diaries/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                       parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e29eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>location</th>\n",
       "      <th>tz_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704110460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 08:01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704110640</td>\n",
       "      <td>-38.318752</td>\n",
       "      <td>36.669677</td>\n",
       "      <td>-4265624.0</td>\n",
       "      <td>4393163.5</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 08:04:00</td>\n",
       "      <td>237</td>\n",
       "      <td>w-x6-y12</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704124860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 12:01:00</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704125160</td>\n",
       "      <td>-38.317944</td>\n",
       "      <td>36.669515</td>\n",
       "      <td>-4265534.0</td>\n",
       "      <td>4393141.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 12:06:00</td>\n",
       "      <td>115</td>\n",
       "      <td>p-x13-y11</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704132060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 14:01:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      uid   timestamp  longitude   latitude          x  \\\n",
       "0  admiring_adoring_allen  1704110460        NaN        NaN        NaN   \n",
       "1  admiring_adoring_allen  1704110640 -38.318752  36.669677 -4265624.0   \n",
       "2  admiring_adoring_allen  1704124860        NaN        NaN        NaN   \n",
       "3  admiring_adoring_allen  1704125160 -38.317944  36.669515 -4265534.0   \n",
       "4  admiring_adoring_allen  1704132060        NaN        NaN        NaN   \n",
       "\n",
       "           y        date            datetime  duration   location  tz_offset  \n",
       "0        NaN  2024-01-01 2024-01-01 08:01:00         3       None     -14400  \n",
       "1  4393163.5  2024-01-01 2024-01-01 08:04:00       237   w-x6-y12     -14400  \n",
       "2        NaN  2024-01-01 2024-01-01 12:01:00         5       None     -14400  \n",
       "3  4393141.0  2024-01-01 2024-01-01 12:06:00       115  p-x13-y11     -14400  \n",
       "4        NaN  2024-01-01 2024-01-01 14:01:00         3       None     -14400  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0be1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ha</th>\n",
       "      <th>date</th>\n",
       "      <th>tz_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704133889</td>\n",
       "      <td>-38.318668</td>\n",
       "      <td>36.670151</td>\n",
       "      <td>-4.265615e+06</td>\n",
       "      <td>4.393229e+06</td>\n",
       "      <td>2024-01-01 14:31:29</td>\n",
       "      <td>9.108753</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704134027</td>\n",
       "      <td>-38.318785</td>\n",
       "      <td>36.670107</td>\n",
       "      <td>-4.265628e+06</td>\n",
       "      <td>4.393223e+06</td>\n",
       "      <td>2024-01-01 14:33:47</td>\n",
       "      <td>10.713133</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704134062</td>\n",
       "      <td>-38.318737</td>\n",
       "      <td>36.670298</td>\n",
       "      <td>-4.265622e+06</td>\n",
       "      <td>4.393250e+06</td>\n",
       "      <td>2024-01-01 14:34:22</td>\n",
       "      <td>14.330517</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704134695</td>\n",
       "      <td>-38.318655</td>\n",
       "      <td>36.670246</td>\n",
       "      <td>-4.265613e+06</td>\n",
       "      <td>4.393242e+06</td>\n",
       "      <td>2024-01-01 14:44:55</td>\n",
       "      <td>13.560872</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admiring_adoring_allen</td>\n",
       "      <td>1704134797</td>\n",
       "      <td>-38.318711</td>\n",
       "      <td>36.670196</td>\n",
       "      <td>-4.265619e+06</td>\n",
       "      <td>4.393236e+06</td>\n",
       "      <td>2024-01-01 14:46:37</td>\n",
       "      <td>10.365565</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>-14400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      uid   timestamp  longitude   latitude             x  \\\n",
       "0  admiring_adoring_allen  1704133889 -38.318668  36.670151 -4.265615e+06   \n",
       "1  admiring_adoring_allen  1704134027 -38.318785  36.670107 -4.265628e+06   \n",
       "2  admiring_adoring_allen  1704134062 -38.318737  36.670298 -4.265622e+06   \n",
       "3  admiring_adoring_allen  1704134695 -38.318655  36.670246 -4.265613e+06   \n",
       "4  admiring_adoring_allen  1704134797 -38.318711  36.670196 -4.265619e+06   \n",
       "\n",
       "              y            datetime         ha        date  tz_offset  \n",
       "0  4.393229e+06 2024-01-01 14:31:29   9.108753  2024-01-01     -14400  \n",
       "1  4.393223e+06 2024-01-01 14:33:47  10.713133  2024-01-01     -14400  \n",
       "2  4.393250e+06 2024-01-01 14:34:22  14.330517  2024-01-01     -14400  \n",
       "3  4.393242e+06 2024-01-01 14:44:55  13.560872  2024-01-01     -14400  \n",
       "4  4.393236e+06 2024-01-01 14:46:37  10.365565  2024-01-01     -14400  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762faed",
   "metadata": {},
   "source": [
    "## Parallelized Trajectory Generation\n",
    "\n",
    "For larger trajectory generation tasks that require a lot of compute power, we can parallelize the trajectory generation using the following code. We generate ground-truth trajectories in agent-month \"chunks\", sparsify each chunk, then reset the ground-truth trajectory field to lessen the memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e81ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using parallel processing (e.g., using a cluster)\n",
    "%%time\n",
    "\n",
    "def generate_trajectory_data(agent_id, agent, seed):\n",
    "    \n",
    "    beta_duration = npr.uniform(15, 180)\n",
    "    beta_start = max(npr.uniform(60, 1200), beta_duration*3)\n",
    "    beta_ping = npr.uniform(1.5, 30)\n",
    "    \n",
    "    param = (beta_start, beta_duration, beta_ping)\n",
    "    \n",
    "    for month in range(1,13):\n",
    "        days = calendar.monthrange(2024, month)[1]\n",
    "        population_n.generate_trajectory(agent, \n",
    "                                         T=datetime(2024, month, days, hour=23, minute=59), \n",
    "                                         seed=seed)\n",
    "    \n",
    "        agent.sample_traj_hier_nhpp(*param, \n",
    "                                    seed=seed,\n",
    "                                    reset_traj=True)\n",
    "    \n",
    "    garden_city_to_lat_long(agent,\n",
    "                            sparse_traj=True,\n",
    "                            full_traj=False)\n",
    "    \n",
    "    return agent_id, copy.deepcopy(agent)\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "shared_roster = manager.dict(population_n.roster)\n",
    "\n",
    "start = 6001  # 12001  # can modify\n",
    "end = 12001   # 18001  # can modify\n",
    "roster = dict(population_n.roster)\n",
    "batch = islice(roster.items(), start, end)\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    with tqdm(total=(end-start), desc=\"Processing agents\") as pbar:\n",
    "        futures = [\n",
    "            executor.submit(generate_trajectory_data, agent_id, agent, i+15000)\n",
    "            for i, (agent_id, agent) in enumerate(batch, start=start)\n",
    "        ]\n",
    "        results = []\n",
    "        for future in futures:\n",
    "            results.append(future.result())\n",
    "            pbar.update(1)\n",
    "\n",
    "for agent_id, agent in results:\n",
    "    population_n.roster[agent_id] = agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee64f31",
   "metadata": {},
   "source": [
    "This code saves the generated trajectories in a parquet file, using the date as the partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdffd98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partition_cols = {\n",
    "    'sparse_traj': ['date'],\n",
    "    'diaries': ['identifier']\n",
    "}\n",
    "\n",
    "roster = dict(islice(population_n.roster.items(), start, end))\n",
    "\n",
    "population_n.save_pop(bucket=\"synthetic-raw-data\",\n",
    "                      prefix=f\"agents-{start+15000}-{end+15000-1}/\",\n",
    "                      save_full_traj=False,\n",
    "                      save_sparse_traj=True,\n",
    "                      save_homes=True,\n",
    "                      save_diaries=True,\n",
    "                      partition_cols=partition_cols,\n",
    "                      roster=roster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a261b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Parquet files\n",
    "s3_path = \"s3://synthetic-raw-data/agents-1-1001/sparse_trajectories.parquet/\"\n",
    "df1 = pd.read_parquet(s3_path)\n",
    "s3_path = \"s3://synthetic-raw-data/agents-1001-2000/sparse_trajectories.parquet/\"\n",
    "df2 = pd.read_parquet(s3_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (daphme)",
   "language": "python",
   "name": "daphme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3 (ipykernel)"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3.10 (daphme)"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 3,
           "op": "addrange",
           "valuelist": "0"
          },
          {
           "key": 3,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

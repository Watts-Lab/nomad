{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fd0c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (traj_gen.py, line 499)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\daphme\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[1], line 23\u001b[0m\n    import nomad.io.base as loader\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Documents\\Nomad\\nomad-repo\\nomad\\__init__.py:4\u001b[1;36m\n\u001b[1;33m    import nomad.traj_gen\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Documents\\Nomad\\nomad-repo\\nomad\\traj_gen.py:499\u001b[1;36m\u001b[0m\n\u001b[1;33m    initial_locs += list(npr.choice(visit_freqs.loc[visit_freqs.type == 'retail'].index, size=npr.poisson(6))\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "from matplotlib import cm\n",
    "import geopandas as gpd\n",
    "\n",
    "from pyproj import Transformer\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import numpy.random as npr\n",
    "import matplotlib.dates as mdates\n",
    "from itertools import product\n",
    "import copy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nomad.io.base as loader\n",
    "import nomad.city_gen as cg\n",
    "from nomad.city_gen import City, Building\n",
    "import nomad.traj_gen as tg\n",
    "from nomad.traj_gen import Agent, Population\n",
    "import nomad.stop_detection.ta_dbscan as DBSCAN\n",
    "import nomad.stop_detection.lachesis as Lachesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_geojson = gpd.read_file('garden_city.geojson')\n",
    "city = cg.load('garden-city.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22f6e1",
   "metadata": {},
   "source": [
    "### Generate N agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af174e5",
   "metadata": {},
   "source": [
    "The following code maps our Garden City coordinates to a location in the Atlantic Ocean (Atlantis?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6dc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def garden_city_to_lat_long(agent, sparse_traj=True, full_traj=False, diaries=True):\n",
    "    def project_city_blocks_to_web_mercator(df):\n",
    "        \"\"\"Convert (x, y) from 15m block units to Web Mercator meters via affine shift and projection.\"\"\"\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\", always_xy=True)\n",
    "        df['x'] = 15 * df['x'] + 4265699\n",
    "        df['y'] = 15 * df['y'] - 4392976\n",
    "        if 'ha' in df:\n",
    "            df['ha'] = 15 * df['ha']\n",
    "        df['longitude'], df['latitude'] = transformer.transform(df['x'].values, df['y'].values)\n",
    "        df['date'] = df['local_timestamp'].dt.date\n",
    "        return df\n",
    "\n",
    "    def finalize(df):\n",
    "        front = ['identifier', 'unix_timestamp', 'longitude', 'latitude', 'x', 'y', 'date']\n",
    "        cols = [col for col in front if col in df] + [col for col in df.columns if col not in front]\n",
    "        return df[cols].rename(columns={'identifier': 'uid', 'unix_timestamp': 'timestamp'}).reset_index(drop=True)\n",
    "\n",
    "    if sparse_traj:\n",
    "        agent.sparse_traj = finalize(project_city_blocks_to_web_mercator(agent.sparse_traj))\n",
    "    if full_traj:\n",
    "        agent.trajectory = finalize(project_city_blocks_to_web_mercator(agent.trajectory))\n",
    "        \n",
    "    if diaries:\n",
    "        diary = agent.diary.copy()\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for loc in diary[\"location\"]:\n",
    "            if loc is None:\n",
    "                xs.append(None)\n",
    "                ys.append(None)\n",
    "            else:\n",
    "                pt = agent.city.buildings[loc].geometry.centroid\n",
    "                xs.append(pt.x)\n",
    "                ys.append(pt.y)\n",
    "        diary[\"x\"] = xs\n",
    "        diary[\"y\"] = ys\n",
    "        agent.diary = finalize(project_city_blocks_to_web_mercator(diary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a5abe",
   "metadata": {},
   "source": [
    "Initiate $N$ empty agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fd6023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Population' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m  \u001b[38;5;66;03m# can modify\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[43mPopulation\u001b[49m(city)\n\u001b[0;32m      4\u001b[0m population\u001b[38;5;241m.\u001b[39mgenerate_agents(N\u001b[38;5;241m=\u001b[39mN, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, name_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Population' is not defined"
     ]
    }
   ],
   "source": [
    "N = 150  # can modify\n",
    "\n",
    "population = Population(city)\n",
    "population.generate_agents(N=N, seed=16, name_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27199b",
   "metadata": {},
   "source": [
    "## Simple trajectory generation\n",
    "\n",
    "For simple trajectory generation tasks that don't require too much computation power and can be done on a personal laptop, the following code generates a trajectory for each agent and saves it to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent_trajectory(agent_id, agent, seed):\n",
    "    \n",
    "    beta_duration = npr.uniform(12, 150)\n",
    "    beta_start = max(npr.uniform(30, 600), beta_duration)\n",
    "    beta_ping = min(npr.uniform(3, 20), beta_duration//2)\n",
    "    print(beta_ping, beta_start, beta_duration)\n",
    "    agent.generate_trajectory(\n",
    "        local_timestamp = \"2024-01-01T06:00 +02:00\",\n",
    "        end_time = pd.Timestamp('2024-01-08T13:30:00 +02:00'),\n",
    "        seed=100,\n",
    "        dt=0.5)\n",
    "    print('finished generating trajectory')\n",
    "    agent.sample_trajectory(\n",
    "        beta_start=beta_start,\n",
    "        beta_durations=beta_duration,\n",
    "        beta_ping = beta_ping,\n",
    "        seed=seed,\n",
    "        replace_sparse_traj=True)\n",
    "    \n",
    "    garden_city_to_lat_long(agent,\n",
    "                            sparse_traj=True,\n",
    "                            full_traj=False)\n",
    "    \n",
    "    return agent_id, copy.deepcopy(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_id, agent = [(agent_id, agent) for agent_id, agent in population.roster.items()][0]\n",
    "agent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e588c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_agent_trajectory(agent_id, agent, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectory_data(agent_id, agent, seed):\n",
    "    agent.reset_trajectory()\n",
    "    \n",
    "    agent.generate_trajectory(\n",
    "        local_timestamp=\"2024-01-01T06:00:00 +02:00\",\n",
    "        end_time=pd.Timestamp(\"2024-01-20T12:00:00 +02:00\"),\n",
    "        seed=105,\n",
    "        dt=1)\n",
    "\n",
    "    beta_duration = npr.uniform(25, 170)\n",
    "    beta_start = max(npr.uniform(25, 520), beta_duration)\n",
    "    beta_ping = min(npr.uniform(3, 15), beta_duration//2)\n",
    "\n",
    "    agent.sample_trajectory(\n",
    "        beta_start=beta_start,\n",
    "        beta_durations=beta_duration,\n",
    "        beta_ping=beta_ping,\n",
    "        seed=seed,\n",
    "        replace_sparse_traj=True)\n",
    "\n",
    "    garden_city_to_lat_long(agent, sparse_traj=True, full_traj=False)\n",
    "    return None\n",
    "\n",
    "# Generate trajectories with progress bar\n",
    "for agent_id, agent in tqdm(population.roster.items(), desc=\"Generating trajectories\"):\n",
    "    generate_trajectory_data(agent_id, agent, seed=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4286bf1-b6f9-4fd0-a284-b39fcbfb613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cols = {\n",
    "    \"user_id\": \"uid\",\n",
    "    \"timestamp\": \"timestamp\",\n",
    "    \"latitude\": \"latitude\",\n",
    "    \"longitude\": \"longitude\",\n",
    "    \"x\": \"x\",\n",
    "    \"y\": \"y\",\n",
    "    \"duration\": \"duration\",\n",
    "    \"datetime\": \"local_timestamp\"}\n",
    "# Save only sparse trajectories and diaries\n",
    "population.save_pop(\n",
    "    sparse_path=\"output/sparse_traj/\",\n",
    "    diaries_path=\"output/diaries/\",\n",
    "    partition_cols={\n",
    "        \"sparse_traj\": [\"date\"],\n",
    "        \"diaries\": [\"uid\"]\n",
    "    },\n",
    "    traj_cols=traj_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e81d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparse_df = loader.from_file(\"output/sparse_traj/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                      parse_dates=True)\n",
    "diaries_df = loader.from_file(\"output/diaries/\", format=\"parquet\", traj_cols=traj_cols,\n",
    "                       parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e29eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0be1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762faed",
   "metadata": {},
   "source": [
    "## Parallelized Trajectory Generation\n",
    "\n",
    "For larger trajectory generation tasks that require a lot of compute power, we can parallelize the trajectory generation using the following code. We generate ground-truth trajectories in agent-month \"chunks\", sparsify each chunk, then reset the ground-truth trajectory field to lessen the memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e81ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using parallel processing (e.g., using a cluster)\n",
    "%%time\n",
    "\n",
    "def generate_trajectory_data(agent_id, agent, seed):\n",
    "    \n",
    "    beta_duration = npr.uniform(15, 180)\n",
    "    beta_start = max(npr.uniform(60, 1200), beta_duration*3)\n",
    "    beta_ping = npr.uniform(1.5, 30)\n",
    "    \n",
    "    param = (beta_start, beta_duration, beta_ping)\n",
    "    \n",
    "    for month in range(1,13):\n",
    "        days = calendar.monthrange(2024, month)[1]\n",
    "        population_n.generate_trajectory(agent, \n",
    "                                         T=datetime(2024, month, days, hour=23, minute=59), \n",
    "                                         seed=seed)\n",
    "    \n",
    "        agent.sample_traj_hier_nhpp(*param, \n",
    "                                    seed=seed,\n",
    "                                    reset_traj=True)\n",
    "    \n",
    "    garden_city_to_lat_long(agent,\n",
    "                            sparse_traj=True,\n",
    "                            full_traj=False)\n",
    "    \n",
    "    return agent_id, copy.deepcopy(agent)\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "shared_roster = manager.dict(population_n.roster)\n",
    "\n",
    "start = 6001  # 12001  # can modify\n",
    "end = 12001   # 18001  # can modify\n",
    "roster = dict(population_n.roster)\n",
    "batch = islice(roster.items(), start, end)\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    with tqdm(total=(end-start), desc=\"Processing agents\") as pbar:\n",
    "        futures = [\n",
    "            executor.submit(generate_trajectory_data, agent_id, agent, i+15000)\n",
    "            for i, (agent_id, agent) in enumerate(batch, start=start)\n",
    "        ]\n",
    "        results = []\n",
    "        for future in futures:\n",
    "            results.append(future.result())\n",
    "            pbar.update(1)\n",
    "\n",
    "for agent_id, agent in results:\n",
    "    population_n.roster[agent_id] = agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee64f31",
   "metadata": {},
   "source": [
    "This code saves the generated trajectories in a parquet file, using the date as the partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdffd98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partition_cols = {\n",
    "    'sparse_traj': ['date'],\n",
    "    'diaries': ['identifier']\n",
    "}\n",
    "\n",
    "roster = dict(islice(population_n.roster.items(), start, end))\n",
    "\n",
    "population_n.save_pop(bucket=\"synthetic-raw-data\",\n",
    "                      prefix=f\"agents-{start+15000}-{end+15000-1}/\",\n",
    "                      save_full_traj=False,\n",
    "                      save_sparse_traj=True,\n",
    "                      save_homes=True,\n",
    "                      save_diaries=True,\n",
    "                      partition_cols=partition_cols,\n",
    "                      roster=roster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a261b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Parquet files\n",
    "s3_path = \"s3://synthetic-raw-data/agents-1-1001/sparse_trajectories.parquet/\"\n",
    "df1 = pd.read_parquet(s3_path)\n",
    "s3_path = \"s3://synthetic-raw-data/agents-1001-2000/sparse_trajectories.parquet/\"\n",
    "df2 = pd.read_parquet(s3_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (daphme)",
   "language": "python",
   "name": "daphme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3 (ipykernel)"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3.10 (daphme)"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 3,
           "op": "addrange",
           "valuelist": "0"
          },
          {
           "key": 3,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
